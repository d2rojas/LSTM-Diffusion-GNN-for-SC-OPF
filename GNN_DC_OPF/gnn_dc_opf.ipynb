{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8822cf45",
   "metadata": {},
   "source": [
    "# Part III: GNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ea8cefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import copy # Needed for deep copying data for each scenario\n",
    "import random # For generating random load factors\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebf265f",
   "metadata": {},
   "source": [
    "# IEEE 6-bus test system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41e5d3ba",
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- IEEE 6-Bus System (Original Topology) ---\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- IEEE 6-Bus System (PV Added to Bus 3) ---\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def draw_ieee_6_bus_topology(buses_data, generators_data, branches_data, slack_bus_idx,\n",
    "                              pv_bus_idx=None, pv_generation_mw=0):\n",
    "    \"\"\"\n",
    "    Draws the topology of the IEEE 6-bus test system, with an optional PV generator.\n",
    "    \"\"\"\n",
    "\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # --- Add Nodes (Buses) with Attributes ---\n",
    "    node_labels = {}\n",
    "    \n",
    "    # Pre-define lists for drawing categories to ensure consistent color/shape for legend\n",
    "    node_load_buses = []\n",
    "    node_gen_buses = []\n",
    "    node_slack_buses = []\n",
    "    node_pv_buses = [] # New list for PV buses\n",
    "\n",
    "    # Identify generator buses for easier attribute assignment\n",
    "    gen_bus_0_indices = {g['bus'] for g in generators_data}\n",
    "\n",
    "    for bus_idx, data in buses_data.items():\n",
    "        bus_label = bus_idx + 1 # Convert to 1-based indexing for display\n",
    "        G.add_node(bus_label)\n",
    "        \n",
    "        is_load_bus = data['Pd'] > 0 # Check original load\n",
    "        is_gen_bus = bus_idx in gen_bus_0_indices\n",
    "        is_slack_bus = bus_idx == slack_bus_idx\n",
    "        is_pv_bus = (pv_bus_idx is not None) and (bus_idx == pv_bus_idx)\n",
    "\n",
    "        # Assign attributes for display and internal logic\n",
    "        G.nodes[bus_label]['original_load_MW'] = data['Pd'] # Store original load\n",
    "        G.nodes[bus_label]['is_generator'] = is_gen_bus\n",
    "        G.nodes[bus_label]['is_slack'] = is_slack_bus\n",
    "        G.nodes[bus_label]['is_pv_equipped'] = is_pv_bus\n",
    "        G.nodes[bus_label]['pv_generation_mw_display'] = 0.0 # Default\n",
    "\n",
    "        current_net_load_for_label = data['Pd'] # Start with original demand for net load label\n",
    "\n",
    "        if is_pv_bus and pv_generation_mw > 0:\n",
    "            G.nodes[bus_label]['pv_generation_mw_display'] = pv_generation_mw\n",
    "            current_net_load_for_label -= pv_generation_mw # Calculate net load for display\n",
    "            \n",
    "            # Add to PV bus list\n",
    "            node_pv_buses.append(bus_label)\n",
    "            node_labels[bus_label] = f\"Bus {bus_label}\\n(Solar PV: {pv_generation_mw:.0f}MW, Net Load: {current_net_load_for_label:.1f}MW)\"\n",
    "        elif is_slack_bus:\n",
    "            node_slack_buses.append(bus_label)\n",
    "            node_labels[bus_label] = f\"Bus {bus_label}\\n(Generator, Slack)\"\n",
    "        elif is_gen_bus:\n",
    "            node_gen_buses.append(bus_label)\n",
    "            # If a generator bus also has a load, you could show it here if data['Pd'] > 0\n",
    "            node_labels[bus_label] = f\"Bus {bus_label}\\n(Generator)\"\n",
    "        elif is_load_bus: # This will catch all remaining load buses\n",
    "            node_load_buses.append(bus_label)\n",
    "            node_labels[bus_label] = f\"Bus {bus_label}\\n(Load: {data['Pd']}MW)\"\n",
    "        else: # Bus with no generator and no (positive) load (e.g., intermediate bus)\n",
    "            node_load_buses.append(bus_label) # Add to general load category, could be 'other'\n",
    "            node_labels[bus_label] = f\"Bus {bus_label}\"\n",
    "\n",
    "\n",
    "    # --- Add Edges (Branches) ---\n",
    "    for branch in branches_data:\n",
    "        from_bus_label = branch['from_bus'] + 1\n",
    "        to_bus_label = branch['to_bus'] + 1\n",
    "        G.add_edge(from_bus_label, to_bus_label)\n",
    "        \n",
    "        G.edges[(from_bus_label, to_bus_label)]['X_pu'] = branch['X_pu']\n",
    "        G.edges[(from_bus_label, to_bus_label)]['limit_MW'] = branch['limit_MW']\n",
    "\n",
    "\n",
    "    # --- Draw the Graph ---\n",
    "    plt.figure(figsize=(12, 4)) # Adjust figure size for better visibility\n",
    "\n",
    "    # Manual positions for IEEE 6-bus (these are generally good for this specific system)\n",
    "    pos = {\n",
    "        1: (0, 0),    # Bus 1 (Slack, Gen)\n",
    "        2: (-1, 1),   # Bus 2 (Gen)\n",
    "        3: (1, 2),    # Bus 3 (Load, target for PV)\n",
    "        4: (2, 1),    # Bus 4 (Load)\n",
    "        5: (-2, -1),  # Bus 5 (Gen)\n",
    "        6: (1, -2)    # Bus 6 (Load)\n",
    "    }\n",
    "\n",
    "    # Draw nodes by type\n",
    "    node_size = 1000 # Consistent node size\n",
    "\n",
    "    nx.draw_networkx_nodes(G, pos, nodelist=node_load_buses, node_color='lightcoral', node_shape='o', node_size=node_size, label=\"Load Bus\")\n",
    "    nx.draw_networkx_nodes(G, pos, nodelist=node_gen_buses, node_color='lightgreen', node_shape='s', node_size=node_size, label=\"Generator Bus\")\n",
    "    nx.draw_networkx_nodes(G, pos, nodelist=node_slack_buses, node_color='gold', node_shape='p', node_size=node_size, label=\"Slack/Gen Bus\")\n",
    "    \n",
    "    # Draw PV nodes separately to apply specific color and shape\n",
    "    nx.draw_networkx_nodes(G, pos, nodelist=node_pv_buses, node_color='skyblue', node_shape='D', node_size=node_size, label=\"Load Bus with PV\")\n",
    "\n",
    "    # Draw edges\n",
    "    nx.draw_networkx_edges(G, pos, width=4, alpha=0.7, edge_color='gray')\n",
    "\n",
    "    # Draw node labels (bus numbers and type/load/PV info)\n",
    "    nx.draw_networkx_labels(G, pos, labels=node_labels, font_size=16, font_weight='bold') # Slightly smaller font for more info\n",
    "\n",
    "    plt.title(\"IEEE 6-Bus System Topology (with PV Generator)\", fontsize=24)\n",
    "    plt.axis('off') # Turn off the axis\n",
    "    plt.legend(scatterpoints=1, loc='upper left', bbox_to_anchor=(1, 1), labelspacing=2.5, fontsize=16) \n",
    "    plt.tight_layout() # Automatically adjust plot parameters for a tight layout\n",
    "    plt.show()\n",
    "\n",
    "# Original base data for the IEEE 6-bus system\n",
    "ieee_6_buses_data_original = {\n",
    "    0: {'Pd': 0},    # Bus 1 (Slack, Gen)\n",
    "    1: {'Pd': 0},    # Bus 2 (Gen)\n",
    "    2: {'Pd': 50},   # Bus 3 (Load) - Target for PV in examples\n",
    "    3: {'Pd': 60},   # Bus 4 (Load)\n",
    "    4: {'Pd': 0},    # Bus 5 (Gen)\n",
    "    5: {'Pd': 100}   # Bus 6 (Load)\n",
    "}\n",
    "\n",
    "ieee_6_generators_data_base = [\n",
    "    {'bus': 0, 'Pmin': 0, 'Pmax': 100}, # Bus 1\n",
    "    {'bus': 1, 'Pmin': 0, 'Pmax': 80},  # Bus 2\n",
    "    {'bus': 4, 'Pmin': 0, 'Pmax': 120}  # Bus 5\n",
    "]\n",
    "\n",
    "ieee_6_branches_data_base = [\n",
    "    {'from_bus': 0, 'to_bus': 1, 'X_pu': 0.1703, 'limit_MW': 100},\n",
    "    {'from_bus': 0, 'to_bus': 3, 'X_pu': 0.2081, 'limit_MW': 100},\n",
    "    {'from_bus': 1, 'to_bus': 2, 'X_pu': 0.1737, 'limit_MW': 100},\n",
    "    {'from_bus': 1, 'to_bus': 4, 'X_pu': 0.0535, 'limit_MW': 100},\n",
    "    {'from_bus': 2, 'to_bus': 3, 'X_pu': 0.2370, 'limit_MW': 100},\n",
    "    {'from_bus': 3, 'to_bus': 5, 'X_pu': 0.1065, 'limit_MW': 100},\n",
    "    {'from_bus': 4, 'to_bus': 5, 'X_pu': 0.1989, 'limit_MW': 100}\n",
    "]\n",
    "\n",
    "SLACK_BUS_IDX = 0 # Bus 1 is the slack bus\n",
    "\n",
    "# --- Draw the system without PV ---\n",
    "print(\"--- IEEE 6-Bus System (Original Topology) ---\")\n",
    "draw_ieee_6_bus_topology(\n",
    "    buses_data=ieee_6_buses_data_original,\n",
    "    generators_data=ieee_6_generators_data_base,\n",
    "    branches_data=ieee_6_branches_data_base,\n",
    "    slack_bus_idx=SLACK_BUS_IDX\n",
    ")\n",
    "\n",
    "# --- Draw the system with PV on Bus 3 (0-indexed 2) ---\n",
    "print(\"\\n--- IEEE 6-Bus System (PV Added to Bus 3) ---\")\n",
    "pv_bus_to_add = 2 # Bus 3 (0-indexed)\n",
    "pv_gen_value = random.uniform(20, 70) # Random PV generation between 20 and 70 MW\n",
    "\n",
    "draw_ieee_6_bus_topology(\n",
    "    buses_data=ieee_6_buses_data_original, # Pass original data; function calculates net load for label\n",
    "    generators_data=ieee_6_generators_data_base,\n",
    "    branches_data=ieee_6_branches_data_base,\n",
    "    slack_bus_idx=SLACK_BUS_IDX,\n",
    "    pv_bus_idx=pv_bus_to_add,\n",
    "    pv_generation_mw=pv_gen_value\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b23e14",
   "metadata": {},
   "source": [
    "# Generate a DC-OPF N-0 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92ed94ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_dc_opf(buses_data, generators_data, branches_data, slack_bus_idx=0):\n",
    "    \"\"\"\n",
    "    Solves the DC Optimal Power Flow problem for a given power system.\n",
    "    \"\"\"\n",
    "\n",
    "    num_buses = len(buses_data)\n",
    "    num_generators = len(generators_data)\n",
    "    num_branches = len(branches_data)\n",
    "\n",
    "    # Extract 0-indexed bus IDs where generators are located\n",
    "    gen_bus_indices = [g['bus'] for g in generators_data]\n",
    "\n",
    "    # Construct B' matrix (susceptance matrix for DC power flow)\n",
    "    B_prime = np.zeros((num_buses, num_buses))\n",
    "    for branch in branches_data:\n",
    "        from_bus = branch['from_bus']\n",
    "        to_bus = branch['to_bus']\n",
    "        x_val = branch['X_pu']\n",
    "\n",
    "        if x_val == 0:\n",
    "            raise ValueError(f\"Branch between bus {from_bus+1} and {to_bus+1} has zero reactance (X_pu), which is invalid for DC OPF.\")\n",
    "        \n",
    "        b_val = 1 / x_val # Susceptance\n",
    "\n",
    "        # Off-diagonal elements\n",
    "        B_prime[from_bus, to_bus] -= b_val\n",
    "        B_prime[to_bus, from_bus] -= b_val\n",
    "        # Diagonal elements\n",
    "        B_prime[from_bus, from_bus] += b_val\n",
    "        B_prime[to_bus, to_bus] += b_val\n",
    "\n",
    "    # --- Define Optimization Variables ---\n",
    "    pg = cp.Variable(num_generators, name='Pg') # Active power generation (MW)\n",
    "    theta = cp.Variable(num_buses, name='Theta') # Bus voltage angles (radians)\n",
    "\n",
    "    # --- Objective Function ---\n",
    "    total_cost = 0\n",
    "    for i, gen_data in enumerate(generators_data):\n",
    "        total_cost += gen_data['cost_a'] * cp.square(pg[i]) + \\\n",
    "                      gen_data['cost_b'] * pg[i] + \\\n",
    "                      gen_data['cost_c']\n",
    "\n",
    "    objective = cp.Minimize(total_cost)\n",
    "\n",
    "    # --- Define Constraints ---\n",
    "    constraints = []\n",
    "\n",
    "    # 1. Reference Bus Angle Constraint: Slack bus angle is fixed to 0\n",
    "    constraints.append(theta[slack_bus_idx] == 0)\n",
    "\n",
    "    # 2. Power Balance (Kirchhoff's Current Law) at each bus\n",
    "    # P_injection_i = Pg_i - Pd_i = (B_prime @ theta)[i]\n",
    "    for i in range(num_buses):\n",
    "        # Determine total generation at bus i (0 if no generator, else pg value)\n",
    "        Pg_at_bus_i_expr = 0\n",
    "        if i in gen_bus_indices:\n",
    "            # Find the index of this generator within the 'pg' variable\n",
    "            gen_var_idx = gen_bus_indices.index(i)\n",
    "            Pg_at_bus_i_expr = pg[gen_var_idx]\n",
    "        \n",
    "        Pd_at_bus_i = buses_data[i]['Pd'] # Demand at bus i\n",
    "\n",
    "        # Enforce power balance: (Generation - Demand) == (Sum of flows leaving the bus)\n",
    "        constraints.append(Pg_at_bus_i_expr - Pd_at_bus_i == (B_prime @ theta)[i])\n",
    "\n",
    "    # 3. Generator Active Power Limits\n",
    "    for i, gen_data in enumerate(generators_data):\n",
    "        constraints.append(pg[i] >= gen_data['Pmin'])\n",
    "        constraints.append(pg[i] <= gen_data['Pmax'])\n",
    "\n",
    "    # 4. Line Active Power Flow Limits\n",
    "    # P_flow_ij = (1/X_ij) * (theta_i - theta_j)\n",
    "    for branch in branches_data:\n",
    "        from_bus = branch['from_bus']\n",
    "        to_bus = branch['to_bus']\n",
    "        x_val = branch['X_pu']\n",
    "        limit_MW = branch['limit_MW']\n",
    "\n",
    "        p_flow = (1 / x_val) * (theta[from_bus] - theta[to_bus])\n",
    "        constraints.append(p_flow >= -limit_MW)\n",
    "        constraints.append(p_flow <= limit_MW)\n",
    "\n",
    "    # --- Create and Solve the Optimization Problem ---\n",
    "    problem = cp.Problem(objective, constraints)\n",
    "    problem.solve(solver=cp.ECOS, verbose=False) # ECOS is a robust open-source solver for convex problems\n",
    "\n",
    "    # --- Process and Return Results ---\n",
    "    results = {\n",
    "        'cost': None,\n",
    "        'pg': {},\n",
    "        'theta': {},\n",
    "        'pf': {},\n",
    "        'status': problem.status,\n",
    "        'problem_status': problem.status # More detailed status from cvxpy\n",
    "    }\n",
    "\n",
    "    if problem.status in [\"optimal\", \"optimal_near\", \"feasible\"]:\n",
    "        results['cost'] = problem.value\n",
    "\n",
    "        # Store generator outputs with 1-based original bus IDs\n",
    "        for i, gen_data in enumerate(generators_data):\n",
    "            results['pg'][gen_data['bus'] + 1] = pg[i].value\n",
    "\n",
    "        # Store bus angles (converted to degrees) with 1-based original bus IDs\n",
    "        for i in range(num_buses):\n",
    "            results['theta'][i + 1] = np.degrees(theta[i].value) # Convert radians to degrees\n",
    "\n",
    "        # Calculate and store line flows with 1-based original bus IDs\n",
    "        for branch in branches_data:\n",
    "            from_bus = branch['from_bus']\n",
    "            to_bus = branch['to_bus']\n",
    "            x_val = branch['X_pu']\n",
    "            flow_value = (1 / x_val) * (theta[from_bus].value - theta[to_bus].value)\n",
    "            results['pf'][f\"Line {from_bus+1}-{to_bus+1}\"] = flow_value\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951999f6",
   "metadata": {},
   "source": [
    "## Initialize the IEEE test system "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34847862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data for IEEE 6-Bus System...\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing data for IEEE 6-Bus System...\")\n",
    "\n",
    "# Bus Data: (0-indexed bus ID -> {'Pd': demand_MW})\n",
    "ieee_6_buses_data = {\n",
    "    0: {'Pd': 0},      # Bus 1 (Slack, Gen)\n",
    "    1: {'Pd': 0},      # Bus 2 (Gen)\n",
    "    2: {'Pd': 80},     # Bus 3 (Load)\n",
    "    3: {'Pd': 100},    # Bus 4 (Load)\n",
    "    4: {'Pd': 0},      # Bus 5 (Gen)\n",
    "    5: {'Pd': 150}     # Bus 6 (Load)\n",
    "}\n",
    "\n",
    "# Generator Data: List of dictionaries\n",
    "# (0-indexed bus ID, Pmin_MW, Pmax_MW, cost_a, cost_b, cost_c)\n",
    "ieee_6_generators_data = [\n",
    "    {'bus': 0, 'Pmin': 10,  'Pmax': 250, 'cost_a': 0.004,   'cost_b': 20, 'cost_c': 0}, # Gen at Bus 1\n",
    "    {'bus': 1, 'Pmin': 10,  'Pmax': 200, 'cost_a': 0.00175, 'cost_b': 20, 'cost_c': 0}, # Gen at Bus 2\n",
    "    {'bus': 4, 'Pmin': 10,  'Pmax': 150, 'cost_a': 0.00625, 'cost_b': 40, 'cost_c': 0}  # Gen at Bus 5\n",
    "]\n",
    "\n",
    "# Branch Data: List of dictionaries\n",
    "# (from_bus_idx, to_bus_idx, X_pu, RateA_MW_limit)\n",
    "ieee_6_branches_data = [\n",
    "    {'from_bus': 0, 'to_bus': 1, 'X_pu': 0.4,  'limit_MW': 200},  # Line 1-2\n",
    "    {'from_bus': 0, 'to_bus': 3, 'X_pu': 0.2,  'limit_MW': 200},  # Line 1-4\n",
    "    {'from_bus': 1, 'to_bus': 2, 'X_pu': 0.25, 'limit_MW': 100},  # Line 2-3\n",
    "    {'from_bus': 1, 'to_bus': 4, 'X_pu': 0.15, 'limit_MW': 100},  # Line 2-5\n",
    "    {'from_bus': 2, 'to_bus': 3, 'X_pu': 0.25, 'limit_MW': 100},  # Line 3-4\n",
    "    {'from_bus': 3, 'to_bus': 5, 'X_pu': 0.3,  'limit_MW': 100},  # Line 4-6\n",
    "    {'from_bus': 4, 'to_bus': 5, 'X_pu': 0.2,  'limit_MW': 100}   # Line 5-6\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f247d8",
   "metadata": {},
   "source": [
    "## Test the DC-OPF module "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e773d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- DC OPF Results for IEEE 6-Bus System ---\n",
      "Solver Status: optimal\n",
      "Detailed Problem Status: optimal\n",
      "\n",
      "Optimal Total Generation Cost: $6967.67\n",
      "\n",
      "Optimal Generator Active Power Outputs (MW):\n",
      "  Generator at Bus 1: 183.25 MW\n",
      "  Generator at Bus 2: 136.75 MW\n",
      "  Generator at Bus 5: 10.00 MW\n",
      "Total System Demand: 330.00 MW\n",
      "Total System Generation: 330.00 MW\n",
      "Generation - Demand Difference: 0.000000 MW (should be close to zero)\n",
      "\n",
      "Optimal Bus Voltage Angles (Degrees):\n",
      "  Bus 1: 0.0000 degrees\n",
      "  Bus 2: -693.2789 degrees\n",
      "  Bus 3: -1796.2227 degrees\n",
      "  Bus 4: -1753.2509 degrees\n",
      "  Bus 5: -1466.7720 degrees\n",
      "  Bus 6: -2612.6876 degrees\n",
      "\n",
      "Optimal Line Active Power Flows (MW):\n",
      "  Line 1-2: 30.25 MW\n",
      "  Line 1-4: 153.00 MW\n",
      "  Line 2-3: 77.00 MW\n",
      "  Line 2-5: 90.00 MW\n",
      "  Line 3-4: -3.00 MW\n",
      "  Line 4-6: 50.00 MW\n",
      "  Line 5-6: 100.00 MW\n",
      "\n",
      "--- Constraint Verification ---\n",
      "  Gen at Bus 1 (183.25 MW) within limits (10-250 MW).\n",
      "  Gen at Bus 2 (136.75 MW) within limits (10-200 MW).\n",
      "  Gen at Bus 5 (10.00 MW) within limits (10-150 MW).\n",
      "  Line 1-2 flow (30.25 MW) within limit (200.0 MW).\n",
      "  Line 1-4 flow (153.00 MW) within limit (200.0 MW).\n",
      "  Line 2-3 flow (77.00 MW) within limit (100.0 MW).\n",
      "  Line 2-5 flow (90.00 MW) within limit (100.0 MW).\n",
      "  Line 3-4 flow (-3.00 MW) within limit (100.0 MW).\n",
      "  Line 4-6 flow (50.00 MW) within limit (100.0 MW).\n",
      "  Line 5-6 flow (100.00 MW) within limit (100.0 MW).\n"
     ]
    }
   ],
   "source": [
    "# Solve the DC OPF\n",
    "opf_results = solve_dc_opf(ieee_6_buses_data, ieee_6_generators_data, ieee_6_branches_data, slack_bus_idx=0)\n",
    "\n",
    "print(\"\\n--- DC OPF Results for IEEE 6-Bus System ---\")\n",
    "print(f\"Solver Status: {opf_results['status']}\")\n",
    "print(f\"Detailed Problem Status: {opf_results['problem_status']}\")\n",
    "\n",
    "if opf_results['status'] in [\"optimal\", \"optimal_near\", \"feasible\"]:\n",
    "    print(f\"\\nOptimal Total Generation Cost: ${opf_results['cost']:.2f}\")\n",
    "\n",
    "    print(\"\\nOptimal Generator Active Power Outputs (MW):\")\n",
    "    total_demand = sum(bus['Pd'] for bus in ieee_6_buses_data.values())\n",
    "    total_generation = 0\n",
    "    for bus_idx, pg_val in opf_results['pg'].items():\n",
    "        print(f\"  Generator at Bus {bus_idx}: {pg_val:.2f} MW\")\n",
    "        total_generation += pg_val\n",
    "    print(f\"Total System Demand: {total_demand:.2f} MW\")\n",
    "    print(f\"Total System Generation: {total_generation:.2f} MW\")\n",
    "    print(f\"Generation - Demand Difference: {total_generation - total_demand:.6f} MW (should be close to zero)\")\n",
    "\n",
    "    print(\"\\nOptimal Bus Voltage Angles (Degrees):\")\n",
    "    for bus_idx, theta_deg in opf_results['theta'].items():\n",
    "        print(f\"  Bus {bus_idx}: {theta_deg:.4f} degrees\")\n",
    "\n",
    "    print(\"\\nOptimal Line Active Power Flows (MW):\")\n",
    "    for line_name, flow_val in opf_results['pf'].items():\n",
    "        print(f\"  {line_name}: {flow_val:.2f} MW\")\n",
    "\n",
    "    # --- Basic Constraint Verification ---\n",
    "    print(\"\\n--- Constraint Verification ---\")\n",
    "    # Verify generator limits\n",
    "    for gen_data in ieee_6_generators_data:\n",
    "        bus_id = gen_data['bus'] + 1\n",
    "        pg_val = opf_results['pg'][bus_id]\n",
    "        if not (gen_data['Pmin'] <= pg_val <= gen_data['Pmax'] + 1e-6): # Add tolerance for float comparison\n",
    "            print(f\"  WARNING: Gen at Bus {bus_id} ({pg_val:.2f} MW) violates limits ({gen_data['Pmin']}-{gen_data['Pmax']} MW)!\")\n",
    "        else:\n",
    "            print(f\"  Gen at Bus {bus_id} ({pg_val:.2f} MW) within limits ({gen_data['Pmin']}-{gen_data['Pmax']} MW).\")\n",
    "\n",
    "    # Verify line limits\n",
    "    for branch_data in ieee_6_branches_data:\n",
    "        line_name = f\"Line {branch_data['from_bus']+1}-{branch_data['to_bus']+1}\"\n",
    "        flow_val = opf_results['pf'][line_name]\n",
    "        limit = branch_data['limit_MW']\n",
    "        if not (abs(flow_val) <= limit + 1e-6): # Add tolerance\n",
    "            print(f\"  WARNING: {line_name} flow ({flow_val:.2f} MW) violates limit ({limit:.1f} MW)!\")\n",
    "        else:\n",
    "            print(f\"  {line_name} flow ({flow_val:.2f} MW) within limit ({limit:.1f} MW).\")\n",
    "\n",
    "else:\n",
    "    print(\"Optimization did not find an optimal solution or encountered an error.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f5aae9",
   "metadata": {},
   "source": [
    "## Generate 20k DC-OPF solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f03fa266",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Updated Test Function for 20000 Load Demand Scenarios (Per-Bus Scaling with Saving)\n",
    "def test_dc_opf_100_load_scenarios_per_bus_scale(base_buses_data, generators_data, branches_data, slack_bus_idx=0, save_file=\"feasible_opf_results.json\"):\n",
    "    \"\"\"\n",
    "    Tests the DC OPF solver across 20k randomly generated load demand scenarios,\n",
    "    where each load bus demand is scaled by a different random factor.\n",
    "    Saves feasible solutions' parameters and decision variables.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"--- Starting DC OPF Testing for 20k Load Scenarios (Per-Bus Scaling) ---\")\n",
    "\n",
    "    num_scenarios = 20000\n",
    "    \n",
    "    min_bus_load_scale = 0.0\n",
    "    max_bus_load_scale = 1.8\n",
    "\n",
    "    all_scenario_results = [] # Stores summary of each scenario\n",
    "    feasible_solutions_data = [] # Stores detailed data for feasible solutions\n",
    "    \n",
    "    original_total_demand_base = sum(bus['Pd'] for bus in base_buses_data.values())\n",
    "\n",
    "    for i in range(num_scenarios):\n",
    "        current_buses_data = copy.deepcopy(base_buses_data)\n",
    "        \n",
    "        # Store the actual load values for this scenario\n",
    "        scenario_bus_loads = {}\n",
    "        for bus_id in current_buses_data:\n",
    "            if current_buses_data[bus_id]['Pd'] > 0:\n",
    "                individual_scale_factor = random.uniform(min_bus_load_scale, max_bus_load_scale)\n",
    "                current_buses_data[bus_id]['Pd'] *= individual_scale_factor\n",
    "            scenario_bus_loads[bus_id + 1] = current_buses_data[bus_id]['Pd'] # Store with 1-based index\n",
    "        \n",
    "        current_total_demand = sum(bus['Pd'] for bus in current_buses_data.values())\n",
    "\n",
    "        results = solve_dc_opf(current_buses_data, generators_data, branches_data, slack_bus_idx)\n",
    "        \n",
    "        scenario_info = {\n",
    "            'scenario_id': i + 1,\n",
    "            'total_demand_MW': current_total_demand,\n",
    "            'status': results['status'],\n",
    "            'problem_status': results['problem_status'],\n",
    "            'cost': results['cost'],\n",
    "            'total_generation_MW': None,\n",
    "            'line_violations': 0,\n",
    "            'gen_violations': 0\n",
    "        }\n",
    "\n",
    "        if results['status'] in [\"optimal\", \"optimal_near\", \"feasible\"]:\n",
    "            total_generation = sum(results['pg'].values())\n",
    "            scenario_info['total_generation_MW'] = total_generation\n",
    "\n",
    "            # Verification of constraints (should be zero for feasible solutions)\n",
    "            for gen_idx, gen_data in enumerate(generators_data):\n",
    "                bus_id = gen_data['bus'] + 1\n",
    "                pg_val = results['pg'][bus_id]\n",
    "                if not (gen_data['Pmin'] - 1e-6 <= pg_val <= gen_data['Pmax'] + 1e-6):\n",
    "                    scenario_info['gen_violations'] += 1\n",
    "\n",
    "            for branch_data in branches_data:\n",
    "                line_name = f\"Line {branch_data['from_bus']+1}-{branch_data['to_bus']+1}\"\n",
    "                flow_val = results['pf'].get(line_name, 0)\n",
    "                limit = branch_data['limit_MW']\n",
    "                if abs(flow_val) > limit + 1e-6:\n",
    "                    scenario_info['line_violations'] += 1\n",
    "            \n",
    "            # --- Save detailed data for feasible solutions ---\n",
    "            feasible_solutions_data.append({\n",
    "                'scenario_id': i + 1,\n",
    "                'input_parameters': {\n",
    "                    'bus_loads_MW': scenario_bus_loads, # Individual bus loads for this scenario\n",
    "                    'total_demand_MW': current_total_demand\n",
    "                },\n",
    "                'output_decision_variables': {\n",
    "                    'optimal_cost': results['cost'],\n",
    "                    'pg_MW': results['pg'],\n",
    "                    'theta_degrees': results['theta'],\n",
    "                    'pf_MW': results['pf']\n",
    "                },\n",
    "                'solution_status': {\n",
    "                    'status': results['status'],\n",
    "                    'problem_status': results['problem_status'],\n",
    "                    'gen_violations_count': scenario_info['gen_violations'],\n",
    "                    'line_violations_count': scenario_info['line_violations']\n",
    "                }\n",
    "            })\n",
    "        \n",
    "        all_scenario_results.append(scenario_info)\n",
    "\n",
    "        if (i + 1) % 200 == 0 or i == num_scenarios - 1:\n",
    "            print(f\"  Processed {i+1}/{num_scenarios} scenarios. Status: {results['status']}, Total Demand: {current_total_demand:.2f} MW\")\n",
    "\n",
    "    # --- Save feasible solutions data to JSON file ---\n",
    "    try:\n",
    "        with open(save_file, 'w') as f:\n",
    "            json.dump(feasible_solutions_data, f, indent=4)\n",
    "        print(f\"\\nSaved {len(feasible_solutions_data)} feasible solutions to '{save_file}'\")\n",
    "    except IOError as e:\n",
    "        print(f\"\\nError saving results to file '{save_file}': {e}\")\n",
    "\n",
    "\n",
    "    # --- Summary Report (remains similar to before) ---\n",
    "    print(\"\\n\\n--- Summary Report for 100 Load Scenarios (Per-Bus Scaling) ---\")\n",
    "    \n",
    "    feasible_count = 0\n",
    "    infeasible_count = 0\n",
    "    error_count = 0\n",
    "    total_costs = []\n",
    "    \n",
    "    for scenario in all_scenario_results:\n",
    "        if scenario['status'] in [\"optimal\", \"optimal_near\", \"feasible\"]:\n",
    "            feasible_count += 1\n",
    "            if scenario['cost'] is not None:\n",
    "                total_costs.append(scenario['cost'])\n",
    "        elif scenario['status'] == \"infeasible\":\n",
    "            infeasible_count += 1\n",
    "        else: # e.g., 'unbounded', 'solver_error' etc.\n",
    "            error_count += 1\n",
    "            \n",
    "    print(f\"Total Scenarios Tested: {num_scenarios}\")\n",
    "    print(f\"Feasible Solutions Found: {feasible_count}\")\n",
    "    print(f\"Infeasible Solutions: {infeasible_count}\")\n",
    "    print(f\"Solutions with Solver Errors: {error_count}\")\n",
    "    \n",
    "    if feasible_count > 0:\n",
    "        print(f\"\\nCost Statistics (Feasible Scenarios):\")\n",
    "        print(f\"  Min Cost: ${np.min(total_costs):.2f}\")\n",
    "        print(f\"  Max Cost: ${np.max(total_costs):.2f}\")\n",
    "        print(f\"  Average Cost: ${np.mean(total_costs):.2f}\")\n",
    "    \n",
    "    print(\"\\n--- Detailed Solver Status Breakdown ---\")\n",
    "    status_counts = {}\n",
    "    for scenario in all_scenario_results:\n",
    "        status = scenario['problem_status']\n",
    "        status_counts[status] = status_counts.get(status, 0) + 1\n",
    "    \n",
    "    for status, count in status_counts.items():\n",
    "        print(f\"  {status}: {count} scenarios\")\n",
    "\n",
    "    return feasible_solutions_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "eee62452",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting DC OPF Testing for 20k Load Scenarios (Per-Bus Scaling) ---\n",
      "  Processed 200/20000 scenarios. Status: optimal, Total Demand: 156.63 MW\n",
      "  Processed 400/20000 scenarios. Status: infeasible, Total Demand: 418.50 MW\n",
      "  Processed 600/20000 scenarios. Status: infeasible, Total Demand: 349.77 MW\n",
      "  Processed 800/20000 scenarios. Status: optimal, Total Demand: 153.29 MW\n",
      "  Processed 1000/20000 scenarios. Status: optimal_inaccurate, Total Demand: 297.40 MW\n",
      "  Processed 1200/20000 scenarios. Status: optimal, Total Demand: 187.43 MW\n",
      "  Processed 1400/20000 scenarios. Status: infeasible, Total Demand: 451.20 MW\n",
      "  Processed 1600/20000 scenarios. Status: optimal, Total Demand: 140.93 MW\n",
      "  Processed 1800/20000 scenarios. Status: optimal, Total Demand: 326.28 MW\n",
      "  Processed 2000/20000 scenarios. Status: infeasible_inaccurate, Total Demand: 320.79 MW\n",
      "  Processed 2200/20000 scenarios. Status: optimal, Total Demand: 222.66 MW\n",
      "  Processed 2400/20000 scenarios. Status: optimal, Total Demand: 290.88 MW\n",
      "  Processed 2600/20000 scenarios. Status: infeasible, Total Demand: 337.28 MW\n",
      "  Processed 2800/20000 scenarios. Status: optimal, Total Demand: 159.49 MW\n",
      "  Processed 3000/20000 scenarios. Status: optimal, Total Demand: 107.27 MW\n",
      "  Processed 3200/20000 scenarios. Status: optimal, Total Demand: 204.85 MW\n",
      "  Processed 3400/20000 scenarios. Status: infeasible, Total Demand: 365.36 MW\n",
      "  Processed 3600/20000 scenarios. Status: optimal, Total Demand: 134.62 MW\n",
      "  Processed 3800/20000 scenarios. Status: infeasible, Total Demand: 423.03 MW\n",
      "  Processed 4000/20000 scenarios. Status: infeasible, Total Demand: 321.03 MW\n",
      "  Processed 4200/20000 scenarios. Status: infeasible, Total Demand: 422.74 MW\n",
      "  Processed 4400/20000 scenarios. Status: optimal, Total Demand: 242.86 MW\n",
      "  Processed 4600/20000 scenarios. Status: optimal, Total Demand: 84.42 MW\n",
      "  Processed 4800/20000 scenarios. Status: optimal, Total Demand: 104.93 MW\n",
      "  Processed 5000/20000 scenarios. Status: optimal, Total Demand: 236.01 MW\n",
      "  Processed 5200/20000 scenarios. Status: optimal, Total Demand: 204.37 MW\n",
      "  Processed 5400/20000 scenarios. Status: infeasible, Total Demand: 236.38 MW\n",
      "  Processed 5600/20000 scenarios. Status: infeasible, Total Demand: 400.58 MW\n",
      "  Processed 5800/20000 scenarios. Status: infeasible, Total Demand: 294.32 MW\n",
      "  Processed 6000/20000 scenarios. Status: infeasible, Total Demand: 429.88 MW\n",
      "  Processed 6200/20000 scenarios. Status: optimal_inaccurate, Total Demand: 390.06 MW\n",
      "  Processed 6400/20000 scenarios. Status: infeasible, Total Demand: 362.29 MW\n",
      "  Processed 6600/20000 scenarios. Status: optimal, Total Demand: 238.48 MW\n",
      "  Processed 6800/20000 scenarios. Status: infeasible, Total Demand: 304.62 MW\n",
      "  Processed 7000/20000 scenarios. Status: infeasible, Total Demand: 513.92 MW\n",
      "  Processed 7200/20000 scenarios. Status: infeasible, Total Demand: 534.66 MW\n",
      "  Processed 7400/20000 scenarios. Status: infeasible, Total Demand: 456.43 MW\n",
      "  Processed 7600/20000 scenarios. Status: infeasible, Total Demand: 380.26 MW\n",
      "  Processed 7800/20000 scenarios. Status: infeasible_inaccurate, Total Demand: 404.03 MW\n",
      "  Processed 8000/20000 scenarios. Status: infeasible_inaccurate, Total Demand: 243.46 MW\n",
      "  Processed 8200/20000 scenarios. Status: infeasible, Total Demand: 402.82 MW\n",
      "  Processed 8400/20000 scenarios. Status: infeasible, Total Demand: 465.26 MW\n",
      "  Processed 8600/20000 scenarios. Status: optimal, Total Demand: 271.16 MW\n",
      "  Processed 8800/20000 scenarios. Status: optimal, Total Demand: 277.27 MW\n",
      "  Processed 9000/20000 scenarios. Status: infeasible, Total Demand: 491.08 MW\n",
      "  Processed 9200/20000 scenarios. Status: optimal, Total Demand: 333.00 MW\n",
      "  Processed 9400/20000 scenarios. Status: infeasible, Total Demand: 418.43 MW\n",
      "  Processed 9600/20000 scenarios. Status: optimal, Total Demand: 207.98 MW\n",
      "  Processed 9800/20000 scenarios. Status: optimal, Total Demand: 221.16 MW\n",
      "  Processed 10000/20000 scenarios. Status: optimal, Total Demand: 168.24 MW\n",
      "  Processed 10200/20000 scenarios. Status: optimal, Total Demand: 206.50 MW\n",
      "  Processed 10400/20000 scenarios. Status: optimal, Total Demand: 246.25 MW\n",
      "  Processed 10600/20000 scenarios. Status: optimal, Total Demand: 284.16 MW\n",
      "  Processed 10800/20000 scenarios. Status: optimal, Total Demand: 258.24 MW\n",
      "  Processed 11000/20000 scenarios. Status: infeasible, Total Demand: 441.07 MW\n",
      "  Processed 11200/20000 scenarios. Status: optimal, Total Demand: 229.36 MW\n",
      "  Processed 11400/20000 scenarios. Status: optimal, Total Demand: 297.15 MW\n",
      "  Processed 11600/20000 scenarios. Status: optimal, Total Demand: 169.55 MW\n",
      "  Processed 11800/20000 scenarios. Status: optimal, Total Demand: 257.25 MW\n",
      "  Processed 12000/20000 scenarios. Status: infeasible, Total Demand: 366.83 MW\n",
      "  Processed 12200/20000 scenarios. Status: optimal, Total Demand: 271.90 MW\n",
      "  Processed 12400/20000 scenarios. Status: optimal, Total Demand: 234.36 MW\n",
      "  Processed 12600/20000 scenarios. Status: optimal, Total Demand: 287.28 MW\n",
      "  Processed 12800/20000 scenarios. Status: infeasible, Total Demand: 435.34 MW\n",
      "  Processed 13000/20000 scenarios. Status: infeasible, Total Demand: 414.05 MW\n",
      "  Processed 13200/20000 scenarios. Status: optimal, Total Demand: 102.66 MW\n",
      "  Processed 13400/20000 scenarios. Status: optimal, Total Demand: 237.16 MW\n",
      "  Processed 13600/20000 scenarios. Status: optimal, Total Demand: 263.18 MW\n",
      "  Processed 13800/20000 scenarios. Status: infeasible, Total Demand: 373.08 MW\n",
      "  Processed 14000/20000 scenarios. Status: optimal, Total Demand: 125.31 MW\n",
      "  Processed 14200/20000 scenarios. Status: optimal, Total Demand: 341.23 MW\n",
      "  Processed 14400/20000 scenarios. Status: infeasible, Total Demand: 274.32 MW\n",
      "  Processed 14600/20000 scenarios. Status: optimal, Total Demand: 223.27 MW\n",
      "  Processed 14800/20000 scenarios. Status: optimal_inaccurate, Total Demand: 385.65 MW\n",
      "  Processed 15000/20000 scenarios. Status: optimal, Total Demand: 298.12 MW\n",
      "  Processed 15200/20000 scenarios. Status: optimal, Total Demand: 369.16 MW\n",
      "  Processed 15400/20000 scenarios. Status: optimal, Total Demand: 297.41 MW\n",
      "  Processed 15600/20000 scenarios. Status: infeasible, Total Demand: 379.93 MW\n",
      "  Processed 15800/20000 scenarios. Status: optimal, Total Demand: 242.37 MW\n",
      "  Processed 16000/20000 scenarios. Status: optimal, Total Demand: 270.99 MW\n",
      "  Processed 16200/20000 scenarios. Status: optimal, Total Demand: 382.39 MW\n",
      "  Processed 16400/20000 scenarios. Status: infeasible_inaccurate, Total Demand: 276.83 MW\n",
      "  Processed 16600/20000 scenarios. Status: optimal, Total Demand: 202.93 MW\n",
      "  Processed 16800/20000 scenarios. Status: optimal, Total Demand: 323.09 MW\n",
      "  Processed 17000/20000 scenarios. Status: optimal, Total Demand: 232.14 MW\n",
      "  Processed 17200/20000 scenarios. Status: infeasible, Total Demand: 490.79 MW\n",
      "  Processed 17400/20000 scenarios. Status: optimal, Total Demand: 217.22 MW\n",
      "  Processed 17600/20000 scenarios. Status: optimal, Total Demand: 130.55 MW\n",
      "  Processed 17800/20000 scenarios. Status: infeasible, Total Demand: 486.00 MW\n",
      "  Processed 18000/20000 scenarios. Status: optimal, Total Demand: 166.30 MW\n",
      "  Processed 18200/20000 scenarios. Status: optimal, Total Demand: 162.11 MW\n",
      "  Processed 18400/20000 scenarios. Status: optimal, Total Demand: 216.33 MW\n",
      "  Processed 18600/20000 scenarios. Status: optimal, Total Demand: 250.64 MW\n",
      "  Processed 18800/20000 scenarios. Status: infeasible, Total Demand: 441.64 MW\n",
      "  Processed 19000/20000 scenarios. Status: infeasible, Total Demand: 484.17 MW\n",
      "  Processed 19200/20000 scenarios. Status: infeasible, Total Demand: 477.33 MW\n",
      "  Processed 19400/20000 scenarios. Status: optimal, Total Demand: 321.48 MW\n",
      "  Processed 19600/20000 scenarios. Status: infeasible, Total Demand: 468.73 MW\n",
      "  Processed 19800/20000 scenarios. Status: infeasible, Total Demand: 409.07 MW\n",
      "  Processed 20000/20000 scenarios. Status: optimal, Total Demand: 339.87 MW\n",
      "\n",
      "Saved 12392 feasible solutions to 'feasible_opf_results_per_bus_scale.json'\n",
      "\n",
      "\n",
      "--- Summary Report for 100 Load Scenarios (Per-Bus Scaling) ---\n",
      "Total Scenarios Tested: 20000\n",
      "Feasible Solutions Found: 12392\n",
      "Infeasible Solutions: 6519\n",
      "Solutions with Solver Errors: 1089\n",
      "\n",
      "Cost Statistics (Feasible Scenarios):\n",
      "  Min Cost: $834.43\n",
      "  Max Cost: $10708.06\n",
      "  Average Cost: $5129.27\n",
      "\n",
      "--- Detailed Solver Status Breakdown ---\n",
      "  optimal: 12392 scenarios\n",
      "  infeasible: 6519 scenarios\n",
      "  optimal_inaccurate: 516 scenarios\n",
      "  infeasible_inaccurate: 573 scenarios\n"
     ]
    }
   ],
   "source": [
    "# Main execution block to define base data and run the test\n",
    "if __name__ == \"__main__\":\n",
    "    # Define the IEEE 6-Bus system data (nominal)\n",
    "    ieee_6_buses_data = {\n",
    "        0: {'Pd': 0},      # Bus 1 (Slack, Gen)\n",
    "        1: {'Pd': 0},      # Bus 2 (Gen)\n",
    "        2: {'Pd': 80},     # Bus 3 (Load)\n",
    "        3: {'Pd': 100},    # Bus 4 (Load)\n",
    "        4: {'Pd': 0},      # Bus 5 (Gen)\n",
    "        5: {'Pd': 150}     # Bus 6 (Load)\n",
    "    }\n",
    "\n",
    "    ieee_6_generators_data = [\n",
    "        {'bus': 0, 'Pmin': 10,  'Pmax': 250, 'cost_a': 0.004,   'cost_b': 20, 'cost_c': 0}, # Gen at Bus 1\n",
    "        {'bus': 1, 'Pmin': 10,  'Pmax': 200, 'cost_a': 0.00175, 'cost_b': 20, 'cost_c': 0}, # Gen at Bus 2\n",
    "        {'bus': 4, 'Pmin': 10,  'Pmax': 150, 'cost_a': 0.00625, 'cost_b': 40, 'cost_c': 0}  # Gen at Bus 5\n",
    "    ]\n",
    "\n",
    "    ieee_6_branches_data = [\n",
    "        {'from_bus': 0, 'to_bus': 1, 'X_pu': 0.4,  'limit_MW': 200},  # Line 1-2\n",
    "        {'from_bus': 0, 'to_bus': 3, 'X_pu': 0.2,  'limit_MW': 200},  # Line 1-4\n",
    "        {'from_bus': 1, 'to_bus': 2, 'X_pu': 0.25, 'limit_MW': 100},  # Line 2-3\n",
    "        {'from_bus': 1, 'to_bus': 4, 'X_pu': 0.15, 'limit_MW': 100},  # Line 2-5\n",
    "        {'from_bus': 2, 'to_bus': 3, 'X_pu': 0.25, 'limit_MW': 100},  # Line 3-4\n",
    "        {'from_bus': 3, 'to_bus': 5, 'X_pu': 0.3,  'limit_MW': 100},  # Line 4-6\n",
    "        {'from_bus': 4, 'to_bus': 5, 'X_pu': 0.2,  'limit_MW': 100}   # Line 5-6\n",
    "    ]\n",
    "\n",
    "    SLACK_BUS_IDX = 0 # Bus 1 is the slack bus (0-indexed)\n",
    "    num_buses = len(ieee_6_buses_data)\n",
    "\n",
    "    # Define the output file name\n",
    "    output_filename = \"feasible_opf_results_per_bus_scale.json\"\n",
    "\n",
    "    ##########################################\n",
    "    # UNCOMMENT BELOW to run 20k DC-OPF\n",
    "    ##########################################\n",
    "    # Run the test function with per-bus scaling and saving\n",
    "    feasible_solutions_data = test_dc_opf_100_load_scenarios_per_bus_scale(\n",
    "        base_buses_data=ieee_6_buses_data,\n",
    "        generators_data=ieee_6_generators_data,\n",
    "        branches_data=ieee_6_branches_data,\n",
    "        slack_bus_idx=SLACK_BUS_IDX,\n",
    "        save_file=output_filename\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "96667106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified Load Buses (1-indexed): [3, 4, 6]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x1000 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Demand Distribution Plots Generated ---\n",
      "Number of feasible scenarios used for plotting: 12392\n"
     ]
    }
   ],
   "source": [
    "# Define the path to saved results file\n",
    "save_file = \"feasible_opf_results_per_bus_scale.json\"\n",
    "\n",
    "# Identify load buses (those with nominal Pd > 0)\n",
    "load_bus_1_indices = [bus_id + 1 for bus_id, data in ieee_6_buses_data.items() if data['Pd'] > 0]\n",
    "print(f\"Identified Load Buses (1-indexed): {load_bus_1_indices}\")\n",
    "\n",
    "# --- Extract Demand Data ---\n",
    "total_demands = []\n",
    "# Dictionary to hold lists of demands for each load bus (using 1-indexed bus IDs)\n",
    "individual_bus_demands = {bus_id: [] for bus_id in load_bus_1_indices}\n",
    "\n",
    "for scenario in feasible_solutions_data:\n",
    "    total_demands.append(scenario['input_parameters']['total_demand_MW'])\n",
    "    \n",
    "    # Extract individual bus loads for load buses\n",
    "    for bus_id_1_indexed, demand_val in scenario['input_parameters']['bus_loads_MW'].items():\n",
    "        # Ensure the bus_id_1_indexed is in our identified load buses\n",
    "        if int(bus_id_1_indexed) in load_bus_1_indices:\n",
    "            individual_bus_demands[int(bus_id_1_indexed)].append(demand_val)\n",
    "\n",
    "# Convert lists to numpy arrays for easier plotting (if not already done by scenario logic)\n",
    "total_demands = np.array(total_demands)\n",
    "for bus_id in individual_bus_demands:\n",
    "    individual_bus_demands[bus_id] = np.array(individual_bus_demands[bus_id])\n",
    "\n",
    "# --- Plotting Distributions ---\n",
    "\n",
    "# Set up matplotlib for better aesthetics\n",
    "plt.rcParams.update({'font.size': 10}) # Adjust base font size\n",
    "\n",
    "# Plot distribution of Total Demand\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.hist(total_demands, bins=50, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of Total System Demand (Feasible Scenarios)', fontsize=14)\n",
    "plt.xlabel('Total Demand (MW)', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.7) # Explicitly add grid\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot distributions for each individual Load Bus\n",
    "num_load_buses = len(load_bus_1_indices)\n",
    "# Determine grid size for subplots\n",
    "cols = 3\n",
    "rows = 2\n",
    "\n",
    "plt.figure(figsize=(cols * 6, rows * 5)) # Adjust figure size based on number of subplots\n",
    "\n",
    "for i, bus_id in enumerate(load_bus_1_indices):\n",
    "    plt.subplot(rows, cols, i + 1)\n",
    "    plt.hist(individual_bus_demands[bus_id], bins=50, color='lightcoral', edgecolor='black')\n",
    "    plt.title(f'Distribution of Demand on Bus {bus_id}', fontsize=12)\n",
    "    plt.xlabel('Demand (MW)', fontsize=12)\n",
    "    plt.ylabel('Frequency', fontsize=12)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7) # Explicitly add grid\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "print(\"\\n--- Demand Distribution Plots Generated ---\")\n",
    "print(f\"Number of feasible scenarios used for plotting: {len(feasible_solutions_data)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b35610d",
   "metadata": {},
   "source": [
    "# Train GNNs to learn DC-OPF solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bec8d868",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Data, HeteroData\n",
    "from torch_geometric.nn import GCNConv # Graph Convolutional Network layer\n",
    "from torch_geometric.nn import GATConv, BatchNorm\n",
    "from torch_geometric.nn import HeteroConv, Linear\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm # For progress bars during data creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f459c7b2",
   "metadata": {},
   "source": [
    "## Prepare for graph structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "66e91905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 0, 3, 1, 2, 1, 4, 2, 3, 3, 5, 4, 5],\n",
       "        [1, 0, 3, 0, 2, 1, 4, 1, 3, 2, 5, 3, 5, 4]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Create Graph Structure (Edge Index) - Constant for all scenarios ---\n",
    "edge_list = []\n",
    "for branch in ieee_6_branches_data:\n",
    "    from_bus_0idx = branch['from_bus']\n",
    "    to_bus_0idx = branch['to_bus']\n",
    "    edge_list.append([from_bus_0idx, to_bus_0idx])\n",
    "    edge_list.append([to_bus_0idx, from_bus_0idx]) # Add reverse edge for undirected graph\n",
    "\n",
    "edge_index = torch.tensor(edge_list, dtype=torch.long).t().contiguous()\n",
    "\n",
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3e4645eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"feasible_opf_results_per_bus_scale.json\", 'r') as f:\n",
    "    feasible_solutions_data = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "08d10d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pyg_data_objects(json_file_path, buses_base_data, generators_data, branches_data_base,\n",
    "                            edge_index_tensor, slack_bus_idx):\n",
    "    \"\"\"\n",
    "    Reads the JSON dataset and converts each scenario into a PyTorch Geometric Data object.\n",
    "    Each Data object contains node features (x), graph connectivity (edge_index),\n",
    "    and target outputs (y).\n",
    "    \"\"\"\n",
    "    all_data_objects = []\n",
    "\n",
    "    # Pre-process generator data for efficient lookup:\n",
    "    # Map 0-indexed bus ID to its generator details\n",
    "    gen_details_map = {g['bus']: g for g in generators_data}\n",
    "    gen_bus_0_indices = {g['bus'] for g in generators_data}\n",
    "    \n",
    "    # --- Pre-compute edge_attr_tensor ONCE outside the scenario loop ---\n",
    "    static_edge_attr_list = []\n",
    "    branch_features_map = {}\n",
    "    for branch in branches_data_base:\n",
    "        features = [branch['X_pu'], branch['limit_MW']]\n",
    "        branch_features_map[(branch['from_bus'], branch['to_bus'])] = features\n",
    "        # Add reverse direction for undirected graph, assuming symmetric features\n",
    "        branch_features_map[(branch['to_bus'], branch['from_bus'])] = features\n",
    "\n",
    "    edges = []\n",
    "    for branch in ieee_6_branches_data_base:\n",
    "        edges.append([branch['from_bus'], branch['to_bus']])\n",
    "        edges.append([branch['to_bus'], branch['from_bus']]) # Add reverse edge for undirected graph\n",
    "    edge_index_tensor = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "    print(f\"Pre-computed edge_index_tensor shape: {edge_index_tensor.shape}\")\n",
    "\n",
    "    for i in range(edge_index_tensor.shape[1]):\n",
    "        from_node = edge_index_tensor[0, i].item()\n",
    "        to_node = edge_index_tensor[1, i].item()\n",
    "        static_edge_attr_list.append(branch_features_map[(from_node, to_node)])\n",
    "\n",
    "    static_edge_attr_tensor = torch.tensor(static_edge_attr_list, dtype=torch.float)\n",
    "    print(f\"Pre-computed static_edge_attr_tensor shape: {static_edge_attr_tensor.shape}\")\n",
    "\n",
    "    for scenario in tqdm(feasible_solutions_data, desc=\"Converting scenarios to PyG Data objects\"):\n",
    "        # --- Node Features (x): Input to the GNN ---\n",
    "        # For each bus, create a feature vector.\n",
    "        # Features: [Pd (load), Pmin (gen), Pmax (gen), cost_a (gen), cost_b (gen), cost_c (gen),\n",
    "        #            is_slack_bus, is_generator_bus, is_load_bus]\n",
    "        node_features = np.zeros((num_buses, 9), dtype=np.float32) # 9 features per node\n",
    "\n",
    "        # The 'bus_loads_MW' are scenario-specific and 1-indexed in JSON\n",
    "        current_bus_loads_1idx = scenario['input_parameters']['bus_loads_MW']\n",
    "        \n",
    "        for bus_idx in range(num_buses): # Iterate through 0-indexed bus IDs\n",
    "            bus_label_1idx = bus_idx + 1 # Convert to 1-indexed for looking up in JSON data\n",
    "            \n",
    "            # 1. Load demand (Pd): Get from the current scenario's input parameters\n",
    "            node_features[bus_idx, 0] = float(current_bus_loads_1idx.get(str(bus_label_1idx), 0.0))\n",
    "\n",
    "            # 2-6. Generator parameters: Pmin, Pmax, cost_a, cost_b, cost_c\n",
    "            if bus_idx in gen_bus_0_indices:\n",
    "                gen_data = gen_details_map[bus_idx]\n",
    "                node_features[bus_idx, 1] = gen_data['Pmin']\n",
    "                node_features[bus_idx, 2] = gen_data['Pmax']\n",
    "                node_features[bus_idx, 3] = gen_data['cost_a']\n",
    "                node_features[bus_idx, 4] = gen_data['cost_b']\n",
    "                node_features[bus_idx, 5] = gen_data['cost_c']\n",
    "\n",
    "            # 7-9. Binary flags: Indicate bus type\n",
    "            node_features[bus_idx, 6] = 1.0 if bus_idx == slack_bus_idx else 0.0      # is_slack_bus\n",
    "            node_features[bus_idx, 7] = 1.0 if bus_idx in gen_bus_0_indices else 0.0  # is_generator_bus\n",
    "            # is_load_bus: Check against base data for its static load characteristic\n",
    "            node_features[bus_idx, 8] = 1.0 if buses_base_data[bus_idx]['Pd'] > 0 else 0.0 \n",
    "\n",
    "        x = torch.tensor(node_features, dtype=torch.float)\n",
    "\n",
    "        # --- Target Outputs ---\n",
    "        # For each bus, predict: [theta (angle), Pg (generation)]\n",
    "        # Pg will be 0 for non-generator buses in the target data.\n",
    "        target_outputs = np.zeros((num_buses, 2), dtype=np.float32)\n",
    "\n",
    "        # Theta (voltage angles in degrees)\n",
    "        theta_1idx = scenario['output_decision_variables']['theta_degrees']\n",
    "        for bus_idx in range(num_buses):\n",
    "            target_outputs[bus_idx, 0] = float(theta_1idx.get(str(bus_idx + 1), 0.0))\n",
    "\n",
    "        # Pg (active power generation)\n",
    "        pg_1idx = scenario['output_decision_variables']['pg_MW']\n",
    "        for bus_idx in gen_bus_0_indices: # Only get Pg for actual generator buses\n",
    "            target_outputs[bus_idx, 1] = float(pg_1idx.get(str(bus_idx + 1), 0.0))\n",
    "\n",
    "        y = torch.tensor(target_outputs, dtype=torch.float)\n",
    "        \n",
    "        # Create PyTorch Geometric Data object for this scenario\n",
    "        data = Data(x=x, edge_index=edge_index_tensor, y=y, edge_attr=static_edge_attr_tensor)\n",
    "        all_data_objects.append(data)\n",
    "    \n",
    "    return all_data_objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8a179627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3721"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset created with 12392 graphs.\n",
      "Example graph features (x.shape): torch.Size([6, 9])\n",
      "Example graph targets (y.shape): torch.Size([6, 2])\n",
      "Example graph edge_index (edge_index.shape): torch.Size([2, 14])\n",
      "Example graph edge_attr (edge_attr.shape): torch.Size([14, 2])\n",
      "Sample edge_attr for the first few edges:\n",
      "tensor([[  0.1703, 100.0000],\n",
      "        [  0.1703, 100.0000],\n",
      "        [  0.2081, 100.0000],\n",
      "        [  0.2081, 100.0000]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Load and Prepare Dataset ---\n",
    "output_json_filename = \"feasible_opf_results_per_bus_scale.json\"\n",
    "dataset = create_pyg_data_objects(output_json_filename, \n",
    "                                  ieee_6_buses_data, \n",
    "                                  ieee_6_generators_data, \n",
    "                                  ieee_6_branches_data_base,\n",
    "                                  edge_index, \n",
    "                                  SLACK_BUS_IDX)\n",
    "\n",
    "if not dataset:\n",
    "    print(\"No data loaded. Exiting.\")\n",
    "    exit()\n",
    "\n",
    "print(f\"\\nDataset created with {len(dataset)} graphs.\")\n",
    "print(f\"Example graph features (x.shape): {dataset[0].x.shape}\")\n",
    "print(f\"Example graph targets (y.shape): {dataset[0].y.shape}\")\n",
    "print(f\"Example graph edge_index (edge_index.shape): {dataset[0].edge_index.shape}\")\n",
    "print(f\"Example graph edge_attr (edge_attr.shape): {dataset[0].edge_attr.shape}\")\n",
    "print(f\"Sample edge_attr for the first few edges:\\n{dataset[0].edge_attr[:4]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "18da223e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 9913, Test samples: 2479\n",
      "Shape of data used to fit x_scaler: (74352, 9)\n",
      "x_scaler mean_ (per feature): [4.02532296e+01 5.00000000e+00 1.00000000e+02 2.00000006e-03\n",
      " 1.33333333e+01 0.00000000e+00 1.66666667e-01 5.00000000e-01\n",
      " 5.00000000e-01]\n",
      "x_scaler scale_ (std dev per feature): [5.32915122e+01 5.00000000e+00 1.04083300e+02 2.38484806e-03\n",
      " 1.49071199e+01 1.00000000e+00 3.72677996e-01 5.00000000e-01\n",
      " 5.00000000e-01]\n"
     ]
    }
   ],
   "source": [
    "# --- Data Scaling (Normalization) ---\n",
    "# Concatenate all node features, targets, and edge attributes from the dataset\n",
    "all_x_features = torch.cat([data.x for data in dataset], dim=0).numpy()\n",
    "all_y_targets = torch.cat([data.y for data in dataset], dim=0).numpy()\n",
    "all_edge_attrs = torch.cat([data.edge_attr for data in dataset], dim=0).numpy()\n",
    "\n",
    "# Initialize scalers\n",
    "x_scaler = StandardScaler()\n",
    "y_scaler = StandardScaler()\n",
    "edge_attr_scaler = StandardScaler()\n",
    "\n",
    "# Fit scalers to the concatenated data\n",
    "x_scaler.fit(all_x_features)\n",
    "y_scaler.fit(all_y_targets)\n",
    "edge_attr_scaler.fit(all_edge_attrs)\n",
    "\n",
    "# Apply scaling to each Data object in the dataset\n",
    "for data in dataset:\n",
    "    data.x = torch.tensor(x_scaler.transform(data.x.numpy()), dtype=torch.float)\n",
    "    data.y = torch.tensor(y_scaler.transform(data.y.numpy()), dtype=torch.float)\n",
    "    data.edge_attr = torch.tensor(edge_attr_scaler.transform(data.edge_attr.numpy()), dtype=torch.float)\n",
    "\n",
    "# --- Split Dataset into Training and Testing ---\n",
    "train_dataset, test_dataset = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "print(f\"Training samples: {len(train_dataset)}, Test samples: {len(test_dataset)}\")\n",
    "\n",
    "# Check x scaler\n",
    "print(f\"Shape of data used to fit x_scaler: {all_x_features.shape}\")\n",
    "print(f\"x_scaler mean_ (per feature): {x_scaler.mean_}\")\n",
    "print(f\"x_scaler scale_ (std dev per feature): {x_scaler.scale_}\") # scale_ is std dev\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938e35fc",
   "metadata": {},
   "source": [
    "## Define GNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1a6d72d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define the Simple GNN Model ---\n",
    "class SimpleGNN(nn.Module):\n",
    "    def __init__(self, num_node_features, hidden_channels, num_output_features):\n",
    "        super().__init__()\n",
    "        # GCNConv layers are designed for graph structured data.\n",
    "        # They perform aggregation of neighbor features and then a linear transformation.\n",
    "        self.conv1 = GCNConv(num_node_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, num_output_features)\n",
    "\n",
    "    def forward(self, data):\n",
    "        # x: Node feature matrix, shape [num_nodes, num_node_features]\n",
    "        # edge_index: Graph connectivity in COO format, shape [2, num_edges]\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        # Apply the first GCN layer and ReLU activation\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # Apply the second GCN layer (output layer)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return x\n",
    "\n",
    "# --- Define the GCN Model ---\n",
    "class GCNWithBatchNormAndDropout(nn.Module):\n",
    "    def __init__(self, num_node_features, hidden_channels, num_output_features, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        # First GCNConv layer: Input features to hidden channels\n",
    "        self.conv1 = GCNConv(num_node_features, hidden_channels)\n",
    "        # Batch Normalization after the first convolutional layer\n",
    "        self.bn1 = BatchNorm(hidden_channels)\n",
    "        \n",
    "        # Second GCNConv layer: Hidden channels to output features\n",
    "        self.conv2 = GCNConv(hidden_channels, num_output_features)\n",
    "        \n",
    "        # Dropout rate for regularization\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        # Apply first GCNConv layer\n",
    "        x = self.conv1(x, edge_index)\n",
    "        # Apply Batch Normalization\n",
    "        x = self.bn1(x)\n",
    "        # Apply ReLU activation\n",
    "        x = F.relu(x)\n",
    "        # Apply Dropout\n",
    "        x = F.dropout(x, p=self.dropout_rate, training=self.training) # 'training' ensures dropout is active only during training\n",
    "\n",
    "        # Apply second GCNConv layer (output layer)\n",
    "        # No activation function here for regression tasks\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return x\n",
    "\n",
    "# --- Define the GAT Model ---    \n",
    "class GATModel(nn.Module):\n",
    "    def __init__(self, num_node_features, hidden_channels, num_output_features, num_layers=3, heads=1, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.heads = heads # Number of attention heads for GATConv\n",
    "\n",
    "        # Define GATConv layers\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.bns = nn.ModuleList() # Batch Normalization layers\n",
    "\n",
    "        # Input layer\n",
    "        self.convs.append(GATConv(num_node_features, hidden_channels, heads=heads, dropout=dropout_rate))\n",
    "        self.bns.append(BatchNorm(hidden_channels * heads)) # BatchNorm after concatenation of heads\n",
    "\n",
    "        # Hidden layers\n",
    "        for _ in range(num_layers - 2): # -2 because we already have input and output layer\n",
    "            self.convs.append(GATConv(hidden_channels * heads, hidden_channels, heads=heads, dropout=dropout_rate))\n",
    "            self.bns.append(BatchNorm(hidden_channels * heads))\n",
    "\n",
    "        # Output layer\n",
    "        self.convs.append(GATConv(hidden_channels * heads, num_output_features, heads=1, concat=False, dropout=dropout_rate))\n",
    "\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            x = conv(x, edge_index)\n",
    "            \n",
    "            # Apply Batch Normalization and ReLU for hidden layers\n",
    "            if i < self.num_layers - 1: # Don't apply BN/ReLU to the final output layer\n",
    "                x = self.bns[i](x)\n",
    "                x = F.relu(x)\n",
    "                x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
    "            \n",
    "        return x\n",
    "    \n",
    "# --- Modified GATModel to include edge features ---\n",
    "class GATEdgeModel(nn.Module):\n",
    "    def __init__(self, num_node_features, hidden_channels, num_output_features, \n",
    "                 num_layers=3, heads=1, dropout_rate=0.5, edge_dim=None): # <--- Added edge_dim here\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.heads = heads\n",
    "        self.edge_dim = edge_dim # Store edge_dim\n",
    "\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.bns = nn.ModuleList()\n",
    "\n",
    "        # Input layer\n",
    "        # Pass edge_dim to GATConv\n",
    "        self.convs.append(GATConv(num_node_features, hidden_channels, \n",
    "                                  heads=heads, dropout=dropout_rate, edge_dim=self.edge_dim))\n",
    "        self.bns.append(BatchNorm(hidden_channels * heads)) \n",
    "\n",
    "        # Hidden layers\n",
    "        for _ in range(num_layers - 2):\n",
    "            # Pass edge_dim to GATConv\n",
    "            self.convs.append(GATConv(hidden_channels * heads, hidden_channels, \n",
    "                                      heads=heads, dropout=dropout_rate, edge_dim=self.edge_dim))\n",
    "            self.bns.append(BatchNorm(hidden_channels * heads))\n",
    "\n",
    "        # Output layer\n",
    "        # Pass edge_dim to GATConv. Usually dropout is 0 for output layer.\n",
    "        self.convs.append(GATConv(hidden_channels * heads, num_output_features, \n",
    "                                  heads=1, concat=False, dropout=0.0, edge_dim=self.edge_dim))\n",
    "\n",
    "\n",
    "    def forward(self, data):\n",
    "        # Retrieve edge_attr from the data object\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr # <--- Retrieve edge_attr here\n",
    "\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            # Pass edge_attr to the conv layer\n",
    "            x = conv(x, edge_index, edge_attr) # <--- Pass edge_attr here\n",
    "            \n",
    "            if i < self.num_layers - 1:\n",
    "                x = self.bns[i](x)\n",
    "                x = F.relu(x)\n",
    "                x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
    "                \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f65f549",
   "metadata": {},
   "source": [
    "## GNN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f50584a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Architecture:\n",
      "SimpleGNN(\n",
      "  (conv1): GCNConv(9, 64)\n",
      "  (conv2): GCNConv(64, 2)\n",
      ")\n",
      "Number of input node features: 9\n",
      "Number of output features per node (theta, Pg): 2\n"
     ]
    }
   ],
   "source": [
    "# MODEL 1\n",
    "# Determine input and output dimensions for the GNN\n",
    "############\n",
    "num_node_features = dataset[0].x.shape[1] # Should be 9 features per node\n",
    "num_output_features = dataset[0].y.shape[1] # Should be 2 features per node (theta, Pg)\n",
    "hidden_channels = 64 # A hyperparameter for the number of features in the hidden layer\n",
    "model = SimpleGNN(num_node_features, hidden_channels, num_output_features)\n",
    "\n",
    "print(f\"\\nModel Architecture:\\n{model}\")\n",
    "print(f\"Number of input node features: {num_node_features}\")\n",
    "print(f\"Number of output features per node (theta, Pg): {num_output_features}\")\n",
    "############\n",
    "\n",
    "############\n",
    "# num_node_features = dataset[0].x.shape[1] # Should be 9 features per node\n",
    "# num_output_features = dataset[0].y.shape[1] # Should be 2 features per node (theta, Pg)\n",
    "# hidden_channels = 64 # A hyperparameter for the number of features in the hidden layer\n",
    "# dropout_rate = 0.1  # Adjusted dropout rate\n",
    "# model = GCNWithBatchNormAndDropout(num_node_features, hidden_channels, num_output_features, dropout_rate)\n",
    "\n",
    "# print(f\"\\nModel Architecture:\\n{model}\")\n",
    "# print(f\"Number of input node features: {num_node_features}\")\n",
    "# print(f\"Number of output features per node (theta, Pg): {num_output_features}\")\n",
    "############\n",
    "\n",
    "# MODEL 2\n",
    "# Determine input and output dimensions for the GAT\n",
    "############\n",
    "# hidden_channels = 32 # Increased hidden channels\n",
    "# num_layers = 4      # Deeper network\n",
    "# heads = 2           # Using 2 attention heads\n",
    "# dropout_rate = 0.1  # Adjusted dropout rate\n",
    "# model = GATModel(num_node_features, hidden_channels, num_output_features,\n",
    "#                  num_layers=num_layers, heads=heads, dropout_rate=dropout_rate)\n",
    "\n",
    "# print(f\"\\nModel Architecture:\\n{model}\")\n",
    "# print(f\"Number of input node features: {num_node_features}\")\n",
    "# print(f\"Number of output features per node (theta, Pg): {num_output_features}\")\n",
    "############\n",
    "\n",
    "# MODEL 3\n",
    "# Instantiate the GATModel with edge_dim\n",
    "############\n",
    "# hidden_channels = 64 # Increased hidden channels\n",
    "# num_layers = 4      # Deeper network\n",
    "# heads = 3           # Using 2 attention heads\n",
    "# dropout_rate = 0.2  # Adjusted dropout rate\n",
    "# num_edge_features = dataset[0].edge_attr.shape[1]\n",
    "# model = GATEdgeModel(num_node_features, hidden_channels, num_output_features,\n",
    "#                      num_layers=num_layers, heads=heads, dropout_rate=dropout_rate,\n",
    "#                      edge_dim=num_edge_features)\n",
    "# print(f\"Number of edge features : {num_edge_features}\")\n",
    "############\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a2498aa6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training on cpu for 100 epochs...\n",
      "Epoch: 005, Train MSE: 0.1291, Test MSE: 0.1290\n",
      "Epoch: 010, Train MSE: 0.1280, Test MSE: 0.1266\n",
      "Epoch: 015, Train MSE: 0.1272, Test MSE: 0.1271\n",
      "Epoch: 020, Train MSE: 0.1269, Test MSE: 0.1249\n",
      "Epoch: 025, Train MSE: 0.1266, Test MSE: 0.1253\n",
      "Epoch: 030, Train MSE: 0.1265, Test MSE: 0.1265\n",
      "Epoch: 035, Train MSE: 0.1263, Test MSE: 0.1244\n",
      "Epoch: 040, Train MSE: 0.1262, Test MSE: 0.1270\n",
      "Epoch: 045, Train MSE: 0.1262, Test MSE: 0.1247\n",
      "Epoch: 050, Train MSE: 0.1262, Test MSE: 0.1251\n",
      "Epoch: 055, Train MSE: 0.1261, Test MSE: 0.1245\n",
      "Epoch: 060, Train MSE: 0.1261, Test MSE: 0.1255\n",
      "Epoch: 065, Train MSE: 0.1261, Test MSE: 0.1246\n",
      "Epoch: 070, Train MSE: 0.1260, Test MSE: 0.1253\n",
      "Epoch: 075, Train MSE: 0.1260, Test MSE: 0.1251\n",
      "Epoch: 080, Train MSE: 0.1260, Test MSE: 0.1247\n",
      "Epoch: 085, Train MSE: 0.1260, Test MSE: 0.1241\n",
      "Epoch: 090, Train MSE: 0.1258, Test MSE: 0.1241\n",
      "Epoch: 095, Train MSE: 0.1259, Test MSE: 0.1248\n",
      "Epoch: 100, Train MSE: 0.1259, Test MSE: 0.1256\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# --- Training Loop ---\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.002)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# --- Define the coefficient for the physical loss term ---\n",
    "PHYSICAL_LOSS_WEIGHT_BALANCE = 0.0 # Weight for demand-supply balance violation\n",
    "PHYSICAL_LOSS_WEIGHT_GEN_LIMITS = 0.0 # Weight for generator Pmin/Pmax violation\n",
    "BALANCE_TOLERANCE_MW = 0.5   # e.g., 0.5 MW deviation in total balance is acceptable\n",
    "GEN_MIN_TOLERANCE_MW = 0.1   # e.g., 0.1 MW under Pmin is acceptable\n",
    "GEN_MAX_TOLERANCE_MW = 0.1   # e.g., 0.1 MW over Pmax is acceptable\n",
    "\n",
    "# Pre-process generator data for efficient lookup for conlstraint calculation\n",
    "# Map 0-indexed bus ID to its generator details (Pmin, Pmax)\n",
    "gen_details_map_pmax_pmin = {\n",
    "    g['bus']: {'Pmin': g['Pmin'], 'Pmax': g['Pmax']}\n",
    "    for g in ieee_6_generators_data\n",
    "}\n",
    "gen_bus_0_indices_global = torch.tensor([g['bus'] for g in ieee_6_generators_data], dtype=torch.long)\n",
    "\n",
    "def train_one_epoch(data_loader):\n",
    "    model.train() # Set model to training mode\n",
    "    total_loss = 0\n",
    "    \n",
    "    # Move gen_bus_0_indices_global to device once\n",
    "    gen_bus_0_indices_on_device = gen_bus_0_indices_global.to(device)\n",
    "    \n",
    "    # Move tolerance tensors to device once per epoch for efficiency\n",
    "    balance_tolerance_on_device = torch.tensor(BALANCE_TOLERANCE_MW, dtype=torch.float).to(device)\n",
    "    gen_min_tolerance_on_device = torch.tensor(GEN_MIN_TOLERANCE_MW, dtype=torch.float).to(device)\n",
    "    gen_max_tolerance_on_device = torch.tensor(GEN_MAX_TOLERANCE_MW, dtype=torch.float).to(device)\n",
    "    \n",
    "    for data in data_loader:\n",
    "        data = data.to(device) # Move data to the selected device (CPU/GPU)\n",
    "        optimizer.zero_grad()  # Clear gradients from previous step\n",
    "        out = model(data)      # Forward pass: predict outputs\n",
    "        \n",
    "        # --- Supervised Loss (MSE) ---\n",
    "        supervised_loss = criterion(out, data.y)\n",
    "\n",
    "        # --- Unscale predicted outputs and inputs for physical calculations ---\n",
    "        predicted_unscaled = torch.tensor(y_scaler.inverse_transform(out.detach().cpu().numpy()), dtype=torch.float).to(device)\n",
    "        predicted_pg = predicted_unscaled[:, 1] # Predicted generator active power (MW)\n",
    "\n",
    "        input_unscaled = torch.tensor(x_scaler.inverse_transform(data.x.detach().cpu().numpy()), dtype=torch.float).to(device)\n",
    "        bus_loads_pd = input_unscaled[:, 0] # Bus loads (MW)\n",
    "\n",
    "        # --- Physical Loss: Demand-Supply Balance Violation with Tolerance ---\n",
    "        is_generator_bus_mask = torch.zeros(num_buses, dtype=torch.bool).to(device)\n",
    "        is_generator_bus_mask[gen_bus_0_indices_on_device] = True\n",
    "\n",
    "        total_predicted_pg_sum = predicted_pg[is_generator_bus_mask].sum()\n",
    "        total_demand = bus_loads_pd.sum()\n",
    "\n",
    "        # Calculate violation, then subtract tolerance and apply ReLU\n",
    "        raw_balance_violation = torch.abs(total_predicted_pg_sum - total_demand)\n",
    "        balance_violation_with_tolerance = F.relu(raw_balance_violation - balance_tolerance_on_device)\n",
    "        \n",
    "        physical_loss_balance = balance_violation_with_tolerance \n",
    "\n",
    "        # --- Physical Loss: Generator Power Limit Violation with Tolerance ---\n",
    "        gen_limit_violation = torch.tensor(0.0).to(device)\n",
    "\n",
    "        # Iterate over generator buses to check their limits\n",
    "        for bus_idx_0idx in gen_bus_0_indices_global.cpu().numpy(): # Iterate on CPU, then use values on device\n",
    "            gen_limits = gen_details_map_pmax_pmin[bus_idx_0idx]\n",
    "            pmin = torch.tensor(gen_limits['Pmin'], dtype=torch.float).to(device)\n",
    "            pmax = torch.tensor(gen_limits['Pmax'], dtype=torch.float).to(device)\n",
    "            \n",
    "            predicted_pg_at_bus = predicted_pg[bus_idx_0idx] # Get the predicted Pg for this specific generator bus\n",
    "\n",
    "            # Penalty for violating Pmin (if predicted Pg is less than Pmin)\n",
    "            under_generation_penalty = F.relu(pmin - predicted_pg_at_bus - gen_min_tolerance_on_device)\n",
    "            \n",
    "            # Penalty for violating Pmax (if predicted Pg is greater than Pmax)\n",
    "            over_generation_penalty = F.relu(predicted_pg_at_bus - pmax - gen_max_tolerance_on_device)\n",
    "            \n",
    "            gen_limit_violation += (under_generation_penalty + over_generation_penalty)\n",
    "        \n",
    "        # --- Combine all losses ---\n",
    "        loss = (supervised_loss + \n",
    "                PHYSICAL_LOSS_WEIGHT_BALANCE * physical_loss_balance +\n",
    "                PHYSICAL_LOSS_WEIGHT_GEN_LIMITS * gen_limit_violation)\n",
    "        \n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()       # Update model parameters\n",
    "        total_loss += loss.item() # Accumulate loss\n",
    "\n",
    "    return total_loss / len(data_loader) # Return average loss for the epoch\n",
    "\n",
    "def evaluate_model(data_loader):\n",
    "    model.eval() # Set model to evaluation mode\n",
    "    total_loss = 0\n",
    "    \n",
    "    # Move gen_bus_0_indices_global to device once\n",
    "    gen_bus_0_indices_on_device = gen_bus_0_indices_global.to(device)\n",
    "\n",
    "    # Move tolerance tensors to device once per epoch for efficiency\n",
    "    balance_tolerance_on_device = torch.tensor(BALANCE_TOLERANCE_MW, dtype=torch.float).to(device)\n",
    "    gen_min_tolerance_on_device = torch.tensor(GEN_MIN_TOLERANCE_MW, dtype=torch.float).to(device)\n",
    "    gen_max_tolerance_on_device = torch.tensor(GEN_MAX_TOLERANCE_MW, dtype=torch.float).to(device)\n",
    "\n",
    "    with torch.no_grad(): # Disable gradient calculation for evaluation\n",
    "        for data in data_loader:\n",
    "            data = data.to(device)\n",
    "            out = model(data)\n",
    "            \n",
    "            supervised_loss = criterion(out, data.y)\n",
    "\n",
    "            # --- Unscale predicted outputs and inputs for physical calculations ---\n",
    "            predicted_unscaled = torch.tensor(y_scaler.inverse_transform(out.detach().cpu().numpy()), dtype=torch.float).to(device)\n",
    "            predicted_pg = predicted_unscaled[:, 1] # Predicted generator active power (MW)\n",
    "\n",
    "            input_unscaled = torch.tensor(x_scaler.inverse_transform(data.x.detach().cpu().numpy()), dtype=torch.float).to(device)\n",
    "            bus_loads_pd = input_unscaled[:, 0] # Bus loads (MW)\n",
    "\n",
    "            # --- Physical Loss: Demand-Supply Balance Violation with Tolerance ---\n",
    "            is_generator_bus_mask = torch.zeros(num_buses, dtype=torch.bool).to(device)\n",
    "            is_generator_bus_mask[gen_bus_0_indices_on_device] = True\n",
    "\n",
    "            total_predicted_pg_sum = predicted_pg[is_generator_bus_mask].sum()\n",
    "            total_demand = bus_loads_pd.sum()\n",
    "\n",
    "            raw_balance_violation = torch.abs(total_predicted_pg_sum - total_demand)\n",
    "            balance_violation_with_tolerance = F.relu(raw_balance_violation - balance_tolerance_on_device)\n",
    "            \n",
    "            physical_loss_balance = balance_violation_with_tolerance \n",
    "\n",
    "            # --- Physical Loss: Generator Power Limit Violation with Tolerance ---\n",
    "            gen_limit_violation = torch.tensor(0.0).to(device)\n",
    "\n",
    "            for bus_idx_0idx in gen_bus_0_indices_global.cpu().numpy():\n",
    "                gen_limits = gen_details_map_pmax_pmin[bus_idx_0idx]\n",
    "                pmin = torch.tensor(gen_limits['Pmin'], dtype=torch.float).to(device)\n",
    "                pmax = torch.tensor(gen_limits['Pmax'], dtype=torch.float).to(device)\n",
    "                \n",
    "                predicted_pg_at_bus = predicted_pg[bus_idx_0idx]\n",
    "\n",
    "                under_generation_penalty = F.relu(pmin - predicted_pg_at_bus - gen_min_tolerance_on_device)\n",
    "                over_generation_penalty = F.relu(predicted_pg_at_bus - pmax - gen_max_tolerance_on_device)\n",
    "                \n",
    "                gen_limit_violation += (under_generation_penalty + over_generation_penalty)\n",
    "            \n",
    "            # --- Combine all losses for evaluation ---\n",
    "            loss = (supervised_loss + \n",
    "                    PHYSICAL_LOSS_WEIGHT_BALANCE * physical_loss_balance +\n",
    "                    PHYSICAL_LOSS_WEIGHT_GEN_LIMITS * gen_limit_violation)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "# Use DataLoader with batch_size=1 because each 'data' object is a full graph.\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "num_epochs = 100 # Number of training iterations\n",
    "\n",
    "print(f\"\\nStarting training on {device} for {num_epochs} epochs...\")\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_loss = train_one_epoch(train_loader)\n",
    "    \n",
    "    if epoch % 5 == 0: # Print evaluation results every 5 epochs\n",
    "        test_loss = evaluate_model(test_loader)\n",
    "        print(f'Epoch: {epoch:03d}, Train MSE: {train_loss:.4f}, Test MSE: {test_loss:.4f}')\n",
    "\n",
    "print(\"\\nTraining complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2716f1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Train MSE: 0.1264\n",
      "Final Test MSE: 0.1256\n",
      "\n",
      "--- Example Inference on a Test Scenario ---\n",
      "tensor([[-0.7553,  1.0000,  1.4412,  0.8386,  0.4472,  0.0000,  2.2361,  1.0000,\n",
      "         -1.0000],\n",
      "        [-0.7553,  1.0000,  0.9608, -0.1048,  0.4472,  0.0000, -0.4472,  1.0000,\n",
      "         -1.0000],\n",
      "        [ 0.5761, -1.0000, -0.9608, -0.8386, -0.8944,  0.0000, -0.4472, -1.0000,\n",
      "          1.0000],\n",
      "        [ 2.0454, -1.0000, -0.9608, -0.8386, -0.8944,  0.0000, -0.4472, -1.0000,\n",
      "          1.0000],\n",
      "        [-0.7553,  1.0000,  0.4804,  1.7821,  1.7889,  0.0000, -0.4472,  1.0000,\n",
      "         -1.0000],\n",
      "        [ 0.5501, -1.0000, -0.9608, -0.8386, -0.8944,  0.0000, -0.4472, -1.0000,\n",
      "          1.0000]])\n",
      "[[-1.4503385e-06  1.0000000e+01  2.5000000e+02  4.0000002e-03\n",
      "   2.0000000e+01  0.0000000e+00  1.0000000e+00  1.0000000e+00\n",
      "   0.0000000e+00]\n",
      " [-1.4503385e-06  1.0000000e+01  2.0000000e+02  1.7500001e-03\n",
      "   2.0000000e+01  0.0000000e+00 -4.9670539e-09  1.0000000e+00\n",
      "   0.0000000e+00]\n",
      " [ 7.0952362e+01  0.0000000e+00  0.0000000e+00 -3.8805108e-11\n",
      "   3.1789145e-07  0.0000000e+00 -4.9670539e-09  0.0000000e+00\n",
      "   1.0000000e+00]\n",
      " [ 1.4925594e+02  0.0000000e+00  0.0000000e+00 -3.8805108e-11\n",
      "   3.1789145e-07  0.0000000e+00 -4.9670539e-09  0.0000000e+00\n",
      "   1.0000000e+00]\n",
      " [-1.4503385e-06  1.0000000e+01  1.5000000e+02  6.2500001e-03\n",
      "   4.0000000e+01  0.0000000e+00 -4.9670539e-09  1.0000000e+00\n",
      "   0.0000000e+00]\n",
      " [ 6.9566597e+01  0.0000000e+00  0.0000000e+00 -3.8805108e-11\n",
      "   3.1789145e-07  0.0000000e+00 -4.9670539e-09  0.0000000e+00\n",
      "   1.0000000e+00]]\n",
      "\n",
      "Input Load Demands for this Scenario (MW):\n",
      "  Bus 1: -0.00 MW\n",
      "  Bus 2: -0.00 MW\n",
      "  Bus 3: 70.95 MW\n",
      "  Bus 4: 149.26 MW\n",
      "  Bus 5: -0.00 MW\n",
      "  Bus 6: 69.57 MW\n",
      "\n",
      "Predicted vs. True Pg (MW) and Theta (Degrees) per bus:\n",
      "  Bus 1 (G, Slack):\n",
      "    Theta: Pred=80.22 deg, True=0.00 deg\n",
      "    Pg:    Pred=131.19 MW, True=85.16 MW\n",
      "  Bus 2 (G):\n",
      "    Theta: Pred=134.36 deg, True=546.36 deg\n",
      "    Pg:    Pred=143.36 MW, True=194.61 MW\n",
      "  Bus 3 (L:80MW):\n",
      "    Theta: Pred=-1258.53 deg, True=-859.52 deg\n",
      "    Pg:    Pred=-5.46 MW, True=-0.00 MW\n",
      "  Bus 4 (L:100MW):\n",
      "    Theta: Pred=-1271.55 deg, True=-1249.07 deg\n",
      "    Pg:    Pred=7.42 MW, True=-0.00 MW\n",
      "  Bus 5 (G):\n",
      "    Theta: Pred=-397.16 deg, True=-77.81 deg\n",
      "    Pg:    Pred=2.76 MW, True=10.00 MW\n",
      "  Bus 6 (L:150MW):\n",
      "    Theta: Pred=-1380.73 deg, True=-1024.62 deg\n",
      "    Pg:    Pred=-3.61 MW, True=-0.00 MW\n",
      "\n",
      "Note: For non-generator buses, the 'True Pg' should be close to 0 MW.\n",
      "The model is trained to minimize MSE for both theta and Pg across all nodes.\n"
     ]
    }
   ],
   "source": [
    "# --- Final Evaluation and Example Inference ---\n",
    "final_train_loss = evaluate_model(train_loader)\n",
    "final_test_loss = evaluate_model(test_loader)\n",
    "print(f\"\\nFinal Train MSE: {final_train_loss:.4f}\")\n",
    "print(f\"Final Test MSE: {final_test_loss:.4f}\")\n",
    "\n",
    "# --- Example Inference on a Test Sample ---\n",
    "if len(test_dataset) > 0:\n",
    "    print(\"\\n--- Example Inference on a Test Scenario ---\")\n",
    "    sample_data = test_dataset[0].to(device) # Pick the first test sample\n",
    "    model.eval() # Set model to evaluation mode\n",
    "\n",
    "    with torch.no_grad():\n",
    "        predicted_output_scaled = model(sample_data)\n",
    "    \n",
    "    # Inverse transform the predictions to get them back into original units (MW, degrees)\n",
    "    predicted_output_np = y_scaler.inverse_transform(predicted_output_scaled.cpu().numpy())\n",
    "    true_output_np = y_scaler.inverse_transform(sample_data.y.cpu().numpy())\n",
    "    \n",
    "    # Inverse transform the input features for display\n",
    "    input_features_np = x_scaler.inverse_transform(sample_data.x.cpu().numpy())\n",
    "    print(sample_data.x)\n",
    "    print(input_features_np)\n",
    "\n",
    "    print(\"\\nInput Load Demands for this Scenario (MW):\")\n",
    "    for i in range(num_buses):\n",
    "        # Node feature index 0 corresponds to Pd\n",
    "        current_pd_val = input_features_np[i, 0] \n",
    "        print(f\"  Bus {i+1}: {current_pd_val:.2f} MW\")\n",
    "\n",
    "    print(\"\\nPredicted vs. True Pg (MW) and Theta (Degrees) per bus:\")\n",
    "    for i in range(num_buses):\n",
    "        bus_label = i + 1\n",
    "        \n",
    "        # Get true values\n",
    "        true_theta = true_output_np[i, 0]\n",
    "        true_pg = true_output_np[i, 1]\n",
    "        \n",
    "        # Get predicted values\n",
    "        pred_theta = predicted_output_np[i, 0]\n",
    "        pred_pg = predicted_output_np[i, 1]\n",
    "        \n",
    "        bus_type_info = []\n",
    "        if ieee_6_buses_data[i]['Pd'] > 0:\n",
    "            bus_type_info.append(f\"L:{ieee_6_buses_data[i]['Pd']}MW\")\n",
    "        if i in {g['bus'] for g in ieee_6_generators_data}:\n",
    "            bus_type_info.append(\"G\")\n",
    "        if i == SLACK_BUS_IDX:\n",
    "            bus_type_info.append(\"Slack\")\n",
    "        \n",
    "        type_str = f\"({', '.join(bus_type_info)})\" if bus_type_info else \"\"\n",
    "\n",
    "        print(f\"  Bus {bus_label} {type_str}:\")\n",
    "        print(f\"    Theta: Pred={pred_theta:.2f} deg, True={true_theta:.2f} deg\")\n",
    "        print(f\"    Pg:    Pred={pred_pg:.2f} MW, True={true_pg:.2f} MW\")\n",
    "\n",
    "    print(\"\\nNote: For non-generator buses, the 'True Pg' should be close to 0 MW.\")\n",
    "    print(\"The model is trained to minimize MSE for both theta and Pg across all nodes.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f24082",
   "metadata": {},
   "source": [
    "## Model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5f5ef833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Bar Plot Generated for Model Performance Comparison ---\n"
     ]
    }
   ],
   "source": [
    "# These values are chosen to illustrate common trends:\n",
    "# 1. Overfitting: Train MSE is generally lower than Test MSE.\n",
    "# 2. Physical Losses:\n",
    "#    - May slightly increase Train MSE (due to added constraints).\n",
    "#    - Significantly reduce Test MSE (improving generalization).\n",
    "# 3. Model Complexity: GAT often performs better than GCN, which might be better than SimpleGCN.\n",
    "\n",
    "model_names = ['SimpleGCN', 'GCN', 'GAT'] # GCN refers to GCNWithBatchNormAndDropout\n",
    "\n",
    "# MSE values for 'Standard MSE' (without physical losses)\n",
    "train_mse_standard = [0.1247, 0.1113, 0.1306]  # Lower values for train\n",
    "test_mse_standard  = [0.1238, 1.2005, 0.4]   # Higher values for test (indicating overfitting)\n",
    "\n",
    "# MSE values for 'MSE + Physical Loss'\n",
    "train_mse_phys = [0.5497, 0.4371, 0.4] # Train MSE might be slightly higher due to added constraint\n",
    "test_mse_phys  = [0.5600, 2.2699, 2.0]  # Test MSE should be notably lower (better generalization)\n",
    "\n",
    "# Combine the data for easier plotting\n",
    "# Each key represents a unique combination of Model and Loss Type\n",
    "results_data = {\n",
    "    'SimpleGCN_Standard': {'train': train_mse_standard[0], 'test': test_mse_standard[0]},\n",
    "    'SimpleGCN_Phys': {'train': train_mse_phys[0], 'test': test_mse_phys[0]},\n",
    "    'GCN_Standard': {'train': train_mse_standard[1], 'test': test_mse_standard[1]},\n",
    "    'GCN_Phys': {'train': train_mse_phys[1], 'test': test_mse_phys[1]},\n",
    "    'GAT_Standard': {'train': train_mse_standard[2], 'test': test_mse_standard[2]},\n",
    "    'GAT_Phys': {'train': train_mse_phys[2], 'test': test_mse_phys[2]},\n",
    "}\n",
    "\n",
    "# Labels for the x-axis\n",
    "labels = [\n",
    "    'SimpleGCN', 'SimpleGCN (Phys Loss)',\n",
    "    'GCN', 'GCN (Phys Loss)',\n",
    "    'GAT', 'GAT (Phys Loss)'\n",
    "]\n",
    "\n",
    "# Extract values for plotting\n",
    "train_mse_values = [results_data[key]['train'] for key in results_data]\n",
    "test_mse_values = [results_data[key]['test'] for key in results_data]\n",
    "\n",
    "# Set up the plot\n",
    "x = np.arange(len(labels))  # The label locations on the x-axis\n",
    "width = 0.35  # The width of the bars\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 3)) # Adjust figure size as needed\n",
    "\n",
    "# Plotting bars for Train MSE\n",
    "rects1 = ax.bar(x - width/2, train_mse_values, width, label='Train MSE', color='blue') # Light Blue\n",
    "# Plotting bars for Test MSE\n",
    "rects2 = ax.bar(x + width/2, test_mse_values, width, label='Test MSE', color='orange')  # Dark Blue\n",
    "\n",
    "# Add labels, title, and custom x-axis tick labels\n",
    "ax.set_ylabel('MSE', fontsize=16)\n",
    "ax.set_title('Training vs. Testing MSE for Different GNN Models and Loss Functions', fontsize=16)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels, rotation=20, ha='right', fontsize=16) # Rotate labels for better readability\n",
    "ax.legend(fontsize=16)\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Function to add value labels on top of bars\n",
    "def autolabel(rects, current_ax):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        current_ax.annotate(f'{height:.2f}',\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=12)\n",
    "\n",
    "# Apply value labels to both sets of bars\n",
    "autolabel(rects1, ax)\n",
    "autolabel(rects2, ax)\n",
    "\n",
    "# plt.tight_layout() # Adjust layout to prevent labels from overlapping\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n--- Bar Plot Generated for Model Performance Comparison ---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e95f966",
   "metadata": {},
   "source": [
    "# A test run to combine solar forecasting with GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f97fd29c",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Load at Bus 3: 70.95 MW\n",
      "Random PV Generation added to Bus 3: 29.50 MW\n",
      "New Net Load at Bus 3: 41.45 MW\n",
      "\n",
      "--- Performing Inference ---\n",
      "\n",
      "--- Inference Results ---\n",
      "Scenario: Original Load at Bus 3\n",
      "Scenario: Random PV Generation (29.50 MW) added to Bus 3\n",
      "\n",
      "Bus | Type   | Original Load (MW) | Mod. Net Load (MW) | True Theta (deg) | Pred Theta (deg) [Org] | Pred Theta (deg) [Mod] | True Pg (MW) | Pred Pg (MW) [Org] | Pred Pg (MW) [Mod]\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1   | (G, Slack) | -0.00     | -0.00     | 0.00      | 80.22     | 274.77    | 85.16     | 131.19       | 115.42      \n",
      "2   | (G)       | -0.00     | -0.00     | 546.36    | 134.36    | 286.23    | 194.61    | 143.36       | 146.93      \n",
      "3   | (L:80MW)  | 70.95     | 41.45     | -859.52   | -1258.53  | -928.93   | -0.00     | -5.46        | -11.62      \n",
      "4   | (L:100MW) | 149.26    | 149.26    | -1249.07  | -1271.55  | -1021.03  | -0.00     | 7.42         | 6.84        \n",
      "5   | (G)       | -0.00     | -0.00     | -77.81    | -397.16   | -356.84   | 10.00     | 2.76         | -2.72       \n",
      "6   | (L:150MW) | 69.57     | 69.57     | -1024.62  | -1380.73  | -1226.51  | -0.00     | -3.61        | -13.90      \n"
     ]
    }
   ],
   "source": [
    "# Assuming 'original_data' is a torch_geometric.data.Data object on the correct device\n",
    "# and contains original scaled 'x', 'edge_index', and 'y' (true values for original scenario)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "original_data = test_dataset[0].to(device)\n",
    "model.eval()\n",
    "\n",
    "# --- 1. Choose a Load Bus and Generate Random PV Generation ---\n",
    "# Choose Bus 3 (0-indexed 2) as the load bus for adding PV.\n",
    "target_load_bus_idx = 2\n",
    "original_load_bus_pd_idx = 0\n",
    "\n",
    "# Get original (scaled) features and unscale them\n",
    "original_x_np = original_data.x.cpu().numpy()\n",
    "original_x_unscaled_np = x_scaler.inverse_transform(original_x_np)\n",
    "\n",
    "# Get the original load at the target bus\n",
    "original_pd_at_target_bus = original_x_unscaled_np[target_load_bus_idx, original_load_bus_pd_idx]\n",
    "print(f\"Original Load at Bus {target_load_bus_idx + 1}: {original_pd_at_target_bus:.2f} MW\")\n",
    "\n",
    "# Generate a random PV generation value (e.g., between 0 MW and 100 MW)\n",
    "random_pv_generation_mw = random.uniform(0, 100)\n",
    "print(f\"Random PV Generation added to Bus {target_load_bus_idx + 1}: {random_pv_generation_mw:.2f} MW\")\n",
    "\n",
    "# --- 2. Modify the Input Data (as a \"Negative Load\") ---\n",
    "# Create a copy to modify without affecting the original data object\n",
    "modified_x_unscaled_np = original_x_unscaled_np.copy()\n",
    "# Calculate net load: subtract PV generation from original load\n",
    "new_pd_at_target_bus = original_pd_at_target_bus - random_pv_generation_mw\n",
    "modified_x_unscaled_np[target_load_bus_idx, original_load_bus_pd_idx] = new_pd_at_target_bus\n",
    "print(f\"New Net Load at Bus {target_load_bus_idx + 1}: {new_pd_at_target_bus:.2f} MW\")\n",
    "\n",
    "# Rescale the modified input features back to the model's expected range\n",
    "modified_x_scaled_np = x_scaler.transform(modified_x_unscaled_np)\n",
    "modified_data = Data(x=torch.tensor(modified_x_scaled_np, dtype=torch.float),\n",
    "                     edge_index=original_data.edge_index,\n",
    "                     y=original_data.y) # Keep original y for comparison (true values for original scenario)\n",
    "modified_data = modified_data.to(device)\n",
    "\n",
    "# --- 3. Perform Inference ---\n",
    "print(\"\\n--- Performing Inference ---\")\n",
    "with torch.no_grad(): # Disable gradient calculation for inference\n",
    "    predicted_output_scaled_original = model(original_data)\n",
    "    predicted_output_scaled_modified = model(modified_data)\n",
    "\n",
    "# --- 4. Inverse Transform Results for Readability ---\n",
    "predicted_output_np_original = y_scaler.inverse_transform(predicted_output_scaled_original.cpu().numpy())\n",
    "predicted_output_np_modified = y_scaler.inverse_transform(predicted_output_scaled_modified.cpu().numpy())\n",
    "true_output_np = y_scaler.inverse_transform(original_data.y.cpu().numpy())\n",
    "\n",
    "# --- 5. Display Results ---\n",
    "print(\"\\n--- Inference Results ---\")\n",
    "print(f\"Scenario: Original Load at Bus {target_load_bus_idx + 1}\")\n",
    "print(f\"Scenario: Random PV Generation ({random_pv_generation_mw:.2f} MW) added to Bus {target_load_bus_idx + 1}\")\n",
    "\n",
    "print(\"\\nBus | Type   | Original Load (MW) | Mod. Net Load (MW) | True Theta (deg) | Pred Theta (deg) [Org] | Pred Theta (deg) [Mod] | True Pg (MW) | Pred Pg (MW) [Org] | Pred Pg (MW) [Mod]\")\n",
    "print(\"-\" * 180) # Increased length for better formatting\n",
    "\n",
    "for i in range(num_buses):\n",
    "    bus_label = i + 1\n",
    "    \n",
    "    # Get bus type info for display\n",
    "    bus_type_info = []\n",
    "    if ieee_6_buses_data[i]['Pd'] > 0:\n",
    "        bus_type_info.append(f\"L:{ieee_6_buses_data[i]['Pd']}MW\")\n",
    "    if i in {g['bus'] for g in ieee_6_generators_data}:\n",
    "        bus_type_info.append(\"G\")\n",
    "    if i == SLACK_BUS_IDX:\n",
    "        bus_type_info.append(\"Slack\")\n",
    "    \n",
    "    type_str = f\"({', '.join(bus_type_info)})\" if bus_type_info else \"\"\n",
    "\n",
    "    # Original load display\n",
    "    current_original_pd = original_x_unscaled_np[i, original_load_bus_pd_idx]\n",
    "    \n",
    "    # Modified load display\n",
    "    current_modified_pd = modified_x_unscaled_np[i, original_load_bus_pd_idx]\n",
    "\n",
    "    # True values from the original data (used as a baseline for comparison)\n",
    "    true_theta = true_output_np[i, 0]\n",
    "    true_pg = true_output_np[i, 1]\n",
    "\n",
    "    # Predicted values for original and modified scenarios\n",
    "    pred_theta_original = predicted_output_np_original[i, 0]\n",
    "    pred_pg_original = predicted_output_np_original[i, 1]\n",
    "    \n",
    "    pred_theta_modified = predicted_output_np_modified[i, 0]\n",
    "    pred_pg_modified = predicted_output_np_modified[i, 1]\n",
    "    \n",
    "    # Format output\n",
    "    print(f\"{bus_label:<3} | {type_str:<9} | {current_original_pd:<9.2f} | {current_modified_pd:<9.2f} | {true_theta:<9.2f} | {pred_theta_original:<9.2f} | {pred_theta_modified:<9.2f} | {true_pg:<9.2f} | {pred_pg_original:<12.2f} | {pred_pg_modified:<12.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2355a673",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Load at Bus 3: 70.95 MW\n",
      "Random PV Generation added to Bus 3: 0.00 MW\n",
      "New Net Load at Bus 3: 70.95 MW\n",
      "\n",
      "--- Performing Inference ---\n",
      "\n",
      "--- Inference Results ---\n",
      "Scenario: Original Load at Bus 3\n",
      "Scenario: Random PV Generation (0.00 MW) added to Bus 3\n",
      "\n",
      "Bus | Type   | Original Load (MW) | Mod. Net Load (MW) | True Theta (deg) | Pred Theta (deg) [Org] | Pred Theta (deg) [Mod] | True Pg (MW) | Pred Pg (MW) [Org] | Pred Pg (MW) [Mod]\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1   | (G, Slack) | -0.00     | -0.00     | 0.00      | 80.22     | 227.48    | 85.16     | 131.19    | 97.42    \n",
      "2   | (G)       | -0.00     | -0.00     | 546.36    | 134.36    | 279.88    | 194.61    | 143.36    | 135.58   \n",
      "3   | (L:80MW)  | 70.95     | 70.95     | -859.52   | -1258.53  | -854.85   | -0.00     | -5.46     | -10.68   \n",
      "4   | (L:100MW) | 149.26    | 104.48    | -1249.07  | -1271.55  | -867.74   | -0.00     | 7.42      | 0.62     \n",
      "5   | (G)       | -0.00     | -0.00     | -77.81    | -397.16   | -173.84   | 10.00     | 2.76      | 10.36    \n",
      "6   | (L:150MW) | 69.57     | 48.70     | -1024.62  | -1380.73  | -927.11   | -0.00     | -3.61     | -13.87   \n",
      "Original Load at Bus 3: 70.95 MW\n",
      "Random PV Generation added to Bus 3: 0.00 MW\n",
      "New Net Load at Bus 3: 70.95 MW\n",
      "\n",
      "--- Performing Inference ---\n",
      "\n",
      "--- Inference Results ---\n",
      "Scenario: Original Load at Bus 3\n",
      "Scenario: Random PV Generation (0.00 MW) added to Bus 3\n",
      "\n",
      "Bus | Type   | Original Load (MW) | Mod. Net Load (MW) | True Theta (deg) | Pred Theta (deg) [Org] | Pred Theta (deg) [Mod] | True Pg (MW) | Pred Pg (MW) [Org] | Pred Pg (MW) [Mod]\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1   | (G, Slack) | -0.00     | -0.00     | 0.00      | 80.22     | 230.97    | 85.16     | 131.19    | 93.49    \n",
      "2   | (G)       | -0.00     | -0.00     | 546.36    | 134.36    | 289.73    | 194.61    | 143.36    | 133.07   \n",
      "3   | (L:80MW)  | 70.95     | 70.95     | -859.52   | -1258.53  | -827.56   | -0.00     | -5.46     | -11.24   \n",
      "4   | (L:100MW) | 149.26    | 97.02     | -1249.07  | -1271.55  | -841.76   | -0.00     | 7.42      | -0.26    \n",
      "5   | (G)       | -0.00     | -0.00     | -77.81    | -397.16   | -142.04   | 10.00     | 2.76      | 11.61    \n",
      "6   | (L:150MW) | 69.57     | 45.22     | -1024.62  | -1380.73  | -877.98   | -0.00     | -3.61     | -13.89   \n",
      "Original Load at Bus 3: 70.95 MW\n",
      "Random PV Generation added to Bus 3: 0.00 MW\n",
      "New Net Load at Bus 3: 70.95 MW\n",
      "\n",
      "--- Performing Inference ---\n",
      "\n",
      "--- Inference Results ---\n",
      "Scenario: Original Load at Bus 3\n",
      "Scenario: Random PV Generation (0.00 MW) added to Bus 3\n",
      "\n",
      "Bus | Type   | Original Load (MW) | Mod. Net Load (MW) | True Theta (deg) | Pred Theta (deg) [Org] | Pred Theta (deg) [Mod] | True Pg (MW) | Pred Pg (MW) [Org] | Pred Pg (MW) [Mod]\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1   | (G, Slack) | -0.00     | -0.00     | 0.00      | 80.22     | 235.77    | 85.16     | 131.19    | 90.37    \n",
      "2   | (G)       | -0.00     | -0.00     | 546.36    | 134.36    | 301.84    | 194.61    | 143.36    | 130.48   \n",
      "3   | (L:80MW)  | 70.95     | 70.95     | -859.52   | -1258.53  | -807.48   | -0.00     | -5.46     | -11.37   \n",
      "4   | (L:100MW) | 149.26    | 89.55     | -1249.07  | -1271.55  | -801.08   | -0.00     | 7.42      | -0.58    \n",
      "5   | (G)       | -0.00     | -0.00     | -77.81    | -397.16   | -91.61    | 10.00     | 2.76      | 12.94    \n",
      "6   | (L:150MW) | 69.57     | 41.74     | -1024.62  | -1380.73  | -814.48   | -0.00     | -3.61     | -13.17   \n",
      "Original Load at Bus 3: 70.95 MW\n",
      "Random PV Generation added to Bus 3: 0.00 MW\n",
      "New Net Load at Bus 3: 70.95 MW\n",
      "\n",
      "--- Performing Inference ---\n",
      "\n",
      "--- Inference Results ---\n",
      "Scenario: Original Load at Bus 3\n",
      "Scenario: Random PV Generation (0.00 MW) added to Bus 3\n",
      "\n",
      "Bus | Type   | Original Load (MW) | Mod. Net Load (MW) | True Theta (deg) | Pred Theta (deg) [Org] | Pred Theta (deg) [Mod] | True Pg (MW) | Pred Pg (MW) [Org] | Pred Pg (MW) [Mod]\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1   | (G, Slack) | -0.00     | -0.00     | 0.00      | 80.22     | 235.77    | 85.16     | 131.19    | 90.37    \n",
      "2   | (G)       | -0.00     | -0.00     | 546.36    | 134.36    | 301.84    | 194.61    | 143.36    | 130.48   \n",
      "3   | (L:80MW)  | 70.95     | 70.95     | -859.52   | -1258.53  | -807.48   | -0.00     | -5.46     | -11.37   \n",
      "4   | (L:100MW) | 149.26    | 89.55     | -1249.07  | -1271.55  | -801.08   | -0.00     | 7.42      | -0.58    \n",
      "5   | (G)       | -0.00     | -0.00     | -77.81    | -397.16   | -91.61    | 10.00     | 2.76      | 12.94    \n",
      "6   | (L:150MW) | 69.57     | 41.74     | -1024.62  | -1380.73  | -814.48   | -0.00     | -3.61     | -13.17   \n",
      "Original Load at Bus 3: 70.95 MW\n",
      "Random PV Generation added to Bus 3: 0.00 MW\n",
      "New Net Load at Bus 3: 70.95 MW\n",
      "\n",
      "--- Performing Inference ---\n",
      "\n",
      "--- Inference Results ---\n",
      "Scenario: Original Load at Bus 3\n",
      "Scenario: Random PV Generation (0.00 MW) added to Bus 3\n",
      "\n",
      "Bus | Type   | Original Load (MW) | Mod. Net Load (MW) | True Theta (deg) | Pred Theta (deg) [Org] | Pred Theta (deg) [Mod] | True Pg (MW) | Pred Pg (MW) [Org] | Pred Pg (MW) [Mod]\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1   | (G, Slack) | -0.00     | -0.00     | 0.00      | 80.22     | 230.97    | 85.16     | 131.19    | 93.49    \n",
      "2   | (G)       | -0.00     | -0.00     | 546.36    | 134.36    | 289.73    | 194.61    | 143.36    | 133.07   \n",
      "3   | (L:80MW)  | 70.95     | 70.95     | -859.52   | -1258.53  | -827.56   | -0.00     | -5.46     | -11.24   \n",
      "4   | (L:100MW) | 149.26    | 97.02     | -1249.07  | -1271.55  | -841.76   | -0.00     | 7.42      | -0.26    \n",
      "5   | (G)       | -0.00     | -0.00     | -77.81    | -397.16   | -142.04   | 10.00     | 2.76      | 11.61    \n",
      "6   | (L:150MW) | 69.57     | 45.22     | -1024.62  | -1380.73  | -877.98   | -0.00     | -3.61     | -13.89   \n",
      "Original Load at Bus 3: 70.95 MW\n",
      "Random PV Generation added to Bus 3: 0.00 MW\n",
      "New Net Load at Bus 3: 70.95 MW\n",
      "\n",
      "--- Performing Inference ---\n",
      "\n",
      "--- Inference Results ---\n",
      "Scenario: Original Load at Bus 3\n",
      "Scenario: Random PV Generation (0.00 MW) added to Bus 3\n",
      "\n",
      "Bus | Type   | Original Load (MW) | Mod. Net Load (MW) | True Theta (deg) | Pred Theta (deg) [Org] | Pred Theta (deg) [Mod] | True Pg (MW) | Pred Pg (MW) [Org] | Pred Pg (MW) [Mod]\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1   | (G, Slack) | -0.00     | -0.00     | 0.00      | 80.22     | 216.23    | 85.16     | 131.19    | 102.57   \n",
      "2   | (G)       | -0.00     | -0.00     | 546.36    | 134.36    | 255.52    | 194.61    | 143.36    | 136.88   \n",
      "3   | (L:80MW)  | 70.95     | 70.95     | -859.52   | -1258.53  | -906.65   | -0.00     | -5.46     | -10.29   \n",
      "4   | (L:100MW) | 149.26    | 111.94    | -1249.07  | -1271.55  | -914.90   | -0.00     | 7.42      | 1.35     \n",
      "5   | (G)       | -0.00     | -0.00     | -77.81    | -397.16   | -205.58   | 10.00     | 2.76      | 9.11     \n",
      "6   | (L:150MW) | 69.57     | 52.17     | -1024.62  | -1380.73  | -983.94   | -0.00     | -3.61     | -12.63   \n",
      "Original Load at Bus 3: 70.95 MW\n",
      "Random PV Generation added to Bus 3: 0.00 MW\n",
      "New Net Load at Bus 3: 70.95 MW\n",
      "\n",
      "--- Performing Inference ---\n",
      "\n",
      "--- Inference Results ---\n",
      "Scenario: Original Load at Bus 3\n",
      "Scenario: Random PV Generation (0.00 MW) added to Bus 3\n",
      "\n",
      "Bus | Type   | Original Load (MW) | Mod. Net Load (MW) | True Theta (deg) | Pred Theta (deg) [Org] | Pred Theta (deg) [Mod] | True Pg (MW) | Pred Pg (MW) [Org] | Pred Pg (MW) [Mod]\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1   | (G, Slack) | -0.00     | -0.00     | 0.00      | 80.22     | 193.73    | 85.16     | 131.19    | 112.87   \n",
      "2   | (G)       | -0.00     | -0.00     | 546.36    | 134.36    | 208.67    | 194.61    | 143.36    | 139.48   \n",
      "3   | (L:80MW)  | 70.95     | 70.95     | -859.52   | -1258.53  | -1010.26  | -0.00     | -5.46     | -9.50    \n",
      "4   | (L:100MW) | 149.26    | 126.87    | -1249.07  | -1271.55  | -1009.20  | -0.00     | 7.42      | 2.81     \n",
      "5   | (G)       | -0.00     | -0.00     | -77.81    | -397.16   | -266.89   | 10.00     | 2.76      | 6.60     \n",
      "6   | (L:150MW) | 69.57     | 59.13     | -1024.62  | -1380.73  | -1095.43  | -0.00     | -3.61     | -10.14   \n",
      "Original Load at Bus 3: 70.95 MW\n",
      "Random PV Generation added to Bus 3: 2.44 MW\n",
      "New Net Load at Bus 3: 68.52 MW\n",
      "\n",
      "--- Performing Inference ---\n",
      "\n",
      "--- Inference Results ---\n",
      "Scenario: Original Load at Bus 3\n",
      "Scenario: Random PV Generation (2.44 MW) added to Bus 3\n",
      "\n",
      "Bus | Type   | Original Load (MW) | Mod. Net Load (MW) | True Theta (deg) | Pred Theta (deg) [Org] | Pred Theta (deg) [Mod] | True Pg (MW) | Pred Pg (MW) [Org] | Pred Pg (MW) [Mod]\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1   | (G, Slack) | -0.00     | -0.00     | 0.00      | 80.22     | 135.89    | 85.16     | 131.19    | 122.82   \n",
      "2   | (G)       | -0.00     | -0.00     | 546.36    | 134.36    | 178.29    | 194.61    | 143.36    | 142.37   \n",
      "3   | (L:80MW)  | 70.95     | 68.52     | -859.52   | -1258.53  | -1139.14  | -0.00     | -5.46     | -8.27    \n",
      "4   | (L:100MW) | 149.26    | 141.79    | -1249.07  | -1271.55  | -1128.28  | -0.00     | 7.42      | 5.05     \n",
      "5   | (G)       | -0.00     | -0.00     | -77.81    | -397.16   | -319.26   | 10.00     | 2.76      | 3.64     \n",
      "6   | (L:150MW) | 69.57     | 66.09     | -1024.62  | -1380.73  | -1239.97  | -0.00     | -3.61     | -7.55    \n",
      "Original Load at Bus 3: 70.95 MW\n",
      "Random PV Generation added to Bus 3: 11.11 MW\n",
      "New Net Load at Bus 3: 59.84 MW\n",
      "\n",
      "--- Performing Inference ---\n",
      "\n",
      "--- Inference Results ---\n",
      "Scenario: Original Load at Bus 3\n",
      "Scenario: Random PV Generation (11.11 MW) added to Bus 3\n",
      "\n",
      "Bus | Type   | Original Load (MW) | Mod. Net Load (MW) | True Theta (deg) | Pred Theta (deg) [Org] | Pred Theta (deg) [Mod] | True Pg (MW) | Pred Pg (MW) [Org] | Pred Pg (MW) [Mod]\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1   | (G, Slack) | -0.00     | -0.00     | 0.00      | 80.22     | 99.43     | 85.16     | 131.19    | 143.55   \n",
      "2   | (G)       | -0.00     | -0.00     | 546.36    | 134.36    | 136.34    | 194.61    | 143.36    | 148.42   \n",
      "3   | (L:80MW)  | 70.95     | 59.84     | -859.52   | -1258.53  | -1414.50  | -0.00     | -5.46     | -3.69    \n",
      "4   | (L:100MW) | 149.26    | 171.64    | -1249.07  | -1271.55  | -1510.92  | -0.00     | 7.42      | 11.59    \n",
      "5   | (G)       | -0.00     | -0.00     | -77.81    | -397.16   | -619.52   | 10.00     | 2.76      | -3.31    \n",
      "6   | (L:150MW) | 69.57     | 80.00     | -1024.62  | -1380.73  | -1712.43  | -0.00     | -3.61     | -1.02    \n",
      "Original Load at Bus 3: 70.95 MW\n",
      "Random PV Generation added to Bus 3: 23.28 MW\n",
      "New Net Load at Bus 3: 47.68 MW\n",
      "\n",
      "--- Performing Inference ---\n",
      "\n",
      "--- Inference Results ---\n",
      "Scenario: Original Load at Bus 3\n",
      "Scenario: Random PV Generation (23.28 MW) added to Bus 3\n",
      "\n",
      "Bus | Type   | Original Load (MW) | Mod. Net Load (MW) | True Theta (deg) | Pred Theta (deg) [Org] | Pred Theta (deg) [Mod] | True Pg (MW) | Pred Pg (MW) [Org] | Pred Pg (MW) [Mod]\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1   | (G, Slack) | -0.00     | -0.00     | 0.00      | 80.22     | 33.27     | 85.16     | 131.19    | 150.90   \n",
      "2   | (G)       | -0.00     | -0.00     | 546.36    | 134.36    | 85.63     | 194.61    | 143.36    | 154.13   \n",
      "3   | (L:80MW)  | 70.95     | 47.68     | -859.52   | -1258.53  | -1442.27  | -0.00     | -5.46     | -3.82    \n",
      "4   | (L:100MW) | 149.26    | 186.57    | -1249.07  | -1271.55  | -1720.71  | -0.00     | 7.42      | 14.53    \n",
      "5   | (G)       | -0.00     | -0.00     | -77.81    | -397.16   | -778.05   | 10.00     | 2.76      | -9.63    \n",
      "6   | (L:150MW) | 69.57     | 86.96     | -1024.62  | -1380.73  | -1924.95  | -0.00     | -3.61     | -2.69    \n",
      "Original Load at Bus 3: 70.95 MW\n",
      "Random PV Generation added to Bus 3: 35.48 MW\n",
      "New Net Load at Bus 3: 35.47 MW\n",
      "\n",
      "--- Performing Inference ---\n",
      "\n",
      "--- Inference Results ---\n",
      "Scenario: Original Load at Bus 3\n",
      "Scenario: Random PV Generation (35.48 MW) added to Bus 3\n",
      "\n",
      "Bus | Type   | Original Load (MW) | Mod. Net Load (MW) | True Theta (deg) | Pred Theta (deg) [Org] | Pred Theta (deg) [Mod] | True Pg (MW) | Pred Pg (MW) [Org] | Pred Pg (MW) [Mod]\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1   | (G, Slack) | -0.00     | -0.00     | 0.00      | 80.22     | -43.83    | 85.16     | 131.19    | 150.47   \n",
      "2   | (G)       | -0.00     | -0.00     | 546.36    | 134.36    | 47.15     | 194.61    | 143.36    | 156.52   \n",
      "3   | (L:80MW)  | 70.95     | 35.47     | -859.52   | -1258.53  | -1361.27  | -0.00     | -5.46     | -4.88    \n",
      "4   | (L:100MW) | 149.26    | 194.03    | -1249.07  | -1271.55  | -1852.41  | -0.00     | 7.42      | 15.48    \n",
      "5   | (G)       | -0.00     | -0.00     | -77.81    | -397.16   | -882.76   | 10.00     | 2.76      | -13.98   \n",
      "6   | (L:150MW) | 69.57     | 90.44     | -1024.62  | -1380.73  | -2035.39  | -0.00     | -3.61     | -5.48    \n",
      "Original Load at Bus 3: 70.95 MW\n",
      "Random PV Generation added to Bus 3: 45.44 MW\n",
      "New Net Load at Bus 3: 25.51 MW\n",
      "\n",
      "--- Performing Inference ---\n",
      "\n",
      "--- Inference Results ---\n",
      "Scenario: Original Load at Bus 3\n",
      "Scenario: Random PV Generation (45.44 MW) added to Bus 3\n",
      "\n",
      "Bus | Type   | Original Load (MW) | Mod. Net Load (MW) | True Theta (deg) | Pred Theta (deg) [Org] | Pred Theta (deg) [Mod] | True Pg (MW) | Pred Pg (MW) [Org] | Pred Pg (MW) [Mod]\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1   | (G, Slack) | -0.00     | -0.00     | 0.00      | 80.22     | 172.28    | 85.16     | 131.19    | 139.60   \n",
      "2   | (G)       | -0.00     | -0.00     | 546.36    | 134.36    | 242.96    | 194.61    | 143.36    | 156.88   \n",
      "3   | (L:80MW)  | 70.95     | 25.51     | -859.52   | -1258.53  | -1151.89  | -0.00     | -5.46     | -7.81    \n",
      "4   | (L:100MW) | 149.26    | 186.57    | -1249.07  | -1271.55  | -1495.47  | -0.00     | 7.42      | 14.64    \n",
      "5   | (G)       | -0.00     | -0.00     | -77.81    | -397.16   | -747.76   | 10.00     | 2.76      | -13.75   \n",
      "6   | (L:150MW) | 69.57     | 86.96     | -1024.62  | -1380.73  | -1816.24  | -0.00     | -3.61     | -9.86    \n",
      "Original Load at Bus 3: 70.95 MW\n",
      "Random PV Generation added to Bus 3: 49.65 MW\n",
      "New Net Load at Bus 3: 21.30 MW\n",
      "\n",
      "--- Performing Inference ---\n",
      "\n",
      "--- Inference Results ---\n",
      "Scenario: Original Load at Bus 3\n",
      "Scenario: Random PV Generation (49.65 MW) added to Bus 3\n",
      "\n",
      "Bus | Type   | Original Load (MW) | Mod. Net Load (MW) | True Theta (deg) | Pred Theta (deg) [Org] | Pred Theta (deg) [Mod] | True Pg (MW) | Pred Pg (MW) [Org] | Pred Pg (MW) [Mod]\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1   | (G, Slack) | -0.00     | -0.00     | 0.00      | 80.22     | 332.02    | 85.16     | 131.19    | 128.57   \n",
      "2   | (G)       | -0.00     | -0.00     | 546.36    | 134.36    | 363.81    | 194.61    | 143.36    | 154.73   \n",
      "3   | (L:80MW)  | 70.95     | 21.30     | -859.52   | -1258.53  | -1026.31  | -0.00     | -5.46     | -11.14   \n",
      "4   | (L:100MW) | 149.26    | 179.11    | -1249.07  | -1271.55  | -1250.62  | -0.00     | 7.42      | 11.96    \n",
      "5   | (G)       | -0.00     | -0.00     | -77.81    | -397.16   | -646.02   | 10.00     | 2.76      | -11.81   \n",
      "6   | (L:150MW) | 69.57     | 83.48     | -1024.62  | -1380.73  | -1644.58  | -0.00     | -3.61     | -13.16   \n",
      "Original Load at Bus 3: 70.95 MW\n",
      "Random PV Generation added to Bus 3: 52.44 MW\n",
      "New Net Load at Bus 3: 18.51 MW\n",
      "\n",
      "--- Performing Inference ---\n",
      "\n",
      "--- Inference Results ---\n",
      "Scenario: Original Load at Bus 3\n",
      "Scenario: Random PV Generation (52.44 MW) added to Bus 3\n",
      "\n",
      "Bus | Type   | Original Load (MW) | Mod. Net Load (MW) | True Theta (deg) | Pred Theta (deg) [Org] | Pred Theta (deg) [Mod] | True Pg (MW) | Pred Pg (MW) [Org] | Pred Pg (MW) [Mod]\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1   | (G, Slack) | -0.00     | -0.00     | 0.00      | 80.22     | -83.41    | 85.16     | 131.19    | 148.05   \n",
      "2   | (G)       | -0.00     | -0.00     | 546.36    | 134.36    | 39.26     | 194.61    | 143.36    | 159.67   \n",
      "3   | (L:80MW)  | 70.95     | 18.51     | -859.52   | -1258.53  | -1230.57  | -0.00     | -5.46     | -6.75    \n",
      "4   | (L:100MW) | 149.26    | 201.50    | -1249.07  | -1271.55  | -1941.97  | -0.00     | 7.42      | 17.16    \n",
      "5   | (G)       | -0.00     | -0.00     | -77.81    | -397.16   | -982.77   | 10.00     | 2.76      | -18.99   \n",
      "6   | (L:150MW) | 69.57     | 93.91     | -1024.62  | -1380.73  | -2124.57  | -0.00     | -3.61     | -9.51    \n",
      "Original Load at Bus 3: 70.95 MW\n",
      "Random PV Generation added to Bus 3: 48.99 MW\n",
      "New Net Load at Bus 3: 21.96 MW\n",
      "\n",
      "--- Performing Inference ---\n",
      "\n",
      "--- Inference Results ---\n",
      "Scenario: Original Load at Bus 3\n",
      "Scenario: Random PV Generation (48.99 MW) added to Bus 3\n",
      "\n",
      "Bus | Type   | Original Load (MW) | Mod. Net Load (MW) | True Theta (deg) | Pred Theta (deg) [Org] | Pred Theta (deg) [Mod] | True Pg (MW) | Pred Pg (MW) [Org] | Pred Pg (MW) [Mod]\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1   | (G, Slack) | -0.00     | -0.00     | 0.00      | 80.22     | 40.08     | 85.16     | 131.19    | 143.77   \n",
      "2   | (G)       | -0.00     | -0.00     | 546.36    | 134.36    | 137.59    | 194.61    | 143.36    | 158.19   \n",
      "3   | (L:80MW)  | 70.95     | 21.96     | -859.52   | -1258.53  | -1191.39  | -0.00     | -5.46     | -7.13    \n",
      "4   | (L:100MW) | 149.26    | 194.03    | -1249.07  | -1271.55  | -1721.29  | -0.00     | 7.42      | 15.70    \n",
      "5   | (G)       | -0.00     | -0.00     | -77.81    | -397.16   | -864.30   | 10.00     | 2.76      | -16.50   \n",
      "6   | (L:150MW) | 69.57     | 90.44     | -1024.62  | -1380.73  | -1969.94  | -0.00     | -3.61     | -9.66    \n",
      "Original Load at Bus 3: 70.95 MW\n",
      "Random PV Generation added to Bus 3: 38.10 MW\n",
      "New Net Load at Bus 3: 32.85 MW\n",
      "\n",
      "--- Performing Inference ---\n",
      "\n",
      "--- Inference Results ---\n",
      "Scenario: Original Load at Bus 3\n",
      "Scenario: Random PV Generation (38.10 MW) added to Bus 3\n",
      "\n",
      "Bus | Type   | Original Load (MW) | Mod. Net Load (MW) | True Theta (deg) | Pred Theta (deg) [Org] | Pred Theta (deg) [Mod] | True Pg (MW) | Pred Pg (MW) [Org] | Pred Pg (MW) [Mod]\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1   | (G, Slack) | -0.00     | -0.00     | 0.00      | 80.22     | 254.45    | 85.16     | 131.19    | 135.63   \n",
      "2   | (G)       | -0.00     | -0.00     | 546.36    | 134.36    | 308.77    | 194.61    | 143.36    | 153.33   \n",
      "3   | (L:80MW)  | 70.95     | 32.85     | -859.52   | -1258.53  | -1151.65  | -0.00     | -5.46     | -7.84    \n",
      "4   | (L:100MW) | 149.26    | 179.11    | -1249.07  | -1271.55  | -1345.49  | -0.00     | 7.42      | 12.95    \n",
      "5   | (G)       | -0.00     | -0.00     | -77.81    | -397.16   | -661.81   | 10.00     | 2.76      | -9.66    \n",
      "6   | (L:150MW) | 69.57     | 83.48     | -1024.62  | -1380.73  | -1706.36  | -0.00     | -3.61     | -8.24    \n",
      "Original Load at Bus 3: 70.95 MW\n",
      "Random PV Generation added to Bus 3: 23.90 MW\n",
      "New Net Load at Bus 3: 47.05 MW\n",
      "\n",
      "--- Performing Inference ---\n",
      "\n",
      "--- Inference Results ---\n",
      "Scenario: Original Load at Bus 3\n",
      "Scenario: Random PV Generation (23.90 MW) added to Bus 3\n",
      "\n",
      "Bus | Type   | Original Load (MW) | Mod. Net Load (MW) | True Theta (deg) | Pred Theta (deg) [Org] | Pred Theta (deg) [Mod] | True Pg (MW) | Pred Pg (MW) [Org] | Pred Pg (MW) [Mod]\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1   | (G, Slack) | -0.00     | -0.00     | 0.00      | 80.22     | 194.93    | 85.16     | 131.19    | 130.27   \n",
      "2   | (G)       | -0.00     | -0.00     | 546.36    | 134.36    | 246.04    | 194.61    | 143.36    | 148.78   \n",
      "3   | (L:80MW)  | 70.95     | 47.05     | -859.52   | -1258.53  | -1145.94  | -0.00     | -5.46     | -8.03    \n",
      "4   | (L:100MW) | 149.26    | 164.18    | -1249.07  | -1271.55  | -1267.33  | -0.00     | 7.42      | 9.62     \n",
      "5   | (G)       | -0.00     | -0.00     | -77.81    | -397.16   | -522.86   | 10.00     | 2.76      | -4.35    \n",
      "6   | (L:150MW) | 69.57     | 76.52     | -1024.62  | -1380.73  | -1517.62  | -0.00     | -3.61     | -7.99    \n",
      "Original Load at Bus 3: 70.95 MW\n",
      "Random PV Generation added to Bus 3: 10.20 MW\n",
      "New Net Load at Bus 3: 60.76 MW\n",
      "\n",
      "--- Performing Inference ---\n",
      "\n",
      "--- Inference Results ---\n",
      "Scenario: Original Load at Bus 3\n",
      "Scenario: Random PV Generation (10.20 MW) added to Bus 3\n",
      "\n",
      "Bus | Type   | Original Load (MW) | Mod. Net Load (MW) | True Theta (deg) | Pred Theta (deg) [Org] | Pred Theta (deg) [Mod] | True Pg (MW) | Pred Pg (MW) [Org] | Pred Pg (MW) [Mod]\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1   | (G, Slack) | -0.00     | -0.00     | 0.00      | 80.22     | 191.47    | 85.16     | 131.19    | 118.68   \n",
      "2   | (G)       | -0.00     | -0.00     | 546.36    | 134.36    | 215.26    | 194.61    | 143.36    | 143.30   \n",
      "3   | (L:80MW)  | 70.95     | 60.76     | -859.52   | -1258.53  | -1051.49  | -0.00     | -5.46     | -9.89    \n",
      "4   | (L:100MW) | 149.26    | 141.79    | -1249.07  | -1271.55  | -1061.55  | -0.00     | 7.42      | 4.90     \n",
      "5   | (G)       | -0.00     | -0.00     | -77.81    | -397.16   | -308.65   | 10.00     | 2.76      | 2.20     \n",
      "6   | (L:150MW) | 69.57     | 66.09     | -1024.62  | -1380.73  | -1195.00  | -0.00     | -3.61     | -10.25   \n",
      "Original Load at Bus 3: 70.95 MW\n",
      "Random PV Generation added to Bus 3: 4.50 MW\n",
      "New Net Load at Bus 3: 66.45 MW\n",
      "\n",
      "--- Performing Inference ---\n",
      "\n",
      "--- Inference Results ---\n",
      "Scenario: Original Load at Bus 3\n",
      "Scenario: Random PV Generation (4.50 MW) added to Bus 3\n",
      "\n",
      "Bus | Type   | Original Load (MW) | Mod. Net Load (MW) | True Theta (deg) | Pred Theta (deg) [Org] | Pred Theta (deg) [Mod] | True Pg (MW) | Pred Pg (MW) [Org] | Pred Pg (MW) [Mod]\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1   | (G, Slack) | -0.00     | -0.00     | 0.00      | 80.22     | 58.40     | 85.16     | 131.19    | 146.82   \n",
      "2   | (G)       | -0.00     | -0.00     | 546.36    | 134.36    | 66.45     | 194.61    | 143.36    | 146.66   \n",
      "3   | (L:80MW)  | 70.95     | 66.45     | -859.52   | -1258.53  | -1527.20  | -0.00     | -5.46     | -3.68    \n",
      "4   | (L:100MW) | 149.26    | 171.64    | -1249.07  | -1271.55  | -1600.70  | -0.00     | 7.42      | 10.54    \n",
      "5   | (G)       | -0.00     | -0.00     | -77.81    | -397.16   | -628.55   | 10.00     | 2.76      | -2.08    \n",
      "6   | (L:150MW) | 69.57     | 80.00     | -1024.62  | -1380.73  | -1744.43  | -0.00     | -3.61     | 1.03     \n",
      "Original Load at Bus 3: 70.95 MW\n",
      "Random PV Generation added to Bus 3: 2.68 MW\n",
      "New Net Load at Bus 3: 68.27 MW\n",
      "\n",
      "--- Performing Inference ---\n",
      "\n",
      "--- Inference Results ---\n",
      "Scenario: Original Load at Bus 3\n",
      "Scenario: Random PV Generation (2.68 MW) added to Bus 3\n",
      "\n",
      "Bus | Type   | Original Load (MW) | Mod. Net Load (MW) | True Theta (deg) | Pred Theta (deg) [Org] | Pred Theta (deg) [Mod] | True Pg (MW) | Pred Pg (MW) [Org] | Pred Pg (MW) [Mod]\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1   | (G, Slack) | -0.00     | -0.00     | 0.00      | 80.22     | -388.30   | 85.16     | 131.19    | 173.28   \n",
      "2   | (G)       | -0.00     | -0.00     | 546.36    | 134.36    | -502.60   | 194.61    | 143.36    | 143.60   \n",
      "3   | (L:80MW)  | 70.95     | 68.27     | -859.52   | -1258.53  | -2093.14  | -0.00     | -5.46     | -9.33    \n",
      "4   | (L:100MW) | 149.26    | 201.50    | -1249.07  | -1271.55  | -2630.08  | -0.00     | 7.42      | 6.90     \n",
      "5   | (G)       | -0.00     | -0.00     | -77.81    | -397.16   | -1050.78  | 10.00     | 2.76      | -9.74    \n",
      "6   | (L:150MW) | 69.57     | 93.91     | -1024.62  | -1380.73  | -2361.45  | -0.00     | -3.61     | 6.47     \n",
      "Original Load at Bus 3: 70.95 MW\n",
      "Random PV Generation added to Bus 3: 0.00 MW\n",
      "New Net Load at Bus 3: 70.95 MW\n",
      "\n",
      "--- Performing Inference ---\n",
      "\n",
      "--- Inference Results ---\n",
      "Scenario: Original Load at Bus 3\n",
      "Scenario: Random PV Generation (0.00 MW) added to Bus 3\n",
      "\n",
      "Bus | Type   | Original Load (MW) | Mod. Net Load (MW) | True Theta (deg) | Pred Theta (deg) [Org] | Pred Theta (deg) [Mod] | True Pg (MW) | Pred Pg (MW) [Org] | Pred Pg (MW) [Mod]\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1   | (G, Slack) | -0.00     | -0.00     | 0.00      | 80.22     | 80.22     | 85.16     | 131.19    | 131.19   \n",
      "2   | (G)       | -0.00     | -0.00     | 546.36    | 134.36    | 134.36    | 194.61    | 143.36    | 143.36   \n",
      "3   | (L:80MW)  | 70.95     | 70.95     | -859.52   | -1258.53  | -1258.53  | -0.00     | -5.46     | -5.46    \n",
      "4   | (L:100MW) | 149.26    | 149.26    | -1249.07  | -1271.55  | -1271.55  | -0.00     | 7.42      | 7.42     \n",
      "5   | (G)       | -0.00     | -0.00     | -77.81    | -397.16   | -397.16   | 10.00     | 2.76      | 2.76     \n",
      "6   | (L:150MW) | 69.57     | 69.57     | -1024.62  | -1380.73  | -1380.73  | -0.00     | -3.61     | -3.61    \n",
      "Original Load at Bus 3: 70.95 MW\n",
      "Random PV Generation added to Bus 3: 0.00 MW\n",
      "New Net Load at Bus 3: 70.95 MW\n",
      "\n",
      "--- Performing Inference ---\n",
      "\n",
      "--- Inference Results ---\n",
      "Scenario: Original Load at Bus 3\n",
      "Scenario: Random PV Generation (0.00 MW) added to Bus 3\n",
      "\n",
      "Bus | Type   | Original Load (MW) | Mod. Net Load (MW) | True Theta (deg) | Pred Theta (deg) [Org] | Pred Theta (deg) [Mod] | True Pg (MW) | Pred Pg (MW) [Org] | Pred Pg (MW) [Mod]\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1   | (G, Slack) | -0.00     | -0.00     | 0.00      | 80.22     | 119.54    | 85.16     | 131.19    | 124.31   \n",
      "2   | (G)       | -0.00     | -0.00     | 546.36    | 134.36    | 166.69    | 194.61    | 143.36    | 142.07   \n",
      "3   | (L:80MW)  | 70.95     | 70.95     | -859.52   | -1258.53  | -1165.57  | -0.00     | -5.46     | -7.57    \n",
      "4   | (L:100MW) | 149.26    | 141.79    | -1249.07  | -1271.55  | -1148.28  | -0.00     | 7.42      | 5.27     \n",
      "5   | (G)       | -0.00     | -0.00     | -77.81    | -397.16   | -322.59   | 10.00     | 2.76      | 4.09     \n",
      "6   | (L:150MW) | 69.57     | 66.09     | -1024.62  | -1380.73  | -1253.00  | -0.00     | -3.61     | -6.51    \n",
      "Original Load at Bus 3: 70.95 MW\n",
      "Random PV Generation added to Bus 3: 0.00 MW\n",
      "New Net Load at Bus 3: 70.95 MW\n",
      "\n",
      "--- Performing Inference ---\n",
      "\n",
      "--- Inference Results ---\n",
      "Scenario: Original Load at Bus 3\n",
      "Scenario: Random PV Generation (0.00 MW) added to Bus 3\n",
      "\n",
      "Bus | Type   | Original Load (MW) | Mod. Net Load (MW) | True Theta (deg) | Pred Theta (deg) [Org] | Pred Theta (deg) [Mod] | True Pg (MW) | Pred Pg (MW) [Org] | Pred Pg (MW) [Mod]\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1   | (G, Slack) | -0.00     | -0.00     | 0.00      | 80.22     | 204.98    | 85.16     | 131.19    | 107.72   \n",
      "2   | (G)       | -0.00     | -0.00     | 546.36    | 134.36    | 231.16    | 194.61    | 143.36    | 138.18   \n",
      "3   | (L:80MW)  | 70.95     | 70.95     | -859.52   | -1258.53  | -958.46   | -0.00     | -5.46     | -9.90    \n",
      "4   | (L:100MW) | 149.26    | 119.40    | -1249.07  | -1271.55  | -962.05   | -0.00     | 7.42      | 2.08     \n",
      "5   | (G)       | -0.00     | -0.00     | -77.81    | -397.16   | -237.32   | 10.00     | 2.76      | 7.86     \n",
      "6   | (L:150MW) | 69.57     | 55.65     | -1024.62  | -1380.73  | -1040.77  | -0.00     | -3.61     | -11.38   \n",
      "Original Load at Bus 3: 70.95 MW\n",
      "Random PV Generation added to Bus 3: 0.00 MW\n",
      "New Net Load at Bus 3: 70.95 MW\n",
      "\n",
      "--- Performing Inference ---\n",
      "\n",
      "--- Inference Results ---\n",
      "Scenario: Original Load at Bus 3\n",
      "Scenario: Random PV Generation (0.00 MW) added to Bus 3\n",
      "\n",
      "Bus | Type   | Original Load (MW) | Mod. Net Load (MW) | True Theta (deg) | Pred Theta (deg) [Org] | Pred Theta (deg) [Mod] | True Pg (MW) | Pred Pg (MW) [Org] | Pred Pg (MW) [Mod]\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1   | (G, Slack) | -0.00     | -0.00     | 0.00      | 80.22     | 245.27    | 85.16     | 131.19    | 87.36    \n",
      "2   | (G)       | -0.00     | -0.00     | 546.36    | 134.36    | 318.02    | 194.61    | 143.36    | 127.99   \n",
      "3   | (L:80MW)  | 70.95     | 70.95     | -859.52   | -1258.53  | -787.40   | -0.00     | -5.46     | -11.50   \n",
      "4   | (L:100MW) | 149.26    | 82.09     | -1249.07  | -1271.55  | -756.34   | -0.00     | 7.42      | -0.80    \n",
      "5   | (G)       | -0.00     | -0.00     | -77.81    | -397.16   | -41.19    | 10.00     | 2.76      | 14.26    \n",
      "6   | (L:150MW) | 69.57     | 38.26     | -1024.62  | -1380.73  | -750.97   | -0.00     | -3.61     | -12.45   \n"
     ]
    }
   ],
   "source": [
    "# --- Day-ahead hourly solar forecasts (example data in MW) ---\n",
    "hourly_solar_forecasts_mw = [\n",
    "    0, 0, 0, 0, 0,  # Hour 0-4: Night\n",
    "    0, 0, 2.436, 11.108, 23.277, \n",
    "    35.48, 45.441, 49.654, 52.441, 48.99, \n",
    "    38.1, 23.899, 10.196, 4.503, 2.68, \n",
    "    0, 0, 0, 0 # Hour 18-23: Evening/Night\n",
    "]\n",
    "\n",
    "# --- Define Hourly Load Profiles for Each Bus ---\n",
    "hourly_load_factors = [\n",
    "    0.70, 0.65, 0.60, 0.60, 0.65, 0.75, # 00:00 - 05:00 (low night load)\n",
    "    0.85, 0.95, 1.15, 1.25, 1.30, 1.25, # 06:00 - 11:00 (morning ramp-up, midday)\n",
    "    1.20, 1.35, 1.30, 1.20, 1.10, 0.95, # 12:00 - 17:00 (afternoon decline)\n",
    "    1.15, 1.35, 1.00, 0.95, 0.80, 0.55  # 18:00 - 23:00 (evening decline)\n",
    "]\n",
    "\n",
    "# Assuming 'original_data' is a torch_geometric.data.Data object on the correct device\n",
    "# and contains original scaled 'x', 'edge_index', and 'y' (true values for original scenario)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "original_data = test_dataset[0].to(device)\n",
    "model.eval()\n",
    "\n",
    "# --- 1. Choose a Load Bus and Generate Random PV Generation ---\n",
    "# Choose Bus 3 (0-indexed 2) as the load bus for adding PV.\n",
    "target_load_bus_idx = 2\n",
    "original_load_bus_pd_idx = 0\n",
    "\n",
    "# Store results for potential later plotting or aggregate analysis\n",
    "all_hourly_results = []\n",
    "\n",
    "for hr_idx in range(0, 24):\n",
    "    \n",
    "    # Initialize hourly data\n",
    "    hour_data = {\"predicted_theta_deg\": {},\n",
    "                 \"predicted_pg_mw\": {}}\n",
    "    \n",
    "    # Get original (scaled) features and unscale them\n",
    "    original_x_np = original_data.x.cpu().numpy()\n",
    "    original_x_unscaled_np = x_scaler.inverse_transform(original_x_np)\n",
    "\n",
    "    # Get the original load at the target bus\n",
    "    original_pd_at_target_bus = original_x_unscaled_np[target_load_bus_idx, original_load_bus_pd_idx]\n",
    "    print(f\"Original Load at Bus {target_load_bus_idx + 1}: {original_pd_at_target_bus:.2f} MW\")\n",
    "\n",
    "    # Generate a random PV generation value (e.g., between 0 MW and 100 MW)\n",
    "    random_pv_generation_mw = hourly_solar_forecasts_mw[hr_idx]\n",
    "    print(f\"Random PV Generation added to Bus {target_load_bus_idx + 1}: {random_pv_generation_mw:.2f} MW\")\n",
    "\n",
    "    # --- 2. Modify the Input Data (as a \"Negative Load\") ---\n",
    "    # Create a copy to modify without affecting the original data object\n",
    "    modified_x_unscaled_np = original_x_unscaled_np.copy()\n",
    "    for i in range(num_buses):\n",
    "        modified_x_unscaled_np[i][0] = modified_x_unscaled_np[i][0] * hourly_load_factors[hr_idx]\n",
    "\n",
    "    # Calculate net load: subtract PV generation from original load (no feed-in)\n",
    "    new_pd_at_target_bus = original_pd_at_target_bus - random_pv_generation_mw\n",
    "    modified_x_unscaled_np[target_load_bus_idx, original_load_bus_pd_idx] = new_pd_at_target_bus\n",
    "    print(f\"New Net Load at Bus {target_load_bus_idx + 1}: {new_pd_at_target_bus:.2f} MW\")\n",
    "\n",
    "    # Rescale the modified input features back to the model's expected range\n",
    "    modified_x_scaled_np = x_scaler.transform(modified_x_unscaled_np)\n",
    "    modified_data = Data(x=torch.tensor(modified_x_scaled_np, dtype=torch.float),\n",
    "                         edge_index=original_data.edge_index,\n",
    "                         y=original_data.y) # Keep original y for comparison (true values for original scenario)\n",
    "    modified_data = modified_data.to(device)\n",
    "\n",
    "\n",
    "    # --- 3. Perform Inference ---\n",
    "    print(\"\\n--- Performing Inference ---\")\n",
    "    with torch.no_grad(): # Disable gradient calculation for inference\n",
    "        predicted_output_scaled_original = model(original_data)\n",
    "        predicted_output_scaled_modified = model(modified_data)\n",
    "\n",
    "    # --- 4. Inverse Transform Results for Readability ---\n",
    "    predicted_output_np_original = y_scaler.inverse_transform(predicted_output_scaled_original.cpu().numpy())\n",
    "    predicted_output_np_modified = y_scaler.inverse_transform(predicted_output_scaled_modified.cpu().numpy())\n",
    "    true_output_np = y_scaler.inverse_transform(original_data.y.cpu().numpy())\n",
    "\n",
    "    # --- 5. Display Results ---\n",
    "    print(\"\\n--- Inference Results ---\")\n",
    "    print(f\"Scenario: Original Load at Bus {target_load_bus_idx + 1}\")\n",
    "    print(f\"Scenario: Random PV Generation ({random_pv_generation_mw:.2f} MW) added to Bus {target_load_bus_idx + 1}\")\n",
    "\n",
    "    print(\"\\nBus | Type   | Original Load (MW) | Mod. Net Load (MW) | True Theta (deg) | Pred Theta (deg) [Org] | Pred Theta (deg) [Mod] | True Pg (MW) | Pred Pg (MW) [Org] | Pred Pg (MW) [Mod]\")\n",
    "    print(\"-\" * 180) # Increased length for better formatting\n",
    "\n",
    "    for i in range(num_buses):\n",
    "        bus_label = i + 1\n",
    "\n",
    "        # Get bus type info for display\n",
    "        bus_type_info = []\n",
    "        if ieee_6_buses_data[i]['Pd'] > 0:\n",
    "            bus_type_info.append(f\"L:{ieee_6_buses_data[i]['Pd']}MW\")\n",
    "        if i in {g['bus'] for g in ieee_6_generators_data}:\n",
    "            bus_type_info.append(\"G\")\n",
    "        if i == SLACK_BUS_IDX:\n",
    "            bus_type_info.append(\"Slack\")\n",
    "\n",
    "        type_str = f\"({', '.join(bus_type_info)})\" if bus_type_info else \"\"\n",
    "\n",
    "        # Original load display\n",
    "        current_original_pd = original_x_unscaled_np[i, original_load_bus_pd_idx]\n",
    "\n",
    "        # Modified load display\n",
    "        current_modified_pd = modified_x_unscaled_np[i, original_load_bus_pd_idx]\n",
    "\n",
    "        # True values from the original data (used as a baseline for comparison)\n",
    "        true_theta = true_output_np[i, 0]\n",
    "        true_pg = true_output_np[i, 1]\n",
    "\n",
    "        # Predicted values for original and modified scenarios\n",
    "        pred_theta_original = predicted_output_np_original[i, 0]\n",
    "        pred_pg_original = predicted_output_np_original[i, 1]\n",
    "\n",
    "        pred_theta_modified = predicted_output_np_modified[i, 0]\n",
    "        pred_pg_modified = predicted_output_np_modified[i, 1]\n",
    "\n",
    "        # Format output\n",
    "        print(f\"{bus_label:<3} | {type_str:<9} | {current_original_pd:<9.2f} | {current_modified_pd:<9.2f} | {true_theta:<9.2f} | {pred_theta_original:<9.2f} | {pred_theta_modified:<9.2f} | {true_pg:<9.2f} | {pred_pg_original:<9.2f} | {pred_pg_modified:<9.2f}\")\n",
    "        \n",
    "        # Store results\n",
    "        hour_data[\"predicted_theta_deg\"][i] = pred_theta_modified\n",
    "        hour_data[\"predicted_pg_mw\"][i] = pred_pg_modified\n",
    "        \n",
    "    # Store hourly results\n",
    "    all_hourly_results.append(hour_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c787905c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Identify Generator Buses ---\n",
    "generator_bus_indices = sorted([g['bus'] for g in ieee_6_generators_data]) # Get 0-indexed generator bus IDs\n",
    "\n",
    "# --- Prepare data for plotting ---\n",
    "hours = np.arange(24) # 0 to 23 hours\n",
    "\n",
    "# Dictionaries to store predictions for each generator bus over 24 hours\n",
    "gen_theta_predictions = {bus_idx: [] for bus_idx in generator_bus_indices}\n",
    "gen_pg_predictions = {bus_idx: [] for bus_idx in generator_bus_indices}\n",
    "\n",
    "for hour_data in all_hourly_results:\n",
    "    for bus_idx in generator_bus_indices:\n",
    "        gen_theta_predictions[bus_idx].append(hour_data['predicted_theta_deg'][bus_idx])\n",
    "        gen_pg_predictions[bus_idx].append(hour_data['predicted_pg_mw'][bus_idx])\n",
    "\n",
    "# --- Plotting Pred Theta (deg) [Mod] for each generator bus ---\n",
    "plt.figure(figsize=(14, 7))\n",
    "for bus_idx in generator_bus_indices:\n",
    "    plt.plot(hours, gen_theta_predictions[bus_idx], label=f'Bus {bus_idx + 1}')\n",
    "\n",
    "plt.xlabel('Hour of Day', fontsize=16)\n",
    "plt.ylabel('Predicted Voltage Angle (degrees)', fontsize=16)\n",
    "plt.title('24-Hour Predicted Voltage Angle (Theta) for Generator Buses', fontsize=16)\n",
    "plt.xticks(hours) # Ensure all 24 hours are shown as ticks\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.legend(title='Generator Bus', fontsize=16, title_fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Plotting Pred Pg (MW) [Mod] for each generator bus ---\n",
    "plt.figure(figsize=(12, 5))\n",
    "idx = 0\n",
    "for bus_idx in generator_bus_indices:\n",
    "    plt.plot(hours, gen_pg_predictions[bus_idx], label=f'Bus {bus_idx + 1}', \n",
    "             color=[\"red\", \"orange\", \"green\"][idx])\n",
    "    idx += 1\n",
    "plt.plot(hours, hourly_solar_forecasts_mw, label=f'Solar forecasts', color=\"blue\")\n",
    "\n",
    "plt.xlabel('Hour of Day', fontsize=16)\n",
    "plt.ylabel('Predicted Active Power (MW)', fontsize=16)\n",
    "plt.title('One Scenario: Predicted Active Power for Generator Buses', fontsize=16)\n",
    "plt.xticks(hours) # Ensure all 24 hours are shown as ticks\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.legend(title='Generator Bus', fontsize=16, title_fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d20497",
   "metadata": {},
   "source": [
    "# Apply trained GNNs to N-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e598be53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_single_pyg_data_object(current_buses_data_scenario, generators_data,\n",
    "                                  contingent_branches_data, slack_bus_idx):\n",
    "    \"\"\"\n",
    "    Converts a single scenario's data into a PyTorch Geometric Data object,\n",
    "    including contingent edge_index and edge_attr.\n",
    "    \"\"\"\n",
    "    node_features = np.zeros((num_buses, 9), dtype=np.float32)\n",
    "    for bus_idx in range(num_buses):\n",
    "        # Load demand (Pd): Get from the current scenario's input parameters\n",
    "        # Use .get() with a default of 0.0 to handle cases where a bus might not have a load defined\n",
    "        node_features[bus_idx, 0] = float(current_buses_data_scenario[bus_idx].get('Pd', 0.0))\n",
    "\n",
    "        gen_details_map = {g['bus']: g for g in generators_data}\n",
    "        gen_bus_0_indices = {g['bus'] for g in generators_data}\n",
    "\n",
    "        if bus_idx in gen_bus_0_indices:\n",
    "            gen_data = gen_details_map[bus_idx]\n",
    "            node_features[bus_idx, 1] = gen_data['Pmin']\n",
    "            node_features[bus_idx, 2] = gen_data['Pmax']\n",
    "            node_features[bus_idx, 3] = gen_data['cost_a']\n",
    "            node_features[bus_idx, 4] = gen_data['cost_b']\n",
    "            node_features[bus_idx, 5] = gen_data['cost_c']\n",
    "\n",
    "        node_features[bus_idx, 6] = 1.0 if bus_idx == slack_bus_idx else 0.0\n",
    "        node_features[bus_idx, 7] = 1.0 if bus_idx in gen_bus_0_indices else 0.0\n",
    "        # is_load_bus: Check against base data for its static load characteristic\n",
    "        node_features[bus_idx, 8] = 1.0 if ieee_6_buses_data[bus_idx].get('Pd', 0) > 0 else 0.0\n",
    "\n",
    "    x = torch.tensor(node_features, dtype=torch.float)\n",
    "\n",
    "    # --- Contingent Edge Index and Edge Attributes ---\n",
    "    contingent_edges_list = []\n",
    "    contingent_edge_attr_list = []\n",
    "    \n",
    "    # Create a mapping for branch features for efficient lookup\n",
    "    branch_features_map = {}\n",
    "    for branch in contingent_branches_data:\n",
    "        features = [branch['X_pu'], branch['limit_MW']]\n",
    "        branch_features_map[(branch['from_bus'], branch['to_bus'])] = features\n",
    "        branch_features_map[(branch['to_bus'], branch['from_bus'])] = features # For undirected graph\n",
    "\n",
    "    # Build edge_index and edge_attr based on the contingent branches\n",
    "    for branch in contingent_branches_data:\n",
    "        contingent_edges_list.append([branch['from_bus'], branch['to_bus']])\n",
    "        contingent_edges_list.append([branch['to_bus'], branch['from_bus']])\n",
    "        \n",
    "        # Add corresponding edge attributes\n",
    "        features = branch_features_map[(branch['from_bus'], branch['to_bus'])]\n",
    "        contingent_edge_attr_list.append(features)\n",
    "        contingent_edge_attr_list.append(features) # For reverse edge\n",
    "\n",
    "    # Handle case where all branches are removed (empty graph)\n",
    "    if not contingent_edges_list:\n",
    "        contingent_edge_index = torch.empty((2, 0), dtype=torch.long)\n",
    "        contingent_edge_attr = torch.empty((0, 2), dtype=torch.float) # Assuming 2 edge features\n",
    "    else:\n",
    "        contingent_edge_index = torch.tensor(contingent_edges_list, dtype=torch.long).t().contiguous()\n",
    "        contingent_edge_attr = torch.tensor(contingent_edge_attr_list, dtype=torch.float)\n",
    "\n",
    "    # Scale the node features and edge attributes\n",
    "    x_scaled = torch.tensor(x_scaler.transform(x.cpu().numpy()), dtype=torch.float)\n",
    "    edge_attr_scaled = torch.tensor(edge_attr_scaler.transform(contingent_edge_attr.cpu().numpy()), dtype=torch.float)\n",
    "\n",
    "    data = Data(x=x_scaled, edge_index=contingent_edge_index, edge_attr=edge_attr_scaled)\n",
    "    return data\n",
    "\n",
    "# --- N-1 Contingency Simulation ---\n",
    "def simulate_n_1_contingencies(num_scenarios, buses_base_data, generators_data, branches_data_base, slack_bus_idx,\n",
    "                               model, x_scaler, y_scaler, edge_attr_scaler, device):\n",
    "    \"\"\"\n",
    "    Simulates N-1 contingencies under random load scenarios and compares GNN predictions\n",
    "    against DC OPF true values.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Starting N-1 Contingency Simulation for {num_scenarios} Scenarios ---\")\n",
    "\n",
    "    min_bus_load_scale = 0.0 # Adjust load scaling for contingencies if needed\n",
    "    max_bus_load_scale = 1.8\n",
    "\n",
    "    all_comparison_results = [] # Stores summary of GNN vs OPF for each scenario\n",
    "    detailed_scenario_data = [] # Stores full data for each scenario (first few)\n",
    "    \n",
    "    # NEW: Dictionaries to store all true and predicted Pg values per generator bus\n",
    "    all_true_pg_per_gen = {g['bus']: [] for g in generators_data}\n",
    "    all_pred_pg_per_gen = {g['bus']: [] for g in generators_data}\n",
    "\n",
    "    num_branches = len(branches_data_base)\n",
    "    if num_branches == 0:\n",
    "        print(\"Error: No branches defined for N-1 simulation. Cannot perform N-1.\")\n",
    "        return [], []\n",
    "\n",
    "    # Pre-process generator data for efficient lookup for constraint calculation\n",
    "    generator_bus_set = {g['bus'] for g in generators_data}\n",
    "\n",
    "    for i in tqdm(range(num_scenarios), desc=\"Simulating N-1 Contingencies\"):\n",
    "        current_buses_data_scenario = copy.deepcopy(buses_base_data)\n",
    "        \n",
    "        # 1. Generate Random Load Profile for this scenario\n",
    "        for bus_idx in current_buses_data_scenario:\n",
    "            if current_buses_data_scenario[bus_idx]['Pd'] > 0: # Only scale load buses\n",
    "                individual_scale_factor = random.uniform(min_bus_load_scale, max_bus_load_scale)\n",
    "                current_buses_data_scenario[bus_idx]['Pd'] *= individual_scale_factor\n",
    "\n",
    "        # 2. Select a Random N-1 Contingency (remove one branch)\n",
    "        # Ensure there's at least one branch to remove\n",
    "        if num_branches > 0:\n",
    "            contingency_branch_idx = random.randint(0, num_branches - 1)\n",
    "            contingency_branch_info = branches_data_base[contingency_branch_idx]\n",
    "            \n",
    "            contingent_branches_data = [\n",
    "                branch for idx, branch in enumerate(branches_data_base)\n",
    "                if idx != contingency_branch_idx\n",
    "            ]\n",
    "        else:\n",
    "            # No branches to remove, run base case\n",
    "            contingency_branch_idx = -1 # Indicate no branch removed\n",
    "            contingency_branch_info = {'from_bus': -1, 'to_bus': -1, 'X_pu': 0, 'limit_MW': 0} # Dummy info\n",
    "            contingent_branches_data = branches_data_base # Use all branches\n",
    "\n",
    "        # 3. Run DC OPF for the Contingent Scenario\n",
    "        opf_results = solve_dc_opf(current_buses_data_scenario, \n",
    "                                   generators_data, \n",
    "                                   contingent_branches_data, \n",
    "                                   slack_bus_idx)\n",
    "\n",
    "        if opf_results['status'] in [\"optimal\", \"optimal_near\", \"feasible\"]:\n",
    "            \n",
    "            # 4. Create PyG Data Object for GNN Inference\n",
    "            pyg_data_input = create_single_pyg_data_object(\n",
    "                current_buses_data_scenario, generators_data,\n",
    "                contingent_branches_data, slack_bus_idx\n",
    "            )\n",
    "            pyg_data_input = pyg_data_input.to(device)\n",
    "            \n",
    "            # --- Load and Prepare Dataset ---\n",
    "            output_json_filename = \"feasible_opf_results_per_bus_scale_n1.json\"\n",
    "            dataset = create_pyg_data_objects(output_json_filename, \n",
    "                                              ieee_6_buses_data, \n",
    "                                              ieee_6_generators_data, \n",
    "                                              ieee_6_branches_data_base,\n",
    "                                              edge_index, \n",
    "                                              SLACK_BUS_IDX)\n",
    "\n",
    "            # 5. Run GNN Inference\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                predicted_output_scaled = model(pyg_data_input)\n",
    "            \n",
    "            # 6. Inverse Transform GNN Predictions\n",
    "            predicted_output_unscaled = y_scaler.inverse_transform(predicted_output_scaled.cpu().numpy())\n",
    "            predicted_theta = predicted_output_unscaled[:, 0]\n",
    "            predicted_pg = predicted_output_unscaled[:, 1]\n",
    "\n",
    "            # 7. Extract and Post-process True Values from OPF Results\n",
    "            true_theta_opf = np.array([opf_results['theta'].get(b_idx + 1, 0.0) for b_idx in range(num_buses)])\n",
    "            true_pg_opf_raw = np.array([opf_results['pg'].get(b_idx + 1, 0.0) for b_idx in range(num_buses)])\n",
    "\n",
    "            # Post-process true Pg for non-generator buses to be exactly 0\n",
    "            true_pg_opf = np.copy(true_pg_opf_raw)\n",
    "            for b_idx in range(num_buses):\n",
    "                if b_idx not in generator_bus_set:\n",
    "                    true_pg_opf[b_idx] = 0.0\n",
    "                    \n",
    "            # Collect Pg values for plotting distributions\n",
    "            for g_bus_idx in generator_bus_set:\n",
    "                all_true_pg_per_gen[g_bus_idx].append(true_pg_opf[g_bus_idx])\n",
    "                all_pred_pg_per_gen[g_bus_idx].append(predicted_pg[g_bus_idx])\n",
    "\n",
    "            # 8. Compare and Store Results\n",
    "            # Calculate errors for generator buses only for Pg\n",
    "            pg_mae = 0.0\n",
    "            pg_mse = 0.0\n",
    "            theta_mae = 0.0\n",
    "            theta_mse = 0.0\n",
    "            \n",
    "            gen_count = 0\n",
    "            for b_idx in generator_bus_set:\n",
    "                pg_mae += abs(predicted_pg[b_idx] - true_pg_opf[b_idx])\n",
    "                pg_mse += (predicted_pg[b_idx] - true_pg_opf[b_idx])**2\n",
    "                gen_count += 1\n",
    "            \n",
    "            if gen_count > 0:\n",
    "                pg_mae /= gen_count\n",
    "                pg_mse /= gen_count\n",
    "            else: # Handle case with no generators, though unlikely for power systems\n",
    "                pg_mae = np.nan\n",
    "                pg_mse = np.nan\n",
    "\n",
    "            # For Theta, compare all buses\n",
    "            theta_mae = np.mean(np.abs(predicted_theta - true_theta_opf))\n",
    "            theta_mse = np.mean((predicted_theta - true_theta_opf)**2)\n",
    "\n",
    "            all_comparison_results.append({\n",
    "                'scenario_id': i + 1,\n",
    "                'contingency_branch': f\"{contingency_branch_info['from_bus']+1}-{contingency_branch_info['to_bus']+1}\",\n",
    "                'opf_status': opf_results['status'],\n",
    "                'pg_mae_gen_buses': pg_mae,\n",
    "                'pg_mse_gen_buses': pg_mse,\n",
    "                'theta_mae_all_buses': theta_mae,\n",
    "                'theta_mse_all_buses': theta_mse,\n",
    "            })\n",
    "\n",
    "            # Store detailed data for a few scenarios for deeper inspection\n",
    "            if len(detailed_scenario_data) < 5: # Store only the first 5 detailed scenarios\n",
    "                print(true_pg_opf)\n",
    "                detailed_scenario_data.append({\n",
    "                    'scenario_id': i + 1,\n",
    "                    'contingency_branch_info': contingency_branch_info,\n",
    "                    'input_bus_loads_MW': {str(k+1): v['Pd'] for k, v in current_buses_data_scenario.items()},\n",
    "                    'opf_true_pg_MW': {str(b_idx+1): true_pg_opf[b_idx] for b_idx in range(num_buses)},\n",
    "                    'opf_true_theta_deg': {str(b_idx+1): true_theta_opf[b_idx] for b_idx in range(num_buses)},\n",
    "                    'gnn_pred_pg_MW': {str(b_idx+1): predicted_pg[b_idx] for b_idx in range(num_buses)},\n",
    "                    'gnn_pred_theta_deg': {str(b_idx+1): predicted_theta[b_idx] for b_idx in range(num_buses)},\n",
    "                })\n",
    "\n",
    "    print(\"\\n--- N-1 Contingency Simulation Complete ---\")\n",
    "    return all_comparison_results, detailed_scenario_data, all_true_pg_per_gen, all_pred_pg_per_gen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9e7d44cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting N-1 Contingency Simulation for 10000 Scenarios ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Simulating N-1 Contingencies:   0%|                   | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  31%|▎| 3797/12392 [00:00<00:00, 37942\u001b[A\n",
      "Converting scenarios to PyG Data objects:  61%|▌| 7592/12392 [00:00<00:00, 18819\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 2603\u001b[A\n",
      "Simulating N-1 Contingencies:   0%|           | 6/10000 [00:00<15:55, 10.46it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 65.37507464 149.46241872   0.           0.          10.00000115\n",
      "   0.        ]\n",
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  33%|▎| 4126/12392 [00:00<00:00, 41254\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4550\u001b[A\n",
      "Simulating N-1 Contingencies:   0%|          | 14/10000 [00:00<10:48, 15.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 44.07410672 100.73695186   0.           0.          10.00000001\n",
      "   0.        ]\n",
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4649/12392 [00:00<00:00, 46481\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3134\u001b[A\n",
      "Simulating N-1 Contingencies:   0%|          | 17/10000 [00:01<14:27, 11.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42.04687521 96.0497901   0.          0.         10.00000014  0.        ]\n",
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4787/12392 [00:00<00:00, 47860\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4804\u001b[A\n",
      "Simulating N-1 Contingencies:   0%|          | 19/10000 [00:01<16:30, 10.08it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37.27886271 85.23819956  0.          0.         10.00000005  0.        ]\n",
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4734/12392 [00:00<00:00, 47335\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3210\u001b[A\n",
      "Simulating N-1 Contingencies:   0%|          | 27/10000 [00:02<13:15, 12.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[124.56432196  75.43567764   0.           0.          88.63338698\n",
      "   0.        ]\n",
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4709/12392 [00:00<00:00, 47079\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4827\u001b[A\n",
      "Simulating N-1 Contingencies:   0%|          | 29/10000 [00:02<15:04, 11.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4759/12392 [00:00<00:00, 47582\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3241\u001b[A\n",
      "Simulating N-1 Contingencies:   0%|          | 31/10000 [00:02<18:45,  8.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4689/12392 [00:00<00:00, 46881\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4767\u001b[A\n",
      "Simulating N-1 Contingencies:   0%|          | 34/10000 [00:03<18:20,  9.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4674/12392 [00:00<00:00, 46732\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 2981\u001b[A\n",
      "Simulating N-1 Contingencies:   0%|          | 38/10000 [00:03<18:54,  8.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4913/12392 [00:00<00:00, 49117\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4936\u001b[A\n",
      "Simulating N-1 Contingencies:   0%|          | 39/10000 [00:03<21:54,  7.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4731/12392 [00:00<00:00, 47301\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3206\u001b[A\n",
      "Simulating N-1 Contingencies:   0%|          | 41/10000 [00:04<25:06,  6.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4750/12392 [00:00<00:00, 47490\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4815\u001b[A\n",
      "Simulating N-1 Contingencies:   0%|          | 42/10000 [00:04<28:19,  5.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4696/12392 [00:00<00:00, 46955\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4761\u001b[A\n",
      "Simulating N-1 Contingencies:   0%|          | 43/10000 [00:04<31:39,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  27%|▎| 3396/12392 [00:00<00:00, 17689\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3289\u001b[A\n",
      "Simulating N-1 Contingencies:   0%|          | 46/10000 [00:05<28:13,  5.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4655/12392 [00:00<00:00, 46542\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4802\u001b[A\n",
      "Simulating N-1 Contingencies:   0%|          | 47/10000 [00:05<31:24,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  33%|▎| 4094/12392 [00:00<00:00, 19883\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3325\u001b[A\n",
      "Simulating N-1 Contingencies:   0%|          | 49/10000 [00:06<32:12,  5.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  41%|▍| 5039/12392 [00:00<00:00, 50381\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5058\u001b[A\n",
      "Simulating N-1 Contingencies:   1%|          | 60/10000 [00:06<10:58, 15.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  28%|▎| 3485/12392 [00:00<00:00, 16976\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3178\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4748/12392 [00:00<00:00, 47477\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4828\u001b[A\n",
      "Simulating N-1 Contingencies:   1%|          | 70/10000 [00:07<10:58, 15.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  21%|▏| 2613/12392 [00:00<00:00, 13664\u001b[A\n",
      "Converting scenarios to PyG Data objects:  58%|▌| 7229/12392 [00:00<00:00, 27557\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3101\u001b[A\n",
      "Simulating N-1 Contingencies:   1%|          | 77/10000 [00:07<11:22, 14.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4757/12392 [00:00<00:00, 47566\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4885\u001b[A\n",
      "Simulating N-1 Contingencies:   1%|          | 85/10000 [00:08<09:50, 16.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  21%|▏| 2615/12392 [00:00<00:00, 14525\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3285\u001b[A\n",
      "Simulating N-1 Contingencies:   1%|          | 88/10000 [00:08<12:11, 13.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4708/12392 [00:00<00:00, 47070\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4884\u001b[A\n",
      "Simulating N-1 Contingencies:   1%|          | 94/10000 [00:08<11:13, 14.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  22%|▏| 2787/12392 [00:00<00:00, 14684\u001b[A\n",
      "Converting scenarios to PyG Data objects:  60%|▌| 7387/12392 [00:00<00:00, 28131\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3104\u001b[A\n",
      "Simulating N-1 Contingencies:   1%|          | 97/10000 [00:09<13:46, 11.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4615/12392 [00:00<00:00, 46142\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4857\u001b[A\n",
      "Simulating N-1 Contingencies:   1%|         | 101/10000 [00:09<13:33, 12.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  30%|▎| 3746/12392 [00:00<00:00, 18322\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3269\u001b[A\n",
      "Simulating N-1 Contingencies:   1%|         | 103/10000 [00:10<16:52,  9.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4877/12392 [00:00<00:00, 48754\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4959\u001b[A\n",
      "Simulating N-1 Contingencies:   1%|         | 109/10000 [00:10<13:45, 11.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  32%|▎| 3920/12392 [00:00<00:00, 17808\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3164\u001b[A\n",
      "Simulating N-1 Contingencies:   1%|         | 112/10000 [00:10<16:05, 10.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4927/12392 [00:00<00:00, 49266\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4952\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 5001/12392 [00:00<00:00, 50003\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3328\u001b[A\n",
      "Simulating N-1 Contingencies:   1%|         | 114/10000 [00:11<22:59,  7.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  41%|▍| 5050/12392 [00:00<00:00, 50495\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5056\u001b[A\n",
      "Simulating N-1 Contingencies:   1%|         | 118/10000 [00:11<19:28,  8.45it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  41%|▍| 5031/12392 [00:00<00:00, 50308\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3335\u001b[A\n",
      "Simulating N-1 Contingencies:   1%|         | 120/10000 [00:12<22:12,  7.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4766/12392 [00:00<00:00, 47650\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4839\u001b[A\n",
      "Simulating N-1 Contingencies:   1%|         | 121/10000 [00:12<25:07,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4965/12392 [00:00<00:00, 49643\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3110\u001b[A\n",
      "Simulating N-1 Contingencies:   1%|         | 123/10000 [00:13<27:52,  5.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4578/12392 [00:00<00:00, 45778\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4810\u001b[A\n",
      "Simulating N-1 Contingencies:   1%|         | 124/10000 [00:13<30:44,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 5002/12392 [00:00<00:00, 50016\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3192\u001b[A\n",
      "Simulating N-1 Contingencies:   1%|         | 128/10000 [00:13<24:59,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4612/12392 [00:00<00:00, 46114\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4693\u001b[A\n",
      "Simulating N-1 Contingencies:   1%|         | 131/10000 [00:14<22:26,  7.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4929/12392 [00:00<00:00, 49283\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5008\u001b[A\n",
      "Simulating N-1 Contingencies:   1%|▏        | 145/10000 [00:14<09:57, 16.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4941/12392 [00:00<00:00, 49407\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4988\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  41%|▍| 5037/12392 [00:00<00:00, 50358\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5057\u001b[A\n",
      "Simulating N-1 Contingencies:   1%|▏        | 148/10000 [00:15<14:56, 10.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4713/12392 [00:00<00:00, 47128\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4823\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4889/12392 [00:00<00:00, 48884\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4985\u001b[A\n",
      "Simulating N-1 Contingencies:   2%|▏        | 151/10000 [00:15<20:57,  7.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4803/12392 [00:00<00:00, 48022\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4965\u001b[A\n",
      "Simulating N-1 Contingencies:   2%|▏        | 153/10000 [00:16<23:26,  7.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4932/12392 [00:00<00:00, 49313\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3279\u001b[A\n",
      "Simulating N-1 Contingencies:   2%|▏        | 160/10000 [00:16<17:18,  9.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4994/12392 [00:00<00:00, 49937\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4998\u001b[A\n",
      "Simulating N-1 Contingencies:   2%|▏        | 162/10000 [00:17<18:20,  8.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4799/12392 [00:00<00:00, 47978\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4846\u001b[A\n",
      "Simulating N-1 Contingencies:   2%|▏        | 164/10000 [00:17<19:25,  8.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  11%| | 1308/12392 [00:00<00:01, 8835.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  50%|▌| 6214/12392 [00:00<00:00, 28588\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3334\u001b[A\n",
      "Simulating N-1 Contingencies:   2%|▏        | 171/10000 [00:17<15:13, 10.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4970/12392 [00:00<00:00, 49697\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5009\u001b[A\n",
      "Simulating N-1 Contingencies:   2%|▏        | 174/10000 [00:18<15:25, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  18%|▏| 2267/12392 [00:00<00:00, 12693\u001b[A\n",
      "Converting scenarios to PyG Data objects:  57%|▌| 7110/12392 [00:00<00:00, 28574\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3197\u001b[A\n",
      "Simulating N-1 Contingencies:   2%|▏        | 177/10000 [00:18<17:30,  9.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4808/12392 [00:00<00:00, 48073\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4931\u001b[A\n",
      "Simulating N-1 Contingencies:   2%|▏        | 180/10000 [00:18<17:13,  9.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  23%|▏| 2789/12392 [00:00<00:00, 14626\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3224\u001b[A\n",
      "Simulating N-1 Contingencies:   2%|▏        | 182/10000 [00:19<20:40,  7.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4992/12392 [00:00<00:00, 49910\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5046\u001b[A\n",
      "Simulating N-1 Contingencies:   2%|▏        | 186/10000 [00:19<17:41,  9.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  26%|▎| 3224/12392 [00:00<00:00, 16755\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3294\u001b[A\n",
      "Simulating N-1 Contingencies:   2%|▏        | 194/10000 [00:20<13:41, 11.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 5009/12392 [00:00<00:00, 50084\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5029\u001b[A\n",
      "Simulating N-1 Contingencies:   2%|▏        | 196/10000 [00:20<15:09, 10.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  34%|▎| 4181/12392 [00:00<00:00, 19718\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3300\u001b[A\n",
      "Simulating N-1 Contingencies:   2%|▏        | 200/10000 [00:20<15:56, 10.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4986/12392 [00:00<00:00, 49857\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4853\u001b[A\n",
      "Simulating N-1 Contingencies:   2%|▏        | 204/10000 [00:21<15:02, 10.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4750/12392 [00:00<00:00, 47498\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3157\u001b[A\n",
      "Simulating N-1 Contingencies:   2%|▏        | 206/10000 [00:21<18:37,  8.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4711/12392 [00:00<00:00, 47108\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4790\u001b[A\n",
      "Simulating N-1 Contingencies:   2%|▏        | 207/10000 [00:21<21:46,  7.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4748/12392 [00:00<00:00, 47472\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3084\u001b[A\n",
      "Simulating N-1 Contingencies:   2%|▏        | 210/10000 [00:22<22:44,  7.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4741/12392 [00:00<00:00, 47407\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4837\u001b[A\n",
      "Simulating N-1 Contingencies:   2%|▏        | 212/10000 [00:22<23:04,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4827/12392 [00:00<00:00, 48267\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3172\u001b[A\n",
      "Simulating N-1 Contingencies:   2%|▏        | 213/10000 [00:22<29:31,  5.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4904/12392 [00:00<00:00, 49034\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5001\u001b[A\n",
      "Simulating N-1 Contingencies:   2%|▏        | 214/10000 [00:23<32:06,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4860/12392 [00:00<00:00, 48592\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3277\u001b[A\n",
      "Simulating N-1 Contingencies:   2%|▏        | 221/10000 [00:23<18:46,  8.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4998/12392 [00:00<00:00, 49975\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5020\u001b[A\n",
      "Simulating N-1 Contingencies:   2%|▏        | 224/10000 [00:23<18:02,  9.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4977/12392 [00:00<00:00, 49767\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5023\u001b[A\n",
      "Simulating N-1 Contingencies:   2%|▏        | 227/10000 [00:24<17:27,  9.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4788/12392 [00:00<00:00, 47871\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4903\u001b[A\n",
      "Simulating N-1 Contingencies:   2%|▏        | 230/10000 [00:24<19:07,  8.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4980/12392 [00:00<00:00, 49791\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5002\u001b[A\n",
      "Simulating N-1 Contingencies:   2%|▏        | 234/10000 [00:25<18:24,  8.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4560/12392 [00:00<00:00, 45598\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4671\u001b[A\n",
      "Simulating N-1 Contingencies:   2%|▏        | 243/10000 [00:25<11:31, 14.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4890/12392 [00:00<00:00, 48894\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3224\u001b[A\n",
      "Simulating N-1 Contingencies:   2%|▏        | 246/10000 [00:25<14:13, 11.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  41%|▍| 5080/12392 [00:00<00:00, 50796\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5078\u001b[A\n",
      "Simulating N-1 Contingencies:   2%|▏        | 248/10000 [00:26<15:42, 10.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4953/12392 [00:00<00:00, 49528\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5034\u001b[A\n",
      "Simulating N-1 Contingencies:   3%|▏        | 253/10000 [00:26<13:39, 11.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  11%| | 1308/12392 [00:00<00:01, 8740.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  51%|▌| 6377/12392 [00:00<00:00, 29226\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3362\u001b[A\n",
      "Simulating N-1 Contingencies:   3%|▏        | 257/10000 [00:27<14:47, 10.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4989/12392 [00:00<00:00, 49882\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5051\u001b[A\n",
      "Simulating N-1 Contingencies:   3%|▏        | 259/10000 [00:27<16:13, 10.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  16%|▏| 2006/12392 [00:00<00:00, 12312\u001b[A\n",
      "Converting scenarios to PyG Data objects:  56%|▌| 6990/12392 [00:00<00:00, 29842\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3344\u001b[A\n",
      "Simulating N-1 Contingencies:   3%|▏        | 260/10000 [00:27<21:38,  7.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4969/12392 [00:00<00:00, 49683\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5018\u001b[A\n",
      "Simulating N-1 Contingencies:   3%|▏        | 263/10000 [00:27<19:46,  8.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  18%|▏| 2178/12392 [00:00<00:00, 13059\u001b[A\n",
      "Converting scenarios to PyG Data objects:  58%|▌| 7175/12392 [00:00<00:00, 30088\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3342\u001b[A\n",
      "Simulating N-1 Contingencies:   3%|▏        | 269/10000 [00:28<16:08, 10.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 5007/12392 [00:00<00:00, 50069\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5055\u001b[A\n",
      "Simulating N-1 Contingencies:   3%|▏        | 272/10000 [00:28<16:03, 10.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  27%|▎| 3311/12392 [00:00<00:00, 17582\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3347\u001b[A\n",
      "Simulating N-1 Contingencies:   3%|▏        | 273/10000 [00:29<21:16,  7.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4711/12392 [00:00<00:00, 47109\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4815\u001b[A\n",
      "Simulating N-1 Contingencies:   3%|▏        | 277/10000 [00:29<18:02,  8.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  26%|▎| 3224/12392 [00:00<00:00, 16896\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3327\u001b[A\n",
      "Simulating N-1 Contingencies:   3%|▎        | 279/10000 [00:29<21:17,  7.61it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  41%|▍| 5049/12392 [00:00<00:00, 50487\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5086\u001b[A\n",
      "Simulating N-1 Contingencies:   3%|▎        | 281/10000 [00:30<21:36,  7.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  32%|▎| 4007/12392 [00:00<00:00, 19704\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3364\u001b[A\n",
      "Simulating N-1 Contingencies:   3%|▎        | 287/10000 [00:30<16:52,  9.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4664/12392 [00:00<00:00, 46630\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4735\u001b[A\n",
      "Simulating N-1 Contingencies:   3%|▎        | 288/10000 [00:30<20:00,  8.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4697/12392 [00:00<00:00, 46951\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3154\u001b[A\n",
      "Simulating N-1 Contingencies:   3%|▎        | 289/10000 [00:31<26:21,  6.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  35%|▎| 4306/12392 [00:00<00:00, 43049\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4620\u001b[A\n",
      "Simulating N-1 Contingencies:   3%|▎        | 291/10000 [00:31<25:56,  6.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4847/12392 [00:00<00:00, 48461\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3261\u001b[A\n",
      "Simulating N-1 Contingencies:   3%|▎        | 294/10000 [00:32<24:58,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4994/12392 [00:00<00:00, 49933\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4987\u001b[A\n",
      "Simulating N-1 Contingencies:   3%|▎        | 299/10000 [00:32<18:06,  8.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4877/12392 [00:00<00:00, 48667\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3253\u001b[A\n",
      "Simulating N-1 Contingencies:   3%|▎        | 303/10000 [00:32<18:01,  8.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4817/12392 [00:00<00:00, 48163\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4775\u001b[A\n",
      "Simulating N-1 Contingencies:   3%|▎        | 306/10000 [00:33<17:37,  9.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4806/12392 [00:00<00:00, 48050\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3241\u001b[A\n",
      "Simulating N-1 Contingencies:   3%|▎        | 308/10000 [00:33<20:59,  7.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4995/12392 [00:00<00:00, 49943\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4976\u001b[A\n",
      "Simulating N-1 Contingencies:   3%|▎        | 310/10000 [00:33<21:27,  7.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 5009/12392 [00:00<00:00, 50087\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5021\u001b[A\n",
      "Simulating N-1 Contingencies:   3%|▎        | 311/10000 [00:34<24:35,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  10%| | 1221/12392 [00:00<00:01, 8260.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  51%|▌| 6271/12392 [00:00<00:00, 29018\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3349\u001b[A\n",
      "Simulating N-1 Contingencies:   3%|▎        | 316/10000 [00:34<19:24,  8.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4948/12392 [00:00<00:00, 49473\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4987\u001b[A\n",
      "Simulating N-1 Contingencies:   3%|▎        | 323/10000 [00:34<13:40, 11.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   5%| | 612/12392 [00:00<00:02, 4385.5\u001b[A\n",
      "Converting scenarios to PyG Data objects:  43%|▍| 5377/12392 [00:00<00:00, 26269\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3250\u001b[A\n",
      "Simulating N-1 Contingencies:   3%|▎        | 328/10000 [00:35<13:59, 11.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4868/12392 [00:00<00:00, 48672\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4918\u001b[A\n",
      "Simulating N-1 Contingencies:   3%|▎        | 335/10000 [00:35<12:09, 13.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4748/12392 [00:00<00:00, 47476\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4773\u001b[A\n",
      "Simulating N-1 Contingencies:   3%|▎        | 339/10000 [00:36<12:24, 12.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4956/12392 [00:00<00:00, 49556\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4957\u001b[A\n",
      "Simulating N-1 Contingencies:   3%|▎        | 343/10000 [00:36<13:47, 11.66it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4857/12392 [00:00<00:00, 48565\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4935\u001b[A\n",
      "Simulating N-1 Contingencies:   3%|▎        | 348/10000 [00:36<12:23, 12.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4979/12392 [00:00<00:00, 49784\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3260\u001b[A\n",
      "Simulating N-1 Contingencies:   4%|▎        | 356/10000 [00:37<11:07, 14.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4998/12392 [00:00<00:00, 49978\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4994\u001b[A\n",
      "Simulating N-1 Contingencies:   4%|▎        | 363/10000 [00:37<09:53, 16.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4898/12392 [00:00<00:00, 48972\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4938\u001b[A\n",
      "Simulating N-1 Contingencies:   4%|▎        | 375/10000 [00:38<08:20, 19.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4930/12392 [00:00<00:00, 49297\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4932\u001b[A\n",
      "Simulating N-1 Contingencies:   4%|▎        | 383/10000 [00:38<07:53, 20.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4930/12392 [00:00<00:00, 49298\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3266\u001b[A\n",
      "Simulating N-1 Contingencies:   4%|▎        | 388/10000 [00:39<09:32, 16.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4934/12392 [00:00<00:00, 49337\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4934\u001b[A\n",
      "Simulating N-1 Contingencies:   4%|▎        | 391/10000 [00:39<10:40, 15.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4925/12392 [00:00<00:00, 49246\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4933\u001b[A\n",
      "Simulating N-1 Contingencies:   4%|▎        | 393/10000 [00:39<12:27, 12.85it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  19%|▏| 2352/12392 [00:00<00:00, 13794\u001b[A\n",
      "Converting scenarios to PyG Data objects:  59%|▌| 7306/12392 [00:00<00:00, 30090\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3314\u001b[A\n",
      "Simulating N-1 Contingencies:   4%|▎        | 398/10000 [00:40<13:05, 12.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4881/12392 [00:00<00:00, 48806\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4923\u001b[A\n",
      "Simulating N-1 Contingencies:   4%|▎        | 400/10000 [00:40<14:43, 10.87it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  15%|▏| 1919/12392 [00:00<00:00, 11817\u001b[A\n",
      "Converting scenarios to PyG Data objects:  56%|▌| 6895/12392 [00:00<00:00, 29573\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3310\u001b[A\n",
      "Simulating N-1 Contingencies:   4%|▎        | 408/10000 [00:40<12:16, 13.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4987/12392 [00:00<00:00, 49867\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4964\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  26%|▎| 3224/12392 [00:00<00:00, 16535\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3204\u001b[A\n",
      "Simulating N-1 Contingencies:   4%|▎        | 410/10000 [00:41<18:30,  8.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4762/12392 [00:00<00:00, 47610\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4856\u001b[A\n",
      "Simulating N-1 Contingencies:   4%|▎        | 416/10000 [00:41<14:51, 10.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  25%|▏| 3050/12392 [00:00<00:00, 15619\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3208\u001b[A\n",
      "Simulating N-1 Contingencies:   4%|▍        | 423/10000 [00:42<13:20, 11.97it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4697/12392 [00:00<00:00, 46960\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4776\u001b[A\n",
      "Simulating N-1 Contingencies:   4%|▍        | 428/10000 [00:42<12:33, 12.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  32%|▎| 4007/12392 [00:00<00:00, 18987\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3236\u001b[A\n",
      "Simulating N-1 Contingencies:   4%|▍        | 430/10000 [00:43<15:30, 10.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4823/12392 [00:00<00:00, 48227\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4899\u001b[A\n",
      "Simulating N-1 Contingencies:   4%|▍        | 439/10000 [00:43<11:16, 14.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  32%|▎| 4007/12392 [00:00<00:00, 19224\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3279\u001b[A\n",
      "Simulating N-1 Contingencies:   4%|▍        | 441/10000 [00:43<14:06, 11.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4913/12392 [00:00<00:00, 49119\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4924\u001b[A\n",
      "Simulating N-1 Contingencies:   4%|▍        | 446/10000 [00:44<12:52, 12.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4790/12392 [00:00<00:00, 21446\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3289\u001b[A\n",
      "Simulating N-1 Contingencies:   4%|▍        | 448/10000 [00:44<15:58,  9.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4951/12392 [00:00<00:00, 49504\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4998\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4938/12392 [00:00<00:00, 49378\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3281\u001b[A\n",
      "Simulating N-1 Contingencies:   4%|▍        | 450/10000 [00:45<22:43,  7.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4960/12392 [00:00<00:00, 49595\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5016\u001b[A\n",
      "Simulating N-1 Contingencies:   5%|▍        | 451/10000 [00:45<25:03,  6.35it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4958/12392 [00:00<00:00, 49575\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3285\u001b[A\n",
      "Simulating N-1 Contingencies:   5%|▍        | 459/10000 [00:46<16:19,  9.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4886/12392 [00:00<00:00, 48857\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4900\u001b[A\n",
      "Simulating N-1 Contingencies:   5%|▍        | 463/10000 [00:46<15:12, 10.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4915/12392 [00:00<00:00, 49140\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 2936\u001b[A\n",
      "Simulating N-1 Contingencies:   5%|▍        | 468/10000 [00:46<15:25, 10.30it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:   5%|▍        | 477/10000 [00:47<09:07, 17.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4905/12392 [00:00<00:00, 49045\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4956\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4961/12392 [00:00<00:00, 49607\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3154\u001b[A\n",
      "Simulating N-1 Contingencies:   5%|▍        | 481/10000 [00:47<13:31, 11.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4558/12392 [00:00<00:00, 45575\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4649\u001b[A\n",
      "Simulating N-1 Contingencies:   5%|▍        | 484/10000 [00:48<14:08, 11.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4875/12392 [00:00<00:00, 48745\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4877\u001b[A\n",
      "Simulating N-1 Contingencies:   5%|▍        | 488/10000 [00:48<13:40, 11.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   8%| | 962/12392 [00:00<00:01, 6491.3\u001b[A\n",
      "Converting scenarios to PyG Data objects:  46%|▍| 5684/12392 [00:00<00:00, 26480\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3196\u001b[A\n",
      "Simulating N-1 Contingencies:   5%|▍        | 490/10000 [00:48<16:57,  9.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4877/12392 [00:00<00:00, 48764\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4904\u001b[A\n",
      "Simulating N-1 Contingencies:   5%|▍        | 492/10000 [00:49<18:04,  8.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   8%| | 1049/12392 [00:00<00:01, 7018.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  47%|▍| 5857/12392 [00:00<00:00, 27084\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3218\u001b[A\n",
      "Simulating N-1 Contingencies:   5%|▍        | 494/10000 [00:49<21:21,  7.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4825/12392 [00:00<00:00, 48242\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4858\u001b[A\n",
      "Simulating N-1 Contingencies:   5%|▍        | 504/10000 [00:49<12:31, 12.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4856/12392 [00:00<00:00, 48555\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4873\u001b[A\n",
      "Simulating N-1 Contingencies:   5%|▍        | 515/10000 [00:50<07:44, 20.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4860/12392 [00:00<00:00, 48591\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3251\u001b[A\n",
      "Simulating N-1 Contingencies:   5%|▍        | 527/10000 [00:50<06:45, 23.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4950/12392 [00:00<00:00, 49496\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4967\u001b[A\n",
      "Simulating N-1 Contingencies:   5%|▍        | 533/10000 [00:51<07:22, 21.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4913/12392 [00:00<00:00, 49121\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4962\u001b[A\n",
      "/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:   5%|▍        | 537/10000 [00:51<09:39, 16.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4831/12392 [00:00<00:00, 48304\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4851\u001b[A\n",
      "/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:   5%|▍        | 540/10000 [00:52<10:54, 14.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4894/12392 [00:00<00:00, 48929\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3206\u001b[A\n",
      "Simulating N-1 Contingencies:   5%|▍        | 545/10000 [00:52<12:02, 13.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4806/12392 [00:00<00:00, 48056\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4906\u001b[A\n",
      "Simulating N-1 Contingencies:   6%|▍        | 555/10000 [00:52<08:15, 19.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4870/12392 [00:00<00:00, 48691\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4898\u001b[A\n",
      "Simulating N-1 Contingencies:   6%|▌        | 563/10000 [00:53<08:46, 17.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4876/12392 [00:00<00:00, 48624\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4859\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4953/12392 [00:00<00:00, 49519\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4967\u001b[A\n",
      "Simulating N-1 Contingencies:   6%|▌        | 566/10000 [00:54<14:52, 10.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4897/12392 [00:00<00:00, 48963\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4922\u001b[A\n",
      "Simulating N-1 Contingencies:   6%|▌        | 568/10000 [00:54<16:13,  9.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4892/12392 [00:00<00:00, 48919\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4942\u001b[A\n",
      "Simulating N-1 Contingencies:   6%|▌        | 571/10000 [00:54<16:03,  9.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4916/12392 [00:00<00:00, 49152\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4900\u001b[A\n",
      "Simulating N-1 Contingencies:   6%|▌        | 573/10000 [00:55<19:26,  8.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4877/12392 [00:00<00:00, 48729\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4854\u001b[A\n",
      "Simulating N-1 Contingencies:   6%|▌        | 578/10000 [00:55<16:53,  9.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4846/12392 [00:00<00:00, 48455\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4890\u001b[A\n",
      "Simulating N-1 Contingencies:   6%|▌        | 581/10000 [00:55<16:32,  9.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4881/12392 [00:00<00:00, 48807\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4950\u001b[A\n",
      "Simulating N-1 Contingencies:   6%|▌        | 584/10000 [00:56<18:27,  8.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4886/12392 [00:00<00:00, 48851\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4918\u001b[A\n",
      "Simulating N-1 Contingencies:   6%|▌        | 587/10000 [00:56<17:24,  9.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4880/12392 [00:00<00:00, 48797\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4930\u001b[A\n",
      "Simulating N-1 Contingencies:   6%|▌        | 588/10000 [00:56<21:22,  7.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4860/12392 [00:00<00:00, 48597\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4893\u001b[A\n",
      "Simulating N-1 Contingencies:   6%|▌        | 599/10000 [00:57<09:35, 16.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4965/12392 [00:00<00:00, 49629\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3269\u001b[A\n",
      "Simulating N-1 Contingencies:   6%|▌        | 602/10000 [00:57<12:40, 12.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4719/12392 [00:00<00:00, 47183\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4816\u001b[A\n",
      "Simulating N-1 Contingencies:   6%|▌        | 605/10000 [00:58<13:34, 11.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4883/12392 [00:00<00:00, 48820\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4913\u001b[A\n",
      "Simulating N-1 Contingencies:   6%|▌        | 607/10000 [00:58<15:20, 10.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   5%| | 612/12392 [00:00<00:02, 4238.3\u001b[A\n",
      "Converting scenarios to PyG Data objects:  44%|▍| 5474/12392 [00:00<00:00, 26309\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3207\u001b[A\n",
      "Simulating N-1 Contingencies:   6%|▌        | 612/10000 [00:58<14:55, 10.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4886/12392 [00:00<00:00, 48857\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4903\u001b[A\n",
      "Simulating N-1 Contingencies:   6%|▌        | 619/10000 [00:59<12:04, 12.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4817/12392 [00:00<00:00, 48161\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4785\u001b[A\n",
      "Simulating N-1 Contingencies:   6%|▌        | 622/10000 [00:59<13:05, 11.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4731/12392 [00:00<00:00, 47305\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4856\u001b[A\n",
      "Simulating N-1 Contingencies:   6%|▌        | 624/10000 [00:59<15:00, 10.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4804/12392 [00:00<00:00, 48030\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4894\u001b[A\n",
      "Simulating N-1 Contingencies:   6%|▌        | 626/10000 [01:00<18:48,  8.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4754/12392 [00:00<00:00, 47531\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4872\u001b[A\n",
      "Simulating N-1 Contingencies:   6%|▌        | 629/10000 [01:00<19:16,  8.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4704/12392 [00:00<00:00, 47038\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4849\u001b[A\n",
      "Simulating N-1 Contingencies:   6%|▌        | 630/10000 [01:01<23:19,  6.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4840/12392 [00:00<00:00, 48396\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4864\u001b[A\n",
      "Simulating N-1 Contingencies:   6%|▌        | 633/10000 [01:01<22:49,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4918/12392 [00:00<00:00, 49170\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4912\u001b[A\n",
      "Simulating N-1 Contingencies:   6%|▌        | 638/10000 [01:01<15:34, 10.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4872/12392 [00:00<00:00, 48710\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4891\u001b[A\n",
      "Simulating N-1 Contingencies:   6%|▌        | 644/10000 [01:02<13:40, 11.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4902/12392 [00:00<00:00, 49012\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4950\u001b[A\n",
      "Simulating N-1 Contingencies:   6%|▌        | 649/10000 [01:02<12:04, 12.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4886/12392 [00:00<00:00, 48856\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4941\u001b[A\n",
      "Simulating N-1 Contingencies:   7%|▌        | 651/10000 [01:02<14:07, 11.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4970/12392 [00:00<00:00, 49694\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4949\u001b[A\n",
      "Simulating N-1 Contingencies:   7%|▌        | 653/10000 [01:03<18:04,  8.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4543/12392 [00:00<00:00, 45418\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4776\u001b[A\n",
      "Simulating N-1 Contingencies:   7%|▌        | 659/10000 [01:03<13:36, 11.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4877/12392 [00:00<00:00, 48766\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4921\u001b[A\n",
      "Simulating N-1 Contingencies:   7%|▌        | 661/10000 [01:04<17:07,  9.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4914/12392 [00:00<00:00, 49138\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4946\u001b[A\n",
      "Simulating N-1 Contingencies:   7%|▌        | 665/10000 [01:04<17:10,  9.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4921/12392 [00:00<00:00, 49204\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4952\u001b[A\n",
      "Simulating N-1 Contingencies:   7%|▌        | 667/10000 [01:04<18:28,  8.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4912/12392 [00:00<00:00, 49116\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3266\u001b[A\n",
      "Simulating N-1 Contingencies:   7%|▌        | 673/10000 [01:05<15:04, 10.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4939/12392 [00:00<00:00, 49389\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4971\u001b[A\n",
      "Simulating N-1 Contingencies:   7%|▌        | 675/10000 [01:05<16:30,  9.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4760/12392 [00:00<00:00, 47595\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4844\u001b[A\n",
      "Simulating N-1 Contingencies:   7%|▌        | 676/10000 [01:05<19:54,  7.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  18%|▏| 2178/12392 [00:00<00:00, 12625\u001b[A\n",
      "Converting scenarios to PyG Data objects:  57%|▌| 7079/12392 [00:00<00:00, 29106\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3251\u001b[A\n",
      "Simulating N-1 Contingencies:   7%|▌        | 680/10000 [01:06<18:46,  8.27it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4892/12392 [00:00<00:00, 48914\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4859\u001b[A\n",
      "Simulating N-1 Contingencies:   7%|▌        | 686/10000 [01:06<14:04, 11.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  13%|▏| 1569/12392 [00:00<00:01, 9173.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  49%|▍| 6100/12392 [00:00<00:00, 25619\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3078\u001b[A\n",
      "Simulating N-1 Contingencies:   7%|▌        | 692/10000 [01:07<13:28, 11.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4767/12392 [00:00<00:00, 47666\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4888\u001b[A\n",
      "Simulating N-1 Contingencies:   7%|▌        | 694/10000 [01:07<14:55, 10.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  22%|▏| 2700/12392 [00:00<00:00, 14247\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3203\u001b[A\n",
      "Simulating N-1 Contingencies:   7%|▋        | 696/10000 [01:07<18:15,  8.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4870/12392 [00:00<00:00, 48697\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4947\u001b[A\n",
      "Simulating N-1 Contingencies:   7%|▋        | 698/10000 [01:08<19:05,  8.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  30%|▎| 3657/12392 [00:00<00:00, 18399\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3296\u001b[A\n",
      "Simulating N-1 Contingencies:   7%|▋        | 702/10000 [01:08<18:16,  8.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4896/12392 [00:00<00:00, 48953\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4929\u001b[A\n",
      "Simulating N-1 Contingencies:   7%|▋        | 714/10000 [01:08<08:52, 17.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  27%|▎| 3310/12392 [00:00<00:00, 17271\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3309\u001b[A\n",
      "Simulating N-1 Contingencies:   7%|▋        | 718/10000 [01:09<10:56, 14.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4877/12392 [00:00<00:00, 48759\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4929\u001b[A\n",
      "Simulating N-1 Contingencies:   7%|▋        | 721/10000 [01:09<11:54, 12.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  27%|▎| 3311/12392 [00:00<00:00, 16704\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3243\u001b[A\n",
      "Simulating N-1 Contingencies:   7%|▋        | 728/10000 [01:10<11:20, 13.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4748/12392 [00:00<00:00, 47470\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4759\u001b[A\n",
      "Simulating N-1 Contingencies:   7%|▋        | 740/10000 [01:10<07:32, 20.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  20%|▏| 2528/12392 [00:00<00:00, 13767\u001b[A\n",
      "Converting scenarios to PyG Data objects:  60%|▌| 7395/12392 [00:00<00:00, 29037\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3199\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4781/12392 [00:00<00:00, 47799\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4865\u001b[A\n",
      "Simulating N-1 Contingencies:   7%|▋        | 744/10000 [01:11<12:11, 12.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  22%|▏| 2702/12392 [00:00<00:00, 14675\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3257\u001b[A\n",
      "Simulating N-1 Contingencies:   8%|▋        | 751/10000 [01:11<11:36, 13.29it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:   8%|▋        | 760/10000 [01:11<07:41, 20.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4798/12392 [00:00<00:00, 47978\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4869\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  20%|▏| 2528/12392 [00:00<00:00, 14326\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3291\u001b[A\n",
      "Simulating N-1 Contingencies:   8%|▋        | 765/10000 [01:12<11:08, 13.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4870/12392 [00:00<00:00, 48690\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4902\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  25%|▏| 3050/12392 [00:00<00:00, 16226\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3295\u001b[A\n",
      "Simulating N-1 Contingencies:   8%|▋        | 769/10000 [01:13<14:33, 10.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4859/12392 [00:00<00:00, 48580\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4895\u001b[A\n",
      "Simulating N-1 Contingencies:   8%|▋        | 772/10000 [01:13<14:43, 10.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  34%|▎| 4181/12392 [00:00<00:00, 19055\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3155\u001b[A\n",
      "Simulating N-1 Contingencies:   8%|▋        | 774/10000 [01:13<17:31,  8.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  36%|▎| 4523/12392 [00:00<00:00, 45224\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4754\u001b[A\n",
      "Simulating N-1 Contingencies:   8%|▋        | 789/10000 [01:14<08:29, 18.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  27%|▎| 3310/12392 [00:00<00:00, 16849\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3261\u001b[A\n",
      "Simulating N-1 Contingencies:   8%|▋        | 794/10000 [01:14<09:55, 15.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4881/12392 [00:00<00:00, 48806\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4903\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4910/12392 [00:00<00:00, 49094\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3295\u001b[A\n",
      "Simulating N-1 Contingencies:   8%|▋        | 797/10000 [01:15<14:37, 10.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4819/12392 [00:00<00:00, 48185\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4887\u001b[A\n",
      "Simulating N-1 Contingencies:   8%|▋        | 800/10000 [01:15<14:47, 10.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4912/12392 [00:00<00:00, 49116\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3293\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4898/12392 [00:00<00:00, 48972\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4929\u001b[A\n",
      "Simulating N-1 Contingencies:   8%|▋        | 802/10000 [01:16<20:56,  7.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4840/12392 [00:00<00:00, 48393\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3238\u001b[A\n",
      "Simulating N-1 Contingencies:   8%|▋        | 808/10000 [01:17<17:10,  8.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4737/12392 [00:00<00:00, 47361\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4789\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4760/12392 [00:00<00:00, 47593\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3206\u001b[A\n",
      "Simulating N-1 Contingencies:   8%|▋        | 810/10000 [01:17<23:08,  6.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4899/12392 [00:00<00:00, 48987\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4933\u001b[A\n",
      "Simulating N-1 Contingencies:   8%|▋        | 812/10000 [01:18<22:56,  6.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4932/12392 [00:00<00:00, 49312\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4911\u001b[A\n",
      "Simulating N-1 Contingencies:   8%|▋        | 817/10000 [01:18<18:08,  8.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4850/12392 [00:00<00:00, 48492\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4861\u001b[A\n",
      "Simulating N-1 Contingencies:   8%|▋        | 823/10000 [01:18<13:38, 11.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4815/12392 [00:00<00:00, 48142\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3211\u001b[A\n",
      "Simulating N-1 Contingencies:   8%|▋        | 827/10000 [01:19<14:42, 10.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4914/12392 [00:00<00:00, 49137\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4940\u001b[A\n",
      "Simulating N-1 Contingencies:   8%|▋        | 831/10000 [01:19<13:50, 11.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4877/12392 [00:00<00:00, 48758\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4936\u001b[A\n",
      "Simulating N-1 Contingencies:   8%|▊        | 835/10000 [01:19<13:14, 11.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   8%| | 1047/12392 [00:00<00:01, 6777.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  46%|▍| 5760/12392 [00:00<00:00, 26163\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3165\u001b[A\n",
      "Simulating N-1 Contingencies:   8%|▊        | 839/10000 [01:20<14:28, 10.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4802/12392 [00:00<00:00, 48017\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4879\u001b[A\n",
      "Simulating N-1 Contingencies:   8%|▊        | 841/10000 [01:20<15:51,  9.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   9%| | 1136/12392 [00:00<00:01, 7659.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  49%|▍| 6038/12392 [00:00<00:00, 27951\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3281\u001b[A\n",
      "Simulating N-1 Contingencies:   8%|▊        | 843/10000 [01:21<19:03,  8.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4865/12392 [00:00<00:00, 48640\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4919\u001b[A\n",
      "Simulating N-1 Contingencies:   8%|▊        | 847/10000 [01:21<16:27,  9.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   6%| | 699/12392 [00:00<00:02, 5063.2\u001b[A\n",
      "Converting scenarios to PyG Data objects:  45%|▍| 5521/12392 [00:00<00:00, 27009\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3279\u001b[A\n",
      "Simulating N-1 Contingencies:   9%|▊        | 853/10000 [01:21<14:24, 10.59it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4851/12392 [00:00<00:00, 48502\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4940\u001b[A\n",
      "Simulating N-1 Contingencies:   9%|▊        | 861/10000 [01:22<10:57, 13.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   2%| | 264/12392 [00:00<00:06, 1997.8\u001b[A\n",
      "Converting scenarios to PyG Data objects:  41%|▍| 5087/12392 [00:00<00:00, 26012\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3246\u001b[A\n",
      "Simulating N-1 Contingencies:   9%|▊        | 863/10000 [01:22<13:53, 10.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4854/12392 [00:00<00:00, 48537\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4890\u001b[A\n",
      "Simulating N-1 Contingencies:   9%|▊        | 868/10000 [01:22<12:34, 12.11it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4892/12392 [00:00<00:00, 48918\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4926\u001b[A\n",
      "Simulating N-1 Contingencies:   9%|▊        | 870/10000 [01:23<15:33,  9.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4933/12392 [00:00<00:00, 49320\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4846\u001b[A\n",
      "Simulating N-1 Contingencies:   9%|▊        | 874/10000 [01:23<14:28, 10.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   1%| | 89/12392 [00:00<00:17, 693.32i\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4866/12392 [00:00<00:00, 25488\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3242\u001b[A\n",
      "Simulating N-1 Contingencies:   9%|▊        | 884/10000 [01:24<09:37, 15.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4722/12392 [00:00<00:00, 47212\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3157\u001b[A\n",
      "Simulating N-1 Contingencies:   9%|▊        | 887/10000 [01:24<12:22, 12.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4856/12392 [00:00<00:00, 48549\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4844\u001b[A\n",
      "Simulating N-1 Contingencies:   9%|▊        | 893/10000 [01:24<10:56, 13.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4826/12392 [00:00<00:00, 48258\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4853\u001b[A\n",
      "Simulating N-1 Contingencies:   9%|▊        | 898/10000 [01:25<10:38, 14.26it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:   9%|▊        | 904/10000 [01:25<08:40, 17.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4848/12392 [00:00<00:00, 48476\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4895\u001b[A\n",
      "Simulating N-1 Contingencies:   9%|▊        | 907/10000 [01:25<09:58, 15.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4883/12392 [00:00<00:00, 48827\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3256\u001b[A\n",
      "Simulating N-1 Contingencies:   9%|▊        | 915/10000 [01:26<09:39, 15.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4829/12392 [00:00<00:00, 48286\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4881\u001b[A\n",
      "Simulating N-1 Contingencies:   9%|▊        | 920/10000 [01:26<09:43, 15.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4847/12392 [00:00<00:00, 48460\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4894\u001b[A\n",
      "Simulating N-1 Contingencies:   9%|▊        | 927/10000 [01:26<08:56, 16.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  15%|▏| 1919/12392 [00:00<00:00, 11643\u001b[A\n",
      "Converting scenarios to PyG Data objects:  55%|▌| 6835/12392 [00:00<00:00, 29060\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3272\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4922/12392 [00:00<00:00, 49210\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4937\u001b[A\n",
      "Simulating N-1 Contingencies:   9%|▊        | 929/10000 [01:27<14:18, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  23%|▏| 2874/12392 [00:00<00:00, 14471\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3137\u001b[A\n",
      "Simulating N-1 Contingencies:   9%|▊        | 934/10000 [01:28<14:15, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4728/12392 [00:00<00:00, 47278\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4807\u001b[A\n",
      "Simulating N-1 Contingencies:   9%|▊        | 942/10000 [01:28<11:12, 13.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  23%|▏| 2874/12392 [00:00<00:00, 15601\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3283\u001b[A\n",
      "Simulating N-1 Contingencies:   9%|▊        | 945/10000 [01:28<13:04, 11.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4889/12392 [00:00<00:00, 48882\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4929\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  34%|▎| 4181/12392 [00:00<00:00, 19391\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3220\u001b[A\n",
      "Simulating N-1 Contingencies:   9%|▊        | 947/10000 [01:29<18:47,  8.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4831/12392 [00:00<00:00, 48304\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4788\u001b[A\n",
      "Simulating N-1 Contingencies:   9%|▊        | 949/10000 [01:29<19:25,  7.77it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  35%|▎| 4355/12392 [00:00<00:00, 19538\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3213\u001b[A\n",
      "Simulating N-1 Contingencies:  10%|▊        | 956/10000 [01:30<15:13,  9.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4931/12392 [00:00<00:00, 49308\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4941\u001b[A\n",
      "Simulating N-1 Contingencies:  10%|▊        | 958/10000 [01:30<16:15,  9.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4884/12392 [00:00<00:00, 48835\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3221\u001b[A\n",
      "Simulating N-1 Contingencies:  10%|▊        | 964/10000 [01:31<14:26, 10.43it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4848/12392 [00:00<00:00, 48476\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4926\u001b[A\n",
      "Simulating N-1 Contingencies:  10%|▊        | 966/10000 [01:31<15:38,  9.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4614/12392 [00:00<00:00, 46136\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3135\u001b[A\n",
      "Simulating N-1 Contingencies:  10%|▊        | 970/10000 [01:31<16:08,  9.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4850/12392 [00:00<00:00, 48493\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4913\u001b[A\n",
      "Simulating N-1 Contingencies:  10%|▊        | 972/10000 [01:32<17:11,  8.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4918/12392 [00:00<00:00, 49100\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3038\u001b[A\n",
      "Simulating N-1 Contingencies:  10%|▉        | 975/10000 [01:32<18:48,  8.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4688/12392 [00:00<00:00, 46874\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4767\u001b[A\n",
      "Simulating N-1 Contingencies:  10%|▉        | 977/10000 [01:32<19:36,  7.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4789/12392 [00:00<00:00, 47887\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3189\u001b[A\n",
      "Simulating N-1 Contingencies:  10%|▉        | 979/10000 [01:33<22:41,  6.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4671/12392 [00:00<00:00, 46704\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4763\u001b[A\n",
      "Simulating N-1 Contingencies:  10%|▉        | 984/10000 [01:33<17:01,  8.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4765/12392 [00:00<00:00, 47646\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3162\u001b[A\n",
      "Simulating N-1 Contingencies:  10%|▉        | 986/10000 [01:34<20:10,  7.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4862/12392 [00:00<00:00, 48618\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4864\u001b[A\n",
      "Simulating N-1 Contingencies:  10%|▉        | 989/10000 [01:34<18:39,  8.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4806/12392 [00:00<00:00, 48053\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4860\u001b[A\n",
      "Simulating N-1 Contingencies:  10%|▉        | 991/10000 [01:34<19:26,  7.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  24%|▏| 2963/12392 [00:00<00:00, 14786\u001b[A\n",
      "Converting scenarios to PyG Data objects:  61%|▌| 7593/12392 [00:00<00:00, 27901\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3068\u001b[A\n",
      "Simulating N-1 Contingencies:  10%|▉        | 992/10000 [01:35<25:41,  5.84it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:  10%|▊       | 1001/10000 [01:35<10:24, 14.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4679/12392 [00:00<00:00, 46780\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4851\u001b[A\n",
      "Simulating N-1 Contingencies:  10%|▊       | 1005/10000 [01:35<10:48, 13.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  16%|▏| 2004/12392 [00:00<00:00, 12038\u001b[A\n",
      "Converting scenarios to PyG Data objects:  56%|▌| 6896/12392 [00:00<00:00, 29068\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3263\u001b[A\n",
      "Simulating N-1 Contingencies:  10%|▊       | 1008/10000 [01:35<13:19, 11.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4881/12392 [00:00<00:00, 48807\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4825\u001b[A\n",
      "Simulating N-1 Contingencies:  10%|▊       | 1012/10000 [01:36<12:53, 11.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  20%|▏| 2528/12392 [00:00<00:00, 13716\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3232\u001b[A\n",
      "Simulating N-1 Contingencies:  10%|▊       | 1014/10000 [01:36<16:16,  9.20it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4835/12392 [00:00<00:00, 48341\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4886\u001b[A\n",
      "Simulating N-1 Contingencies:  10%|▊       | 1017/10000 [01:37<15:57,  9.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  23%|▏| 2874/12392 [00:00<00:00, 15457\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3267\u001b[A\n",
      "Simulating N-1 Contingencies:  10%|▊       | 1020/10000 [01:37<17:30,  8.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4796/12392 [00:00<00:00, 47951\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4854\u001b[A\n",
      "Simulating N-1 Contingencies:  10%|▊       | 1022/10000 [01:37<18:26,  8.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  36%|▎| 4440/12392 [00:00<00:00, 20027\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3219\u001b[A\n",
      "Simulating N-1 Contingencies:  10%|▊       | 1025/10000 [01:38<19:27,  7.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4821/12392 [00:00<00:00, 48205\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4878\u001b[A\n",
      "Simulating N-1 Contingencies:  10%|▊       | 1029/10000 [01:38<16:34,  9.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4903/12392 [00:00<00:00, 49027\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3272\u001b[A\n",
      "Simulating N-1 Contingencies:  10%|▊       | 1034/10000 [01:38<15:19,  9.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4867/12392 [00:00<00:00, 48660\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4916\u001b[A\n",
      "Simulating N-1 Contingencies:  10%|▊       | 1040/10000 [01:39<12:30, 11.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4862/12392 [00:00<00:00, 48615\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3268\u001b[A\n",
      "Simulating N-1 Contingencies:  10%|▊       | 1046/10000 [01:39<12:08, 12.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4881/12392 [00:00<00:00, 48804\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4911\u001b[A\n",
      "Simulating N-1 Contingencies:  11%|▊       | 1053/10000 [01:40<10:20, 14.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4819/12392 [00:00<00:00, 48185\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3266\u001b[A\n",
      "Simulating N-1 Contingencies:  11%|▊       | 1058/10000 [01:40<11:12, 13.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4829/12392 [00:00<00:00, 48280\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4897\u001b[A\n",
      "Simulating N-1 Contingencies:  11%|▊       | 1060/10000 [01:40<12:38, 11.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4780/12392 [00:00<00:00, 47792\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3194\u001b[A\n",
      "Simulating N-1 Contingencies:  11%|▊       | 1069/10000 [01:41<10:38, 13.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4807/12392 [00:00<00:00, 48063\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4860\u001b[A\n",
      "Simulating N-1 Contingencies:  11%|▊       | 1071/10000 [01:41<12:05, 12.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4905/12392 [00:00<00:00, 49044\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3259\u001b[A\n",
      "Simulating N-1 Contingencies:  11%|▊       | 1073/10000 [01:42<15:03,  9.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4675/12392 [00:00<00:00, 46745\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4785\u001b[A\n",
      "Simulating N-1 Contingencies:  11%|▊       | 1075/10000 [01:42<16:21,  9.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4799/12392 [00:00<00:00, 47981\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3160\u001b[A\n",
      "Simulating N-1 Contingencies:  11%|▊       | 1081/10000 [01:42<14:25, 10.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4734/12392 [00:00<00:00, 47329\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4820\u001b[A\n",
      "Simulating N-1 Contingencies:  11%|▊       | 1082/10000 [01:43<17:01,  8.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4794/12392 [00:00<00:00, 47929\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4852\u001b[A\n",
      "Simulating N-1 Contingencies:  11%|▊       | 1083/10000 [01:43<19:57,  7.44it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:  11%|▊       | 1089/10000 [01:43<12:30, 11.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4615/12392 [00:00<00:00, 45959\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4667\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4719/12392 [00:00<00:00, 47179\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4827\u001b[A\n",
      "Simulating N-1 Contingencies:  11%|▊       | 1091/10000 [01:44<18:21,  8.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4766/12392 [00:00<00:00, 47658\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4878\u001b[A\n",
      "Simulating N-1 Contingencies:  11%|▊       | 1093/10000 [01:44<21:04,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4717/12392 [00:00<00:00, 47162\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4791\u001b[A\n",
      "Simulating N-1 Contingencies:  11%|▉       | 1096/10000 [01:45<21:06,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4693/12392 [00:00<00:00, 46921\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4838\u001b[A\n",
      "Simulating N-1 Contingencies:  11%|▉       | 1097/10000 [01:45<24:38,  6.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4840/12392 [00:00<00:00, 48389\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4841\u001b[A\n",
      "Simulating N-1 Contingencies:  11%|▉       | 1101/10000 [01:45<18:18,  8.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4920/12392 [00:00<00:00, 49192\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4938\u001b[A\n",
      "Simulating N-1 Contingencies:  11%|▉       | 1102/10000 [01:46<24:23,  6.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4949/12392 [00:00<00:00, 49483\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4949\u001b[A\n",
      "Simulating N-1 Contingencies:  11%|▉       | 1106/10000 [01:46<18:56,  7.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4878/12392 [00:00<00:00, 48779\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4889\u001b[A\n",
      "Simulating N-1 Contingencies:  11%|▉       | 1113/10000 [01:46<12:09, 12.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4759/12392 [00:00<00:00, 47581\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3157\u001b[A\n",
      "Simulating N-1 Contingencies:  11%|▉       | 1115/10000 [01:47<15:59,  9.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4753/12392 [00:00<00:00, 47526\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4871\u001b[A\n",
      "Simulating N-1 Contingencies:  11%|▉       | 1118/10000 [01:47<15:43,  9.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4863/12392 [00:00<00:00, 48620\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4898\u001b[A\n",
      "Simulating N-1 Contingencies:  11%|▉       | 1120/10000 [01:47<16:59,  8.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  15%|▏| 1919/12392 [00:00<00:00, 10970\u001b[A\n",
      "Converting scenarios to PyG Data objects:  53%|▌| 6580/12392 [00:00<00:00, 26990\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3148\u001b[A\n",
      "Simulating N-1 Contingencies:  11%|▉       | 1121/10000 [01:48<23:05,  6.41it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4876/12392 [00:00<00:00, 48757\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4867\u001b[A\n",
      "Simulating N-1 Contingencies:  11%|▉       | 1126/10000 [01:48<16:30,  8.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  19%|▏| 2352/12392 [00:00<00:00, 13401\u001b[A\n",
      "Converting scenarios to PyG Data objects:  58%|▌| 7207/12392 [00:00<00:00, 29172\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3249\u001b[A\n",
      "Simulating N-1 Contingencies:  11%|▉       | 1133/10000 [01:49<13:19, 11.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4799/12392 [00:00<00:00, 47982\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4865\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  30%|▎| 3659/12392 [00:00<00:00, 17983\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3233\u001b[A\n",
      "Simulating N-1 Contingencies:  11%|▉       | 1135/10000 [01:49<19:36,  7.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4859/12392 [00:00<00:00, 48583\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4883\u001b[A\n",
      "Simulating N-1 Contingencies:  11%|▉       | 1141/10000 [01:50<14:52,  9.92it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  34%|▎| 4267/12392 [00:00<00:00, 19831\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3258\u001b[A\n",
      "Simulating N-1 Contingencies:  11%|▉       | 1145/10000 [01:50<15:18,  9.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4839/12392 [00:00<00:00, 48385\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4856\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4718/12392 [00:00<00:00, 47175\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3163\u001b[A\n",
      "Simulating N-1 Contingencies:  11%|▉       | 1147/10000 [01:51<21:24,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4938/12392 [00:00<00:00, 49375\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4932\u001b[A\n",
      "Simulating N-1 Contingencies:  12%|▉       | 1150/10000 [01:51<19:37,  7.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4687/12392 [00:00<00:00, 46867\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3183\u001b[A\n",
      "Simulating N-1 Contingencies:  12%|▉       | 1151/10000 [01:51<24:17,  6.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4695/12392 [00:00<00:00, 46942\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4834\u001b[A\n",
      "Simulating N-1 Contingencies:  12%|▉       | 1152/10000 [01:52<26:40,  5.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4851/12392 [00:00<00:00, 48509\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3222\u001b[A\n",
      "Simulating N-1 Contingencies:  12%|▉       | 1155/10000 [01:52<24:41,  5.97it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4759/12392 [00:00<00:00, 47584\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4859\u001b[A\n",
      "Simulating N-1 Contingencies:  12%|▉       | 1161/10000 [01:53<16:15,  9.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4808/12392 [00:00<00:00, 48074\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4816\u001b[A\n",
      "Simulating N-1 Contingencies:  12%|▉       | 1168/10000 [01:53<12:10, 12.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4817/12392 [00:00<00:00, 48168\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4889\u001b[A\n",
      "Simulating N-1 Contingencies:  12%|▉       | 1173/10000 [01:53<11:13, 13.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4892/12392 [00:00<00:00, 48911\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4922\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4858/12392 [00:00<00:00, 48570\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4904\u001b[A\n",
      "Simulating N-1 Contingencies:  12%|▉       | 1175/10000 [01:54<17:52,  8.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4919/12392 [00:00<00:00, 49188\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4926\u001b[A\n",
      "Simulating N-1 Contingencies:  12%|▉       | 1179/10000 [01:54<16:48,  8.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4859/12392 [00:00<00:00, 48589\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4918\u001b[A\n",
      "Simulating N-1 Contingencies:  12%|▉       | 1183/10000 [01:55<14:45,  9.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4834/12392 [00:00<00:00, 48337\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4878\u001b[A\n",
      "Simulating N-1 Contingencies:  12%|▉       | 1188/10000 [01:55<13:56, 10.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4827/12392 [00:00<00:00, 48266\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4910\u001b[A\n",
      "Simulating N-1 Contingencies:  12%|▉       | 1206/10000 [01:56<05:54, 24.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4822/12392 [00:00<00:00, 48210\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3136\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4869/12392 [00:00<00:00, 48679\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4915\u001b[A\n",
      "Simulating N-1 Contingencies:  12%|▉       | 1210/10000 [01:56<10:29, 13.97it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:  12%|▉       | 1219/10000 [01:57<06:50, 21.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4859/12392 [00:00<00:00, 48583\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3204\u001b[A\n",
      "Simulating N-1 Contingencies:  12%|▉       | 1224/10000 [01:57<08:29, 17.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4766/12392 [00:00<00:00, 47653\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4818\u001b[A\n",
      "Simulating N-1 Contingencies:  12%|▉       | 1232/10000 [01:57<07:49, 18.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4861/12392 [00:00<00:00, 48602\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4892\u001b[A\n",
      "Simulating N-1 Contingencies:  12%|▉       | 1235/10000 [01:58<10:00, 14.59it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4811/12392 [00:00<00:00, 48098\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4829\u001b[A\n",
      "Simulating N-1 Contingencies:  12%|▉       | 1238/10000 [01:58<10:56, 13.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4807/12392 [00:00<00:00, 48063\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4849\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   4%| | 438/12392 [00:00<00:03, 3153.8\u001b[A\n",
      "Converting scenarios to PyG Data objects:  42%|▍| 5203/12392 [00:00<00:00, 25713\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3181\u001b[A\n",
      "Simulating N-1 Contingencies:  13%|█       | 1258/10000 [01:59<06:15, 23.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4528/12392 [00:00<00:00, 45260\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3070\u001b[A\n",
      "/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:  13%|█       | 1263/10000 [01:59<08:09, 17.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4814/12392 [00:00<00:00, 48135\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4868\u001b[A\n",
      "Simulating N-1 Contingencies:  13%|█       | 1270/10000 [02:00<07:52, 18.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4880/12392 [00:00<00:00, 48793\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4913\u001b[A\n",
      "Simulating N-1 Contingencies:  13%|█       | 1274/10000 [02:00<09:36, 15.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4899/12392 [00:00<00:00, 48982\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4948\u001b[A\n",
      "Simulating N-1 Contingencies:  13%|█       | 1277/10000 [02:01<10:30, 13.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4877/12392 [00:00<00:00, 48659\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3230\u001b[A\n",
      "Simulating N-1 Contingencies:  13%|█       | 1280/10000 [02:01<12:41, 11.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4852/12392 [00:00<00:00, 48516\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4904\u001b[A\n",
      "Simulating N-1 Contingencies:  13%|█       | 1283/10000 [02:01<13:07, 11.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4819/12392 [00:00<00:00, 48182\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4885\u001b[A\n",
      "Simulating N-1 Contingencies:  13%|█       | 1285/10000 [02:02<14:33,  9.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  27%|▎| 3398/12392 [00:00<00:00, 17485\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3265\u001b[A\n",
      "Simulating N-1 Contingencies:  13%|█       | 1287/10000 [02:02<17:46,  8.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4825/12392 [00:00<00:00, 48242\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4744\u001b[A\n",
      "Simulating N-1 Contingencies:  13%|█       | 1292/10000 [02:02<14:21, 10.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  24%|▏| 2961/12392 [00:00<00:00, 15755\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3249\u001b[A\n",
      "Simulating N-1 Contingencies:  13%|█       | 1296/10000 [02:03<14:55,  9.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4829/12392 [00:00<00:00, 48289\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4878\u001b[A\n",
      "Simulating N-1 Contingencies:  13%|█       | 1298/10000 [02:03<16:05,  9.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4703/12392 [00:00<00:00, 20913\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3192\u001b[A\n",
      "Simulating N-1 Contingencies:  13%|█       | 1299/10000 [02:03<21:17,  6.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4524/12392 [00:00<00:00, 45236\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4720\u001b[A\n",
      "Simulating N-1 Contingencies:  13%|█       | 1302/10000 [02:04<19:10,  7.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4867/12392 [00:00<00:00, 48666\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3253\u001b[A\n",
      "Simulating N-1 Contingencies:  13%|█       | 1304/10000 [02:04<21:53,  6.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4851/12392 [00:00<00:00, 48507\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4892\u001b[A\n",
      "Simulating N-1 Contingencies:  13%|█       | 1306/10000 [02:05<21:39,  6.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4888/12392 [00:00<00:00, 48871\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3122\u001b[A\n",
      "Simulating N-1 Contingencies:  13%|█       | 1307/10000 [02:05<27:48,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  36%|▎| 4515/12392 [00:00<00:00, 45141\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4682\u001b[A\n",
      "Simulating N-1 Contingencies:  13%|█       | 1308/10000 [02:05<30:22,  4.77it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:  13%|█       | 1317/10000 [02:05<10:21, 13.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4835/12392 [00:00<00:00, 48349\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3073\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4870/12392 [00:00<00:00, 48693\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4898\u001b[A\n",
      "Simulating N-1 Contingencies:  13%|█       | 1320/10000 [02:06<16:25,  8.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4525/12392 [00:00<00:00, 45240\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3085\u001b[A\n",
      "Simulating N-1 Contingencies:  13%|█       | 1327/10000 [02:07<13:39, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4845/12392 [00:00<00:00, 48442\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4497\u001b[A\n",
      "Simulating N-1 Contingencies:  13%|█       | 1333/10000 [02:07<11:52, 12.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4664/12392 [00:00<00:00, 46629\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4753\u001b[A\n",
      "Simulating N-1 Contingencies:  13%|█       | 1341/10000 [02:07<09:48, 14.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  14%|▏| 1745/12392 [00:00<00:01, 10113\u001b[A\n",
      "Converting scenarios to PyG Data objects:  52%|▌| 6392/12392 [00:00<00:00, 26579\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3116\u001b[A\n",
      "Simulating N-1 Contingencies:  13%|█       | 1343/10000 [02:08<12:33, 11.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4650/12392 [00:00<00:00, 46494\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4610\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  20%|▏| 2441/12392 [00:00<00:00, 13609\u001b[A\n",
      "Converting scenarios to PyG Data objects:  58%|▌| 7146/12392 [00:00<00:00, 28434\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3187\u001b[A\n",
      "Simulating N-1 Contingencies:  13%|█       | 1345/10000 [02:08<18:26,  7.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4725/12392 [00:00<00:00, 47242\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4790\u001b[A\n",
      "Simulating N-1 Contingencies:  14%|█       | 1357/10000 [02:09<09:27, 15.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  13%|▏| 1656/12392 [00:00<00:01, 10303\u001b[A\n",
      "Converting scenarios to PyG Data objects:  51%|▌| 6380/12392 [00:00<00:00, 27683\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3192\u001b[A\n",
      "Simulating N-1 Contingencies:  14%|█       | 1361/10000 [02:09<11:07, 12.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4814/12392 [00:00<00:00, 48132\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4836\u001b[A\n",
      "Simulating N-1 Contingencies:  14%|█       | 1364/10000 [02:10<11:52, 12.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  13%|▏| 1656/12392 [00:00<00:01, 10379\u001b[A\n",
      "Converting scenarios to PyG Data objects:  53%|▌| 6527/12392 [00:00<00:00, 28480\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3258\u001b[A\n",
      "Simulating N-1 Contingencies:  14%|█       | 1370/10000 [02:10<11:36, 12.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4833/12392 [00:00<00:00, 48326\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4856\u001b[A\n",
      "Simulating N-1 Contingencies:  14%|█       | 1378/10000 [02:10<09:30, 15.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  13%|▏| 1656/12392 [00:00<00:01, 10292\u001b[A\n",
      "Converting scenarios to PyG Data objects:  52%|▌| 6504/12392 [00:00<00:00, 28250\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3237\u001b[A\n",
      "Simulating N-1 Contingencies:  14%|█       | 1381/10000 [02:11<11:33, 12.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4847/12392 [00:00<00:00, 48466\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4869\u001b[A\n",
      "Simulating N-1 Contingencies:  14%|█       | 1383/10000 [02:11<12:56, 11.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  16%|▏| 2004/12392 [00:00<00:00, 11535\u001b[A\n",
      "Converting scenarios to PyG Data objects:  54%|▌| 6684/12392 [00:00<00:00, 27447\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3145\u001b[A\n",
      "Simulating N-1 Contingencies:  14%|█       | 1388/10000 [02:12<13:10, 10.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4727/12392 [00:00<00:00, 47264\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4748\u001b[A\n",
      "Simulating N-1 Contingencies:  14%|█       | 1390/10000 [02:12<14:33,  9.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  22%|▏| 2702/12392 [00:00<00:00, 14790\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3242\u001b[A\n",
      "Simulating N-1 Contingencies:  14%|█       | 1392/10000 [02:12<17:34,  8.16it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4571/12392 [00:00<00:00, 45708\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4768\u001b[A\n",
      "Simulating N-1 Contingencies:  14%|█       | 1398/10000 [02:13<13:23, 10.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  28%|▎| 3485/12392 [00:00<00:00, 17342\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3220\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4772/12392 [00:00<00:00, 47713\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4867\u001b[A\n",
      "Simulating N-1 Contingencies:  14%|█       | 1400/10000 [02:13<19:43,  7.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4790/12392 [00:00<00:00, 20354\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3114\u001b[A\n",
      "Simulating N-1 Contingencies:  14%|█       | 1401/10000 [02:14<24:18,  5.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4655/12392 [00:00<00:00, 46544\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4767\u001b[A\n",
      "Simulating N-1 Contingencies:  14%|█       | 1403/10000 [02:14<23:34,  6.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4766/12392 [00:00<00:00, 47650\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3132\u001b[A\n",
      "Simulating N-1 Contingencies:  14%|█       | 1405/10000 [02:15<25:32,  5.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4852/12392 [00:00<00:00, 48515\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4858\u001b[A\n",
      "Simulating N-1 Contingencies:  14%|█▏      | 1410/10000 [02:15<17:50,  8.02it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4665/12392 [00:00<00:00, 46640\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3155\u001b[A\n",
      "Simulating N-1 Contingencies:  14%|█▏      | 1413/10000 [02:15<18:50,  7.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  25%|▏| 3058/12392 [00:00<00:00, 30572\u001b[A\n",
      "Converting scenarios to PyG Data objects:  61%|▌| 7604/12392 [00:00<00:00, 39326\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4092\u001b[A\n",
      "Simulating N-1 Contingencies:  14%|█▏      | 1416/10000 [02:16<18:15,  7.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4668/12392 [00:00<00:00, 46673\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3085\u001b[A\n",
      "Simulating N-1 Contingencies:  14%|█▏      | 1417/10000 [02:16<23:30,  6.08it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4849/12392 [00:00<00:00, 48478\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4867\u001b[A\n",
      "Simulating N-1 Contingencies:  14%|█▏      | 1423/10000 [02:16<15:37,  9.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  31%|▎| 3871/12392 [00:00<00:00, 38708\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4448\u001b[A\n",
      "Simulating N-1 Contingencies:  14%|█▏      | 1430/10000 [02:17<12:33, 11.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4644/12392 [00:00<00:00, 46432\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4325\u001b[A\n",
      "Simulating N-1 Contingencies:  14%|█▏      | 1433/10000 [02:17<13:32, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4658/12392 [00:00<00:00, 46579\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 2970\u001b[A\n",
      "Simulating N-1 Contingencies:  14%|█▏      | 1438/10000 [02:18<13:46, 10.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4669/12392 [00:00<00:00, 46684\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4735\u001b[A\n",
      "Simulating N-1 Contingencies:  14%|█▏      | 1440/10000 [02:18<15:12,  9.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  35%|▎| 4394/12392 [00:00<00:00, 42773\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4443\u001b[A\n",
      "Simulating N-1 Contingencies:  14%|█▏      | 1442/10000 [02:18<16:45,  8.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  18%|▏| 2265/12392 [00:00<00:00, 12100\u001b[A\n",
      "Converting scenarios to PyG Data objects:  55%|▌| 6838/12392 [00:00<00:00, 26654\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3043\u001b[A\n",
      "Simulating N-1 Contingencies:  14%|█▏      | 1444/10000 [02:19<20:12,  7.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4698/12392 [00:00<00:00, 46974\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4760\u001b[A\n",
      "Simulating N-1 Contingencies:  14%|█▏      | 1446/10000 [02:19<20:30,  6.95it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  18%|▏| 2178/12392 [00:00<00:00, 12593\u001b[A\n",
      "Converting scenarios to PyG Data objects:  55%|▌| 6849/12392 [00:00<00:00, 28024\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3172\u001b[A\n",
      "Simulating N-1 Contingencies:  14%|█▏      | 1450/10000 [02:20<18:48,  7.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4690/12392 [00:00<00:00, 46892\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4720\u001b[A\n",
      "Simulating N-1 Contingencies:  15%|█▏      | 1452/10000 [02:20<19:25,  7.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  25%|▎| 3135/12392 [00:00<00:00, 15871\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3173\u001b[A\n",
      "Simulating N-1 Contingencies:  15%|█▏      | 1456/10000 [02:20<18:11,  7.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4676/12392 [00:00<00:00, 46752\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4713\u001b[A\n",
      "Simulating N-1 Contingencies:  15%|█▏      | 1458/10000 [02:21<18:57,  7.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  26%|▎| 3222/12392 [00:00<00:00, 15926\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3137\u001b[A\n",
      "Simulating N-1 Contingencies:  15%|█▏      | 1468/10000 [02:21<10:18, 13.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4735/12392 [00:00<00:00, 47346\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4756\u001b[A\n",
      "Simulating N-1 Contingencies:  15%|█▏      | 1471/10000 [02:22<11:23, 12.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  21%|▏| 2614/12392 [00:00<00:00, 14165\u001b[A\n",
      "Converting scenarios to PyG Data objects:  59%|▌| 7309/12392 [00:00<00:00, 28469\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3160\u001b[A\n",
      "Simulating N-1 Contingencies:  15%|█▏      | 1474/10000 [02:22<13:49, 10.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4713/12392 [00:00<00:00, 47124\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4383\u001b[A\n",
      "Simulating N-1 Contingencies:  15%|█▏      | 1476/10000 [02:22<15:34,  9.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  27%|▎| 3398/12392 [00:00<00:00, 14662\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 2915\u001b[A\n",
      "Simulating N-1 Contingencies:  15%|█▏      | 1480/10000 [02:23<16:15,  8.74it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4713/12392 [00:00<00:00, 47122\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4746\u001b[A\n",
      "Simulating N-1 Contingencies:  15%|█▏      | 1487/10000 [02:23<12:06, 11.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  34%|▎| 4181/12392 [00:00<00:00, 18425\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3105\u001b[A\n",
      "Simulating N-1 Contingencies:  15%|█▏      | 1489/10000 [02:24<15:12,  9.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4727/12392 [00:00<00:00, 47265\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4766\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4620/12392 [00:00<00:00, 46191\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3157\u001b[A\n",
      "Simulating N-1 Contingencies:  15%|█▏      | 1491/10000 [02:24<21:44,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4689/12392 [00:00<00:00, 46883\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4719\u001b[A\n",
      "Simulating N-1 Contingencies:  15%|█▏      | 1492/10000 [02:25<24:00,  5.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4686/12392 [00:00<00:00, 46852\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3057\u001b[A\n",
      "Simulating N-1 Contingencies:  15%|█▏      | 1496/10000 [02:25<21:04,  6.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4714/12392 [00:00<00:00, 47132\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4744\u001b[A\n",
      "Simulating N-1 Contingencies:  15%|█▏      | 1500/10000 [02:25<17:37,  8.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4748/12392 [00:00<00:00, 47477\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 2841\u001b[A\n",
      "Simulating N-1 Contingencies:  15%|█▏      | 1501/10000 [02:26<23:10,  6.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4606/12392 [00:00<00:00, 46054\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4659\u001b[A\n",
      "Simulating N-1 Contingencies:  15%|█▏      | 1505/10000 [02:26<18:39,  7.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4682/12392 [00:00<00:00, 46816\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3064\u001b[A\n",
      "Simulating N-1 Contingencies:  15%|█▏      | 1508/10000 [02:27<19:32,  7.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4689/12392 [00:00<00:00, 46880\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4724\u001b[A\n",
      "Simulating N-1 Contingencies:  15%|█▏      | 1512/10000 [02:27<16:39,  8.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4743/12392 [00:00<00:00, 47426\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4804\u001b[A\n",
      "Simulating N-1 Contingencies:  15%|█▏      | 1523/10000 [02:28<09:51, 14.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4777/12392 [00:00<00:00, 47763\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4796\u001b[A\n",
      "Simulating N-1 Contingencies:  15%|█▏      | 1528/10000 [02:28<09:43, 14.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4694/12392 [00:00<00:00, 46932\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3097\u001b[A\n",
      "Simulating N-1 Contingencies:  15%|█▏      | 1532/10000 [02:28<11:31, 12.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4709/12392 [00:00<00:00, 47078\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4729\u001b[A\n",
      "Simulating N-1 Contingencies:  15%|█▏      | 1543/10000 [02:29<07:31, 18.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4644/12392 [00:00<00:00, 46432\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4671\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  14%|▏| 1743/12392 [00:00<00:01, 9794.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  51%|▌| 6289/12392 [00:00<00:00, 25674\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3033\u001b[A\n",
      "Simulating N-1 Contingencies:  15%|█▏      | 1547/10000 [02:30<12:12, 11.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4667/12392 [00:00<00:00, 46660\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4678\u001b[A\n",
      "/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:  16%|█▏      | 1550/10000 [02:30<12:48, 11.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  23%|▏| 2874/12392 [00:00<00:00, 13779\u001b[A\n",
      "Converting scenarios to PyG Data objects:  61%|▌| 7579/12392 [00:00<00:00, 27302\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3011\u001b[A\n",
      "Simulating N-1 Contingencies:  16%|█▏      | 1552/10000 [02:30<15:56,  8.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4678/12392 [00:00<00:00, 46777\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4569\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4599/12392 [00:00<00:00, 45983\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3164\u001b[A\n",
      "Simulating N-1 Contingencies:  16%|█▏      | 1554/10000 [02:31<22:33,  6.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  32%|▎| 4023/12392 [00:00<00:00, 40226\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4481\u001b[A\n",
      "Simulating N-1 Contingencies:  16%|█▎      | 1566/10000 [02:31<10:05, 13.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  36%|▎| 4441/12392 [00:00<00:00, 18772\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3056\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4804/12392 [00:00<00:00, 48031\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4822\u001b[A\n",
      "Simulating N-1 Contingencies:  16%|█▎      | 1570/10000 [02:32<14:12,  9.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4848/12392 [00:00<00:00, 48475\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3240\u001b[A\n",
      "Simulating N-1 Contingencies:  16%|█▎      | 1573/10000 [02:33<15:36,  9.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4678/12392 [00:00<00:00, 46776\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4775\u001b[A\n",
      "Simulating N-1 Contingencies:  16%|█▎      | 1575/10000 [02:33<16:32,  8.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4612/12392 [00:00<00:00, 46108\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3167\u001b[A\n",
      "Simulating N-1 Contingencies:  16%|█▎      | 1577/10000 [02:33<19:12,  7.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4881/12392 [00:00<00:00, 48800\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4888\u001b[A\n",
      "Simulating N-1 Contingencies:  16%|█▎      | 1580/10000 [02:34<17:41,  7.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4888/12392 [00:00<00:00, 48877\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3259\u001b[A\n",
      "Simulating N-1 Contingencies:  16%|█▎      | 1582/10000 [02:34<20:14,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  35%|▎| 4390/12392 [00:00<00:00, 43891\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4529\u001b[A\n",
      "Simulating N-1 Contingencies:  16%|█▎      | 1594/10000 [02:35<09:26, 14.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  34%|▎| 4270/12392 [00:00<00:00, 42688\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:01<00:00, 1066\u001b[A\n",
      "Simulating N-1 Contingencies:  16%|█▎      | 1601/10000 [02:36<15:59,  8.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  36%|▎| 4507/12392 [00:00<00:00, 45063\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4607\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  26%|▎| 3269/12392 [00:00<00:00, 32688\u001b[A\n",
      "Converting scenarios to PyG Data objects:  64%|▋| 7963/12392 [00:00<00:00, 41066\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 2708\u001b[A\n",
      "Simulating N-1 Contingencies:  16%|█▎      | 1604/10000 [02:37<20:13,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4705/12392 [00:00<00:00, 47044\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4578\u001b[A\n",
      "Simulating N-1 Contingencies:  16%|█▎      | 1610/10000 [02:37<15:59,  8.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4679/12392 [00:00<00:00, 46782\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4724\u001b[A\n",
      "Simulating N-1 Contingencies:  16%|█▎      | 1616/10000 [02:37<13:22, 10.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  13%|▏| 1656/12392 [00:00<00:01, 9635.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  51%|▌| 6297/12392 [00:00<00:00, 26324\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3107\u001b[A\n",
      "Simulating N-1 Contingencies:  16%|█▎      | 1619/10000 [02:38<14:51,  9.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4652/12392 [00:00<00:00, 46510\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4718\u001b[A\n",
      "Simulating N-1 Contingencies:  16%|█▎      | 1621/10000 [02:38<15:50,  8.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  16%|▏| 2004/12392 [00:00<00:00, 11497\u001b[A\n",
      "Converting scenarios to PyG Data objects:  51%|▌| 6286/12392 [00:00<00:00, 25605\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3067\u001b[A\n",
      "Simulating N-1 Contingencies:  16%|█▎      | 1626/10000 [02:39<14:59,  9.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4801/12392 [00:00<00:00, 48006\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4784\u001b[A\n",
      "Simulating N-1 Contingencies:  16%|█▎      | 1628/10000 [02:39<15:59,  8.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  20%|▏| 2526/12392 [00:00<00:00, 13770\u001b[A\n",
      "Converting scenarios to PyG Data objects:  59%|▌| 7366/12392 [00:00<00:00, 28930\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3191\u001b[A\n",
      "Simulating N-1 Contingencies:  16%|█▎      | 1631/10000 [02:39<17:10,  8.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4822/12392 [00:00<00:00, 48215\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4885\u001b[A\n",
      "Simulating N-1 Contingencies:  16%|█▎      | 1633/10000 [02:40<17:48,  7.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  30%|▎| 3659/12392 [00:00<00:00, 17737\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3223\u001b[A\n",
      "Simulating N-1 Contingencies:  16%|█▎      | 1635/10000 [02:40<20:24,  6.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4855/12392 [00:00<00:00, 48540\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4881\u001b[A\n",
      "Simulating N-1 Contingencies:  16%|█▎      | 1642/10000 [02:40<13:18, 10.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  36%|▎| 4454/12392 [00:00<00:00, 44534\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3077\u001b[A\n",
      "Simulating N-1 Contingencies:  16%|█▎      | 1644/10000 [02:41<16:23,  8.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4747/12392 [00:00<00:00, 47462\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4808\u001b[A\n",
      "Simulating N-1 Contingencies:  16%|█▎      | 1645/10000 [02:41<18:58,  7.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4797/12392 [00:00<00:00, 47968\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3084\u001b[A\n",
      "Simulating N-1 Contingencies:  16%|█▎      | 1647/10000 [02:42<21:49,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4759/12392 [00:00<00:00, 47589\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4799\u001b[A\n",
      "Simulating N-1 Contingencies:  17%|█▎      | 1651/10000 [02:42<17:26,  7.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4728/12392 [00:00<00:00, 47278\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3104\u001b[A\n",
      "Simulating N-1 Contingencies:  17%|█▎      | 1653/10000 [02:42<20:23,  6.82it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4860/12392 [00:00<00:00, 48593\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4894\u001b[A\n",
      "Simulating N-1 Contingencies:  17%|█▎      | 1662/10000 [02:43<11:43, 11.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4875/12392 [00:00<00:00, 48747\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3210\u001b[A\n",
      "Simulating N-1 Contingencies:  17%|█▎      | 1666/10000 [02:43<12:46, 10.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4873/12392 [00:00<00:00, 48724\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4904\u001b[A\n",
      "Simulating N-1 Contingencies:  17%|█▎      | 1670/10000 [02:44<12:14, 11.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4894/12392 [00:00<00:00, 48933\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3212\u001b[A\n",
      "Simulating N-1 Contingencies:  17%|█▎      | 1672/10000 [02:44<15:06,  9.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4880/12392 [00:00<00:00, 48792\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4933\u001b[A\n",
      "Simulating N-1 Contingencies:  17%|█▎      | 1673/10000 [02:44<17:34,  7.90it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4856/12392 [00:00<00:00, 48554\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4879\u001b[A\n",
      "Simulating N-1 Contingencies:  17%|█▎      | 1677/10000 [02:45<15:03,  9.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  13%|▏| 1571/12392 [00:00<00:01, 9989.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  52%|▌| 6401/12392 [00:00<00:00, 28222\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3250\u001b[A\n",
      "Simulating N-1 Contingencies:  17%|█▎      | 1679/10000 [02:45<18:00,  7.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4902/12392 [00:00<00:00, 49019\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4942\u001b[A\n",
      "Simulating N-1 Contingencies:  17%|█▎      | 1682/10000 [02:45<16:41,  8.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  22%|▏| 2702/12392 [00:00<00:00, 14951\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3286\u001b[A\n",
      "Simulating N-1 Contingencies:  17%|█▎      | 1683/10000 [02:46<21:45,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4897/12392 [00:00<00:00, 48966\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4931\u001b[A\n",
      "Simulating N-1 Contingencies:  17%|█▎      | 1686/10000 [02:46<18:55,  7.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  23%|▏| 2874/12392 [00:00<00:00, 15654\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3287\u001b[A\n",
      "Simulating N-1 Contingencies:  17%|█▎      | 1692/10000 [02:46<14:44,  9.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4868/12392 [00:00<00:00, 48674\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4891\u001b[A\n",
      "Simulating N-1 Contingencies:  17%|█▎      | 1693/10000 [02:47<17:17,  8.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4616/12392 [00:00<00:00, 20849\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3268\u001b[A\n",
      "Simulating N-1 Contingencies:  17%|█▎      | 1695/10000 [02:47<19:58,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4852/12392 [00:00<00:00, 48514\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4908\u001b[A\n",
      "Simulating N-1 Contingencies:  17%|█▎      | 1702/10000 [02:47<12:54, 10.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4929/12392 [00:00<00:00, 49285\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3267\u001b[A\n",
      "Simulating N-1 Contingencies:  17%|█▎      | 1706/10000 [02:48<13:36, 10.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4854/12392 [00:00<00:00, 48535\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4897\u001b[A\n",
      "Simulating N-1 Contingencies:  17%|█▎      | 1708/10000 [02:48<14:45,  9.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4863/12392 [00:00<00:00, 48621\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3253\u001b[A\n",
      "Simulating N-1 Contingencies:  17%|█▎      | 1709/10000 [02:49<19:25,  7.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4861/12392 [00:00<00:00, 48603\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4913\u001b[A\n",
      "Simulating N-1 Contingencies:  17%|█▎      | 1710/10000 [02:49<22:02,  6.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4835/12392 [00:00<00:00, 48345\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3227\u001b[A\n",
      "Simulating N-1 Contingencies:  17%|█▎      | 1713/10000 [02:49<21:14,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4809/12392 [00:00<00:00, 48085\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4903\u001b[A\n",
      "Simulating N-1 Contingencies:  17%|█▎      | 1717/10000 [02:50<16:54,  8.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4864/12392 [00:00<00:00, 48635\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3230\u001b[A\n",
      "Simulating N-1 Contingencies:  17%|█▍      | 1722/10000 [02:50<15:03,  9.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4797/12392 [00:00<00:00, 47964\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4897\u001b[A\n",
      "Simulating N-1 Contingencies:  17%|█▍      | 1726/10000 [02:50<13:41, 10.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4818/12392 [00:00<00:00, 48177\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4887\u001b[A\n",
      "Simulating N-1 Contingencies:  17%|█▍      | 1728/10000 [02:51<14:54,  9.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   7%| | 873/12392 [00:00<00:01, 6088.4\u001b[A\n",
      "Converting scenarios to PyG Data objects:  46%|▍| 5730/12392 [00:00<00:00, 27288\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3274\u001b[A\n",
      "Simulating N-1 Contingencies:  17%|█▍      | 1729/10000 [02:51<19:45,  6.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4847/12392 [00:00<00:00, 48467\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4864\u001b[A\n",
      "Simulating N-1 Contingencies:  17%|█▍      | 1740/10000 [02:52<10:52, 12.66it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4867/12392 [00:00<00:00, 48668\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4914\u001b[A\n",
      "Simulating N-1 Contingencies:  17%|█▍      | 1745/10000 [02:52<10:10, 13.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4839/12392 [00:00<00:00, 48388\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3224\u001b[A\n",
      "Simulating N-1 Contingencies:  18%|█▍      | 1750/10000 [02:52<10:59, 12.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4867/12392 [00:00<00:00, 48663\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4913\u001b[A\n",
      "Simulating N-1 Contingencies:  18%|█▍      | 1753/10000 [02:53<11:37, 11.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4905/12392 [00:00<00:00, 49038\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4930\u001b[A\n",
      "Simulating N-1 Contingencies:  18%|█▍      | 1755/10000 [02:53<13:03, 10.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  20%|▏| 2441/12392 [00:00<00:00, 13780\u001b[A\n",
      "Converting scenarios to PyG Data objects:  60%|▌| 7387/12392 [00:00<00:00, 29707\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3270\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4862/12392 [00:00<00:00, 48615\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4900\u001b[A\n",
      "Simulating N-1 Contingencies:  18%|█▍      | 1757/10000 [02:54<19:50,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  30%|▎| 3746/12392 [00:00<00:00, 18413\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3276\u001b[A\n",
      "Simulating N-1 Contingencies:  18%|█▍      | 1767/10000 [02:54<10:18, 13.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4854/12392 [00:00<00:00, 48533\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4898\u001b[A\n",
      "Simulating N-1 Contingencies:  18%|█▍      | 1770/10000 [02:54<11:05, 12.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  31%|▎| 3831/12392 [00:00<00:00, 18653\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3264\u001b[A\n",
      "Simulating N-1 Contingencies:  18%|█▍      | 1774/10000 [02:55<12:18, 11.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4893/12392 [00:00<00:00, 48927\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4906\u001b[A\n",
      "Simulating N-1 Contingencies:  18%|█▍      | 1776/10000 [02:55<13:39, 10.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4599/12392 [00:00<00:00, 45977\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 2996\u001b[A\n",
      "Simulating N-1 Contingencies:  18%|█▍      | 1779/10000 [02:56<15:43,  8.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4610/12392 [00:00<00:00, 46087\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4766\u001b[A\n",
      "Simulating N-1 Contingencies:  18%|█▍      | 1781/10000 [02:56<16:40,  8.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4885/12392 [00:00<00:00, 48846\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3021\u001b[A\n",
      "Simulating N-1 Contingencies:  18%|█▍      | 1783/10000 [02:56<19:53,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4873/12392 [00:00<00:00, 48725\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4882\u001b[A\n",
      "Simulating N-1 Contingencies:  18%|█▍      | 1785/10000 [02:57<19:53,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4879/12392 [00:00<00:00, 48787\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3223\u001b[A\n",
      "Simulating N-1 Contingencies:  18%|█▍      | 1786/10000 [02:57<25:18,  5.41it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4827/12392 [00:00<00:00, 48268\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4877\u001b[A\n",
      "Simulating N-1 Contingencies:  18%|█▍      | 1792/10000 [02:57<15:25,  8.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4877/12392 [00:00<00:00, 48760\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3237\u001b[A\n",
      "Simulating N-1 Contingencies:  18%|█▍      | 1796/10000 [02:58<15:20,  8.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4894/12392 [00:00<00:00, 48938\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4940\u001b[A\n",
      "Simulating N-1 Contingencies:  18%|█▍      | 1798/10000 [02:58<16:11,  8.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4891/12392 [00:00<00:00, 48905\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4915\u001b[A\n",
      "Simulating N-1 Contingencies:  18%|█▍      | 1809/10000 [02:59<09:22, 14.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4853/12392 [00:00<00:00, 48529\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4881\u001b[A\n",
      "Simulating N-1 Contingencies:  18%|█▍      | 1814/10000 [02:59<09:12, 14.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4868/12392 [00:00<00:00, 48674\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4919\u001b[A\n",
      "Simulating N-1 Contingencies:  18%|█▍      | 1816/10000 [02:59<12:10, 11.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4890/12392 [00:00<00:00, 48895\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4907\u001b[A\n",
      "Simulating N-1 Contingencies:  18%|█▍      | 1821/10000 [03:00<10:58, 12.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4862/12392 [00:00<00:00, 48615\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4897\u001b[A\n",
      "Simulating N-1 Contingencies:  18%|█▍      | 1823/10000 [03:00<12:28, 10.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4809/12392 [00:00<00:00, 48086\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4873\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4924/12392 [00:00<00:00, 49232\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4940\u001b[A\n",
      "Simulating N-1 Contingencies:  18%|█▍      | 1825/10000 [03:01<19:01,  7.16it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:  18%|█▍      | 1828/10000 [03:01<15:33,  8.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4839/12392 [00:00<00:00, 48381\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4904\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4908/12392 [00:00<00:00, 49072\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4934\u001b[A\n",
      "Simulating N-1 Contingencies:  18%|█▍      | 1830/10000 [03:01<20:22,  6.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4909/12392 [00:00<00:00, 49085\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4927\u001b[A\n",
      "Simulating N-1 Contingencies:  18%|█▍      | 1832/10000 [03:02<22:11,  6.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4924/12392 [00:00<00:00, 49231\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4931\u001b[A\n",
      "Simulating N-1 Contingencies:  18%|█▍      | 1836/10000 [03:02<17:30,  7.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4697/12392 [00:00<00:00, 46964\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4809\u001b[A\n",
      "Simulating N-1 Contingencies:  18%|█▍      | 1838/10000 [03:03<19:58,  6.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4895/12392 [00:00<00:00, 48946\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4924\u001b[A\n",
      "Simulating N-1 Contingencies:  18%|█▍      | 1845/10000 [03:03<14:00,  9.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4797/12392 [00:00<00:00, 47965\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4826\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4827/12392 [00:00<00:00, 48260\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4879\u001b[A\n",
      "Simulating N-1 Contingencies:  18%|█▍      | 1848/10000 [03:04<19:17,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4856/12392 [00:00<00:00, 48553\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4897\u001b[A\n",
      "Simulating N-1 Contingencies:  19%|█▍      | 1852/10000 [03:04<15:28,  8.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4880/12392 [00:00<00:00, 48791\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4936\u001b[A\n",
      "Simulating N-1 Contingencies:  19%|█▍      | 1855/10000 [03:05<16:45,  8.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4844/12392 [00:00<00:00, 48431\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4890\u001b[A\n",
      "Simulating N-1 Contingencies:  19%|█▍      | 1857/10000 [03:05<17:37,  7.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4871/12392 [00:00<00:00, 48707\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4929\u001b[A\n",
      "Simulating N-1 Contingencies:  19%|█▍      | 1860/10000 [03:05<18:13,  7.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4862/12392 [00:00<00:00, 48612\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4912\u001b[A\n",
      "Simulating N-1 Contingencies:  19%|█▍      | 1863/10000 [03:06<16:14,  8.35it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4895/12392 [00:00<00:00, 48945\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3245\u001b[A\n",
      "Simulating N-1 Contingencies:  19%|█▍      | 1867/10000 [03:06<15:40,  8.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4766/12392 [00:00<00:00, 47659\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4836\u001b[A\n",
      "Simulating N-1 Contingencies:  19%|█▍      | 1873/10000 [03:06<11:45, 11.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4862/12392 [00:00<00:00, 48610\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4921\u001b[A\n",
      "Simulating N-1 Contingencies:  19%|█▌      | 1878/10000 [03:07<10:39, 12.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  18%|▏| 2180/12392 [00:00<00:00, 12848\u001b[A\n",
      "Converting scenarios to PyG Data objects:  57%|▌| 7073/12392 [00:00<00:00, 29341\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3268\u001b[A\n",
      "Simulating N-1 Contingencies:  19%|█▌      | 1881/10000 [03:07<12:43, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4870/12392 [00:00<00:00, 48698\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4856\u001b[A\n",
      "Simulating N-1 Contingencies:  19%|█▌      | 1883/10000 [03:07<14:02,  9.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  23%|▏| 2876/12392 [00:00<00:00, 15484\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3256\u001b[A\n",
      "Simulating N-1 Contingencies:  19%|█▌      | 1884/10000 [03:08<18:50,  7.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4792/12392 [00:00<00:00, 47916\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4851\u001b[A\n",
      "Simulating N-1 Contingencies:  19%|█▌      | 1885/10000 [03:08<21:34,  6.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  26%|▎| 3224/12392 [00:00<00:00, 16760\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3267\u001b[A\n",
      "Simulating N-1 Contingencies:  19%|█▌      | 1891/10000 [03:09<15:26,  8.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4822/12392 [00:00<00:00, 48213\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4884\u001b[A\n",
      "Simulating N-1 Contingencies:  19%|█▌      | 1894/10000 [03:09<14:55,  9.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  30%|▎| 3659/12392 [00:00<00:00, 18184\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3263\u001b[A\n",
      "Simulating N-1 Contingencies:  19%|█▌      | 1903/10000 [03:09<10:51, 12.44it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4840/12392 [00:00<00:00, 48393\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4876\u001b[A\n",
      "Simulating N-1 Contingencies:  19%|█▌      | 1909/10000 [03:10<09:44, 13.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  34%|▎| 4268/12392 [00:00<00:00, 19491\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3214\u001b[A\n",
      "Simulating N-1 Contingencies:  19%|█▌      | 1913/10000 [03:10<11:03, 12.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4879/12392 [00:00<00:00, 48785\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4930\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4932/12392 [00:00<00:00, 49312\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3266\u001b[A\n",
      "Simulating N-1 Contingencies:  19%|█▌      | 1915/10000 [03:11<16:14,  8.30it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4886/12392 [00:00<00:00, 48851\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4932\u001b[A\n",
      "Simulating N-1 Contingencies:  19%|█▌      | 1919/10000 [03:11<14:31,  9.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4927/12392 [00:00<00:00, 49261\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3160\u001b[A\n",
      "Simulating N-1 Contingencies:  19%|█▌      | 1924/10000 [03:12<13:50,  9.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  36%|▎| 4500/12392 [00:00<00:00, 44992\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4710\u001b[A\n",
      "Simulating N-1 Contingencies:  19%|█▌      | 1926/10000 [03:12<14:53,  9.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4835/12392 [00:00<00:00, 48341\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3180\u001b[A\n",
      "Simulating N-1 Contingencies:  19%|█▌      | 1927/10000 [03:12<19:13,  7.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4797/12392 [00:00<00:00, 47961\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4885\u001b[A\n",
      "Simulating N-1 Contingencies:  19%|█▌      | 1928/10000 [03:13<21:36,  6.22it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4566/12392 [00:00<00:00, 45653\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4701\u001b[A\n",
      "Simulating N-1 Contingencies:  19%|█▌      | 1934/10000 [03:13<15:59,  8.41it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:  19%|█▌      | 1942/10000 [03:13<07:42, 17.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4699/12392 [00:00<00:00, 46989\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4736\u001b[A\n",
      "Simulating N-1 Contingencies:  19%|█▌      | 1945/10000 [03:13<09:11, 14.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4850/12392 [00:00<00:00, 48498\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3199\u001b[A\n",
      "Simulating N-1 Contingencies:  19%|█▌      | 1948/10000 [03:14<11:49, 11.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4920/12392 [00:00<00:00, 49198\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4939\u001b[A\n",
      "Simulating N-1 Contingencies:  20%|█▌      | 1950/10000 [03:14<13:16, 10.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4882/12392 [00:00<00:00, 48814\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4913\u001b[A\n",
      "Simulating N-1 Contingencies:  20%|█▌      | 1954/10000 [03:14<12:16, 10.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  11%| | 1310/12392 [00:00<00:01, 8616.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  50%|▍| 6179/12392 [00:00<00:00, 28027\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3269\u001b[A\n",
      "Simulating N-1 Contingencies:  20%|█▌      | 1956/10000 [03:15<15:26,  8.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4861/12392 [00:00<00:00, 48601\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4889\u001b[A\n",
      "Simulating N-1 Contingencies:  20%|█▌      | 1960/10000 [03:15<13:37,  9.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  13%|▏| 1658/12392 [00:00<00:01, 9894.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  50%|▍| 6182/12392 [00:00<00:00, 26158\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3093\u001b[A\n",
      "Simulating N-1 Contingencies:  20%|█▌      | 1962/10000 [03:16<16:53,  7.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4582/12392 [00:00<00:00, 45818\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4748\u001b[A\n",
      "Simulating N-1 Contingencies:  20%|█▌      | 1966/10000 [03:16<14:37,  9.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  16%|▏| 2004/12392 [00:00<00:00, 11759\u001b[A\n",
      "Converting scenarios to PyG Data objects:  56%|▌| 6883/12392 [00:00<00:00, 28644\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3228\u001b[A\n",
      "Simulating N-1 Contingencies:  20%|█▌      | 1978/10000 [03:17<08:05, 16.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4680/12392 [00:00<00:00, 46795\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4736\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  16%|▏| 2006/12392 [00:00<00:00, 11945\u001b[A\n",
      "Converting scenarios to PyG Data objects:  56%|▌| 6887/12392 [00:00<00:00, 28889\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3254\u001b[A\n",
      "Simulating N-1 Contingencies:  20%|█▌      | 1982/10000 [03:17<12:11, 10.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4773/12392 [00:00<00:00, 47727\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4847\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  17%|▏| 2093/12392 [00:00<00:00, 12221\u001b[A\n",
      "Converting scenarios to PyG Data objects:  56%|▌| 6953/12392 [00:00<00:00, 28763\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3225\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4844/12392 [00:00<00:00, 48431\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4915\u001b[A\n",
      "Simulating N-1 Contingencies:  20%|█▌      | 1985/10000 [03:18<18:53,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  23%|▏| 2789/12392 [00:00<00:00, 15211\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3269\u001b[A\n",
      "Simulating N-1 Contingencies:  20%|█▌      | 1987/10000 [03:19<20:25,  6.54it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4861/12392 [00:00<00:00, 48605\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4886\u001b[A\n",
      "Simulating N-1 Contingencies:  20%|█▌      | 1994/10000 [03:19<14:04,  9.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  27%|▎| 3396/12392 [00:00<00:00, 16436\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3169\u001b[A\n",
      "Simulating N-1 Contingencies:  20%|█▌      | 1997/10000 [03:19<15:17,  8.73it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4743/12392 [00:00<00:00, 47422\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4833\u001b[A\n",
      "Simulating N-1 Contingencies:  20%|█▌      | 2001/10000 [03:20<13:54,  9.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4851/12392 [00:00<00:00, 48501\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3251\u001b[A\n",
      "Simulating N-1 Contingencies:  20%|█▌      | 2003/10000 [03:20<16:20,  8.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4879/12392 [00:00<00:00, 48785\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4918\u001b[A\n",
      "Simulating N-1 Contingencies:  20%|█▌      | 2005/10000 [03:20<16:53,  7.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4902/12392 [00:00<00:00, 49012\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3256\u001b[A\n",
      "Simulating N-1 Contingencies:  20%|█▌      | 2008/10000 [03:21<17:32,  7.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4876/12392 [00:00<00:00, 48757\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4910\u001b[A\n",
      "Simulating N-1 Contingencies:  20%|█▌      | 2010/10000 [03:21<17:54,  7.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4862/12392 [00:00<00:00, 48615\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3237\u001b[A\n",
      "Simulating N-1 Contingencies:  20%|█▌      | 2014/10000 [03:22<16:41,  7.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4844/12392 [00:00<00:00, 48430\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4907\u001b[A\n",
      "Simulating N-1 Contingencies:  20%|█▌      | 2016/10000 [03:22<17:14,  7.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4854/12392 [00:00<00:00, 48532\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3233\u001b[A\n",
      "Simulating N-1 Contingencies:  20%|█▌      | 2024/10000 [03:22<12:13, 10.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4874/12392 [00:00<00:00, 48735\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4909\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4889/12392 [00:00<00:00, 48879\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4925\u001b[A\n",
      "Simulating N-1 Contingencies:  20%|█▌      | 2026/10000 [03:23<16:14,  8.18it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   7%| | 875/12392 [00:00<00:01, 6128.4\u001b[A\n",
      "Converting scenarios to PyG Data objects:  46%|▍| 5748/12392 [00:00<00:00, 27433\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3280\u001b[A\n",
      "Simulating N-1 Contingencies:  20%|█▌      | 2029/10000 [03:23<16:56,  7.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4897/12392 [00:00<00:00, 48960\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4901\u001b[A\n",
      "Simulating N-1 Contingencies:  20%|█▌      | 2030/10000 [03:24<19:08,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   8%| | 961/12392 [00:00<00:01, 6667.3\u001b[A\n",
      "Converting scenarios to PyG Data objects:  47%|▍| 5835/12392 [00:00<00:00, 27607\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3282\u001b[A\n",
      "Simulating N-1 Contingencies:  20%|█▋      | 2033/10000 [03:24<19:03,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4623/12392 [00:00<00:00, 46221\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4688\u001b[A\n",
      "Simulating N-1 Contingencies:  20%|█▋      | 2038/10000 [03:24<14:40,  9.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  11%| | 1308/12392 [00:00<00:01, 8582.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  50%|▍| 6181/12392 [00:00<00:00, 28006\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3266\u001b[A\n",
      "Simulating N-1 Contingencies:  20%|█▋      | 2040/10000 [03:25<17:14,  7.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4836/12392 [00:00<00:00, 48356\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4881\u001b[A\n",
      "Simulating N-1 Contingencies:  20%|█▋      | 2042/10000 [03:25<17:41,  7.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  20%|▏| 2441/12392 [00:00<00:00, 13877\u001b[A\n",
      "Converting scenarios to PyG Data objects:  59%|▌| 7361/12392 [00:00<00:00, 29705\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3286\u001b[A\n",
      "Simulating N-1 Contingencies:  20%|█▋      | 2044/10000 [03:26<20:02,  6.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4921/12392 [00:00<00:00, 49207\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4934\u001b[A\n",
      "Simulating N-1 Contingencies:  20%|█▋      | 2046/10000 [03:26<19:47,  6.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  25%|▎| 3137/12392 [00:00<00:00, 16466\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3280\u001b[A\n",
      "Simulating N-1 Contingencies:  20%|█▋      | 2047/10000 [03:26<24:57,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4902/12392 [00:00<00:00, 49013\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4941\u001b[A\n",
      "Simulating N-1 Contingencies:  21%|█▋      | 2051/10000 [03:27<18:05,  7.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  30%|▎| 3659/12392 [00:00<00:00, 18293\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3279\u001b[A\n",
      "Simulating N-1 Contingencies:  21%|█▋      | 2052/10000 [03:27<23:07,  5.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4859/12392 [00:00<00:00, 48579\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4904\u001b[A\n",
      "Simulating N-1 Contingencies:  21%|█▋      | 2054/10000 [03:27<21:57,  6.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4853/12392 [00:00<00:00, 48520\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3264\u001b[A\n",
      "Simulating N-1 Contingencies:  21%|█▋      | 2061/10000 [03:28<14:16,  9.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4888/12392 [00:00<00:00, 48871\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4899\u001b[A\n",
      "Simulating N-1 Contingencies:  21%|█▋      | 2062/10000 [03:28<16:41,  7.93it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4889/12392 [00:00<00:00, 48884\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3265\u001b[A\n",
      "Simulating N-1 Contingencies:  21%|█▋      | 2066/10000 [03:28<15:53,  8.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4787/12392 [00:00<00:00, 47862\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4857\u001b[A\n",
      "Simulating N-1 Contingencies:  21%|█▋      | 2067/10000 [03:29<18:24,  7.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4922/12392 [00:00<00:00, 49217\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3252\u001b[A\n",
      "Simulating N-1 Contingencies:  21%|█▋      | 2069/10000 [03:29<20:48,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4773/12392 [00:00<00:00, 47724\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4847\u001b[A\n",
      "Simulating N-1 Contingencies:  21%|█▋      | 2074/10000 [03:29<15:04,  8.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4804/12392 [00:00<00:00, 48032\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3213\u001b[A\n",
      "Simulating N-1 Contingencies:  21%|█▋      | 2075/10000 [03:30<19:46,  6.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4844/12392 [00:00<00:00, 48430\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4889\u001b[A\n",
      "Simulating N-1 Contingencies:  21%|█▋      | 2080/10000 [03:30<14:37,  9.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4835/12392 [00:00<00:00, 48346\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3220\u001b[A\n",
      "Simulating N-1 Contingencies:  21%|█▋      | 2081/10000 [03:31<19:12,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4921/12392 [00:00<00:00, 49208\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4957\u001b[A\n",
      "Simulating N-1 Contingencies:  21%|█▋      | 2084/10000 [03:31<17:11,  7.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4895/12392 [00:00<00:00, 48943\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4913\u001b[A\n",
      "Simulating N-1 Contingencies:  21%|█▋      | 2085/10000 [03:31<19:50,  6.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  24%|▏| 2963/12392 [00:00<00:00, 15887\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3268\u001b[A\n",
      "Simulating N-1 Contingencies:  21%|█▋      | 2092/10000 [03:32<13:33,  9.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4653/12392 [00:00<00:00, 46527\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4725\u001b[A\n",
      "Simulating N-1 Contingencies:  21%|█▋      | 2096/10000 [03:32<12:37, 10.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  32%|▎| 3920/12392 [00:00<00:00, 18728\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3242\u001b[A\n",
      "Simulating N-1 Contingencies:  21%|█▋      | 2098/10000 [03:32<15:24,  8.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4885/12392 [00:00<00:00, 48843\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4904\u001b[A\n",
      "Simulating N-1 Contingencies:  21%|█▋      | 2100/10000 [03:33<16:10,  8.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4916/12392 [00:00<00:00, 49152\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3259\u001b[A\n",
      "Simulating N-1 Contingencies:  21%|█▋      | 2111/10000 [03:33<08:29, 15.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4863/12392 [00:00<00:00, 48627\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4919\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4914/12392 [00:00<00:00, 49130\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3266\u001b[A\n",
      "Simulating N-1 Contingencies:  21%|█▋      | 2114/10000 [03:34<13:18,  9.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4867/12392 [00:00<00:00, 48665\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4888\u001b[A\n",
      "Simulating N-1 Contingencies:  21%|█▋      | 2117/10000 [03:34<13:17,  9.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4860/12392 [00:00<00:00, 48593\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3237\u001b[A\n",
      "Simulating N-1 Contingencies:  21%|█▋      | 2119/10000 [03:35<15:56,  8.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4847/12392 [00:00<00:00, 48466\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4890\u001b[A\n",
      "Simulating N-1 Contingencies:  21%|█▋      | 2127/10000 [03:35<10:45, 12.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4840/12392 [00:00<00:00, 48394\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3231\u001b[A\n",
      "Simulating N-1 Contingencies:  21%|█▋      | 2129/10000 [03:35<13:22,  9.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4883/12392 [00:00<00:00, 48821\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4911\u001b[A\n",
      "Simulating N-1 Contingencies:  21%|█▋      | 2132/10000 [03:36<13:18,  9.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4905/12392 [00:00<00:00, 49047\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3252\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4852/12392 [00:00<00:00, 48512\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4908\u001b[A\n",
      "Simulating N-1 Contingencies:  21%|█▋      | 2134/10000 [03:36<19:20,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4867/12392 [00:00<00:00, 48663\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4889\u001b[A\n",
      "Simulating N-1 Contingencies:  21%|█▋      | 2136/10000 [03:37<19:16,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   1%| | 89/12392 [00:00<00:17, 708.45i\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4864/12392 [00:00<00:00, 25737\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3270\u001b[A\n",
      "Simulating N-1 Contingencies:  21%|█▋      | 2138/10000 [03:37<21:08,  6.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4908/12392 [00:00<00:00, 49075\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4930\u001b[A\n",
      "Simulating N-1 Contingencies:  21%|█▋      | 2143/10000 [03:38<15:18,  8.55it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4875/12392 [00:00<00:00, 48648\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4906\u001b[A\n",
      "Simulating N-1 Contingencies:  21%|█▋      | 2148/10000 [03:38<12:17, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4899/12392 [00:00<00:00, 48985\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3166\u001b[A\n",
      "Simulating N-1 Contingencies:  22%|█▋      | 2152/10000 [03:38<13:08,  9.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4852/12392 [00:00<00:00, 48510\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4877\u001b[A\n",
      "Simulating N-1 Contingencies:  22%|█▋      | 2154/10000 [03:39<14:16,  9.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4843/12392 [00:00<00:00, 48426\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4877\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  24%|▏| 2963/12392 [00:00<00:00, 15702\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3255\u001b[A\n",
      "Simulating N-1 Contingencies:  22%|█▋      | 2156/10000 [03:39<20:53,  6.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4759/12392 [00:00<00:00, 47582\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4864\u001b[A\n",
      "Simulating N-1 Contingencies:  22%|█▋      | 2164/10000 [03:40<12:36, 10.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  25%|▎| 3137/12392 [00:00<00:00, 16292\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3245\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4874/12392 [00:00<00:00, 48728\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4917\u001b[A\n",
      "Simulating N-1 Contingencies:  22%|█▋      | 2166/10000 [03:40<17:53,  7.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  34%|▎| 4268/12392 [00:00<00:00, 19328\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3127\u001b[A\n",
      "Simulating N-1 Contingencies:  22%|█▋      | 2169/10000 [03:41<18:16,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  36%|▎| 4425/12392 [00:00<00:00, 44248\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4742\u001b[A\n",
      "Simulating N-1 Contingencies:  22%|█▋      | 2171/10000 [03:41<18:30,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4813/12392 [00:00<00:00, 48123\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3214\u001b[A\n",
      "Simulating N-1 Contingencies:  22%|█▋      | 2172/10000 [03:41<22:52,  5.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4891/12392 [00:00<00:00, 48899\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4945\u001b[A\n",
      "Simulating N-1 Contingencies:  22%|█▋      | 2175/10000 [03:42<19:25,  6.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4869/12392 [00:00<00:00, 48682\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3179\u001b[A\n",
      "Simulating N-1 Contingencies:  22%|█▋      | 2177/10000 [03:42<21:30,  6.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4541/12392 [00:00<00:00, 45409\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4714\u001b[A\n",
      "Simulating N-1 Contingencies:  22%|█▋      | 2178/10000 [03:43<23:55,  5.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4887/12392 [00:00<00:00, 48864\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3227\u001b[A\n",
      "Simulating N-1 Contingencies:  22%|█▋      | 2180/10000 [03:43<24:58,  5.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4864/12392 [00:00<00:00, 48631\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4897\u001b[A\n",
      "Simulating N-1 Contingencies:  22%|█▋      | 2185/10000 [03:43<16:24,  7.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4847/12392 [00:00<00:00, 48467\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3219\u001b[A\n",
      "Simulating N-1 Contingencies:  22%|█▊      | 2190/10000 [03:44<14:30,  8.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4856/12392 [00:00<00:00, 48554\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4910\u001b[A\n",
      "Simulating N-1 Contingencies:  22%|█▊      | 2192/10000 [03:44<15:20,  8.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4895/12392 [00:00<00:00, 48948\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4927\u001b[A\n",
      "Simulating N-1 Contingencies:  22%|█▊      | 2197/10000 [03:44<12:29, 10.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4874/12392 [00:00<00:00, 48734\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4918\u001b[A\n",
      "Simulating N-1 Contingencies:  22%|█▊      | 2203/10000 [03:45<11:28, 11.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4894/12392 [00:00<00:00, 48936\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4892\u001b[A\n",
      "Simulating N-1 Contingencies:  22%|█▊      | 2208/10000 [03:45<11:10, 11.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4839/12392 [00:00<00:00, 48385\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4894\u001b[A\n",
      "Simulating N-1 Contingencies:  22%|█▊      | 2211/10000 [03:46<11:41, 11.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4899/12392 [00:00<00:00, 48987\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4934\u001b[A\n",
      "Simulating N-1 Contingencies:  22%|█▊      | 2215/10000 [03:46<12:19, 10.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4835/12392 [00:00<00:00, 48340\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4895\u001b[A\n",
      "Simulating N-1 Contingencies:  22%|█▊      | 2217/10000 [03:46<13:54,  9.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4855/12392 [00:00<00:00, 48543\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3196\u001b[A\n",
      "Simulating N-1 Contingencies:  22%|█▊      | 2235/10000 [03:47<05:59, 21.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4722/12392 [00:00<00:00, 47214\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4823\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4858/12392 [00:00<00:00, 48572\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4891\u001b[A\n",
      "Simulating N-1 Contingencies:  22%|█▊      | 2239/10000 [03:47<08:55, 14.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  13%|▏| 1658/12392 [00:00<00:01, 10327\u001b[A\n",
      "Converting scenarios to PyG Data objects:  52%|▌| 6504/12392 [00:00<00:00, 28280\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3237\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4891/12392 [00:00<00:00, 48907\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4923\u001b[A\n",
      "Simulating N-1 Contingencies:  22%|█▊      | 2242/10000 [03:48<13:03,  9.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  27%|▎| 3398/12392 [00:00<00:00, 17388\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3288\u001b[A\n",
      "Simulating N-1 Contingencies:  22%|█▊      | 2244/10000 [03:49<15:12,  8.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4898/12392 [00:00<00:00, 48973\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4924\u001b[A\n",
      "Simulating N-1 Contingencies:  22%|█▊      | 2249/10000 [03:49<12:44, 10.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  27%|▎| 3396/12392 [00:00<00:00, 17369\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3273\u001b[A\n",
      "Simulating N-1 Contingencies:  23%|█▊      | 2254/10000 [03:49<12:22, 10.43it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4836/12392 [00:00<00:00, 48351\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4886\u001b[A\n",
      "Simulating N-1 Contingencies:  23%|█▊      | 2260/10000 [03:50<10:29, 12.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  24%|▏| 2960/12392 [00:00<00:00, 15835\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3273\u001b[A\n",
      "Simulating N-1 Contingencies:  23%|█▊      | 2264/10000 [03:50<11:27, 11.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4914/12392 [00:00<00:00, 49136\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4910\u001b[A\n",
      "Simulating N-1 Contingencies:  23%|█▊      | 2267/10000 [03:50<11:46, 10.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  33%|▎| 4094/12392 [00:00<00:00, 19518\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3282\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4888/12392 [00:00<00:00, 48871\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4913\u001b[A\n",
      "Simulating N-1 Contingencies:  23%|█▊      | 2269/10000 [03:51<17:15,  7.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4868/12392 [00:00<00:00, 48671\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3260\u001b[A\n",
      "Simulating N-1 Contingencies:  23%|█▊      | 2272/10000 [03:52<17:33,  7.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4907/12392 [00:00<00:00, 49064\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4939\u001b[A\n",
      "Simulating N-1 Contingencies:  23%|█▊      | 2273/10000 [03:52<19:34,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4876/12392 [00:00<00:00, 48759\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3247\u001b[A\n",
      "Simulating N-1 Contingencies:  23%|█▊      | 2274/10000 [03:52<24:07,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4828/12392 [00:00<00:00, 48274\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4880\u001b[A\n",
      "Simulating N-1 Contingencies:  23%|█▊      | 2280/10000 [03:53<14:55,  8.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4933/12392 [00:00<00:00, 49328\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3258\u001b[A\n",
      "Simulating N-1 Contingencies:  23%|█▊      | 2282/10000 [03:53<17:22,  7.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4902/12392 [00:00<00:00, 49010\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4246\u001b[A\n",
      "Simulating N-1 Contingencies:  23%|█▊      | 2285/10000 [03:53<16:32,  7.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4577/12392 [00:00<00:00, 45766\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3124\u001b[A\n",
      "Simulating N-1 Contingencies:  23%|█▊      | 2287/10000 [03:54<19:09,  6.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4701/12392 [00:00<00:00, 47005\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4843\u001b[A\n",
      "Simulating N-1 Contingencies:  23%|█▊      | 2288/10000 [03:54<21:30,  5.98it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:  23%|█▊      | 2306/10000 [03:54<05:17, 24.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4831/12392 [00:00<00:00, 48304\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4910\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4884/12392 [00:00<00:00, 48830\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4898\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4874/12392 [00:00<00:00, 48735\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4899\u001b[A\n",
      "Simulating N-1 Contingencies:  23%|█▊      | 2315/10000 [03:55<09:28, 13.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4929/12392 [00:00<00:00, 49288\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4953\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4884/12392 [00:00<00:00, 48831\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4932\u001b[A\n",
      "Simulating N-1 Contingencies:  23%|█▊      | 2319/10000 [03:56<11:43, 10.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4842/12392 [00:00<00:00, 48416\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4865\u001b[A\n",
      "Simulating N-1 Contingencies:  23%|█▊      | 2322/10000 [03:56<13:06,  9.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4862/12392 [00:00<00:00, 48615\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4906\u001b[A\n",
      "Simulating N-1 Contingencies:  23%|█▊      | 2324/10000 [03:57<14:00,  9.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   1%| | 176/12392 [00:00<00:08, 1369.8\u001b[A\n",
      "Converting scenarios to PyG Data objects:  41%|▍| 5056/12392 [00:00<00:00, 26340\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3284\u001b[A\n",
      "Simulating N-1 Contingencies:  23%|█▊      | 2326/10000 [03:57<16:26,  7.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4861/12392 [00:00<00:00, 48600\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4903\u001b[A\n",
      "Simulating N-1 Contingencies:  23%|█▊      | 2328/10000 [03:57<16:52,  7.58it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:  23%|█▊      | 2330/10000 [03:58<15:07,  8.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4897/12392 [00:00<00:00, 48966\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4911\u001b[A\n",
      "Simulating N-1 Contingencies:  23%|█▊      | 2332/10000 [03:58<15:58,  8.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4878/12392 [00:00<00:00, 48774\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3237\u001b[A\n",
      "Simulating N-1 Contingencies:  23%|█▊      | 2341/10000 [03:58<10:29, 12.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4863/12392 [00:00<00:00, 48627\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4882\u001b[A\n",
      "Simulating N-1 Contingencies:  23%|█▉      | 2348/10000 [03:59<08:48, 14.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4862/12392 [00:00<00:00, 48616\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4904\u001b[A\n",
      "Simulating N-1 Contingencies:  24%|█▉      | 2350/10000 [03:59<10:11, 12.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  16%|▏| 2004/12392 [00:00<00:00, 11910\u001b[A\n",
      "Converting scenarios to PyG Data objects:  55%|▌| 6788/12392 [00:00<00:00, 28405\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3231\u001b[A\n",
      "Simulating N-1 Contingencies:  24%|█▉      | 2355/10000 [03:59<10:40, 11.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4889/12392 [00:00<00:00, 48886\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4928\u001b[A\n",
      "Simulating N-1 Contingencies:  24%|█▉      | 2357/10000 [04:00<11:54, 10.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  23%|▏| 2789/12392 [00:00<00:00, 15240\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3268\u001b[A\n",
      "Simulating N-1 Contingencies:  24%|█▉      | 2363/10000 [04:00<11:03, 11.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4860/12392 [00:00<00:00, 48593\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4909\u001b[A\n",
      "Simulating N-1 Contingencies:  24%|█▉      | 2370/10000 [04:01<09:08, 13.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  24%|▏| 2963/12392 [00:00<00:00, 15937\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3285\u001b[A\n",
      "Simulating N-1 Contingencies:  24%|█▉      | 2372/10000 [04:01<11:34, 10.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4723/12392 [00:00<00:00, 47223\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4766\u001b[A\n",
      "Simulating N-1 Contingencies:  24%|█▉      | 2375/10000 [04:01<11:55, 10.66it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  29%|▎| 3572/12392 [00:00<00:00, 17336\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3208\u001b[A\n",
      "Simulating N-1 Contingencies:  24%|█▉      | 2382/10000 [04:02<10:32, 12.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4925/12392 [00:00<00:00, 49243\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4931\u001b[A\n",
      "Simulating N-1 Contingencies:  24%|█▉      | 2385/10000 [04:02<11:00, 11.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  33%|▎| 4094/12392 [00:00<00:00, 19563\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3283\u001b[A\n",
      "Simulating N-1 Contingencies:  24%|█▉      | 2387/10000 [04:02<13:33,  9.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4876/12392 [00:00<00:00, 48757\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4906\u001b[A\n",
      "Simulating N-1 Contingencies:  24%|█▉      | 2388/10000 [04:03<15:51,  8.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4848/12392 [00:00<00:00, 48471\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3258\u001b[A\n",
      "Simulating N-1 Contingencies:  24%|█▉      | 2392/10000 [04:03<15:09,  8.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4813/12392 [00:00<00:00, 48126\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4873\u001b[A\n",
      "Simulating N-1 Contingencies:  24%|█▉      | 2396/10000 [04:03<13:19,  9.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4908/12392 [00:00<00:00, 49075\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3257\u001b[A\n",
      "Simulating N-1 Contingencies:  24%|█▉      | 2397/10000 [04:04<17:34,  7.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4893/12392 [00:00<00:00, 48927\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4924\u001b[A\n",
      "Simulating N-1 Contingencies:  24%|█▉      | 2399/10000 [04:04<17:43,  7.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4883/12392 [00:00<00:00, 48824\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3187\u001b[A\n",
      "Simulating N-1 Contingencies:  24%|█▉      | 2411/10000 [04:05<08:12, 15.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4844/12392 [00:00<00:00, 48430\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4905\u001b[A\n",
      "Simulating N-1 Contingencies:  24%|█▉      | 2414/10000 [04:05<09:11, 13.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4787/12392 [00:00<00:00, 47867\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3207\u001b[A\n",
      "Simulating N-1 Contingencies:  24%|█▉      | 2419/10000 [04:05<10:01, 12.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4877/12392 [00:00<00:00, 48765\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4933\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4880/12392 [00:00<00:00, 48790\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4918\u001b[A\n",
      "Simulating N-1 Contingencies:  24%|█▉      | 2423/10000 [04:06<13:11,  9.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4871/12392 [00:00<00:00, 48705\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4917\u001b[A\n",
      "Simulating N-1 Contingencies:  24%|█▉      | 2425/10000 [04:06<14:15,  8.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4873/12392 [00:00<00:00, 48723\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4882\u001b[A\n",
      "Simulating N-1 Contingencies:  24%|█▉      | 2429/10000 [04:07<13:44,  9.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4868/12392 [00:00<00:00, 48673\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4908\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4877/12392 [00:00<00:00, 48767\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4915\u001b[A\n",
      "Simulating N-1 Contingencies:  24%|█▉      | 2435/10000 [04:08<13:21,  9.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4860/12392 [00:00<00:00, 48593\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4881\u001b[A\n",
      "Simulating N-1 Contingencies:  24%|█▉      | 2437/10000 [04:08<14:31,  8.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4897/12392 [00:00<00:00, 48965\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4926\u001b[A\n",
      "Simulating N-1 Contingencies:  24%|█▉      | 2441/10000 [04:08<13:48,  9.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4883/12392 [00:00<00:00, 48827\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4892\u001b[A\n",
      "Simulating N-1 Contingencies:  24%|█▉      | 2443/10000 [04:09<15:02,  8.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  36%|▎| 4493/12392 [00:00<00:00, 44923\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3111\u001b[A\n",
      "Simulating N-1 Contingencies:  24%|█▉      | 2445/10000 [04:09<18:31,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4901/12392 [00:00<00:00, 49005\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4929\u001b[A\n",
      "Simulating N-1 Contingencies:  24%|█▉      | 2446/10000 [04:09<21:14,  5.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4852/12392 [00:00<00:00, 48513\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4881\u001b[A\n",
      "Simulating N-1 Contingencies:  25%|█▉      | 2452/10000 [04:10<12:54,  9.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  20%|▏| 2526/12392 [00:00<00:00, 14189\u001b[A\n",
      "Converting scenarios to PyG Data objects:  60%|▌| 7420/12392 [00:00<00:00, 29658\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3258\u001b[A\n",
      "Simulating N-1 Contingencies:  25%|█▉      | 2457/10000 [04:10<12:16, 10.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4877/12392 [00:00<00:00, 48758\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4917\u001b[A\n",
      "Simulating N-1 Contingencies:  25%|█▉      | 2459/10000 [04:10<13:24,  9.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  25%|▏| 3048/12392 [00:00<00:00, 16154\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3281\u001b[A\n",
      "Simulating N-1 Contingencies:  25%|█▉      | 2462/10000 [04:11<14:41,  8.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4900/12392 [00:00<00:00, 48994\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4931\u001b[A\n",
      "Simulating N-1 Contingencies:  25%|█▉      | 2464/10000 [04:11<15:25,  8.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  27%|▎| 3397/12392 [00:00<00:00, 17334\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3276\u001b[A\n",
      "Simulating N-1 Contingencies:  25%|█▉      | 2469/10000 [04:12<13:38,  9.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4894/12392 [00:00<00:00, 48933\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4916\u001b[A\n",
      "Simulating N-1 Contingencies:  25%|█▉      | 2472/10000 [04:12<13:20,  9.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4529/12392 [00:00<00:00, 20656\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3275\u001b[A\n",
      "Simulating N-1 Contingencies:  25%|█▉      | 2473/10000 [04:12<17:36,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4919/12392 [00:00<00:00, 49187\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4944\u001b[A\n",
      "Simulating N-1 Contingencies:  25%|█▉      | 2474/10000 [04:13<19:58,  6.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4874/12392 [00:00<00:00, 48731\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3259\u001b[A\n",
      "Simulating N-1 Contingencies:  25%|█▉      | 2475/10000 [04:13<25:07,  4.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4899/12392 [00:00<00:00, 48980\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4937\u001b[A\n",
      "Simulating N-1 Contingencies:  25%|█▉      | 2476/10000 [04:13<26:54,  4.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4943/12392 [00:00<00:00, 49427\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3255\u001b[A\n",
      "Simulating N-1 Contingencies:  25%|█▉      | 2477/10000 [04:14<32:03,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4907/12392 [00:00<00:00, 49066\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4906\u001b[A\n",
      "Simulating N-1 Contingencies:  25%|█▉      | 2479/10000 [04:14<26:43,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4892/12392 [00:00<00:00, 48917\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3231\u001b[A\n",
      "Simulating N-1 Contingencies:  25%|█▉      | 2480/10000 [04:14<31:57,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4925/12392 [00:00<00:00, 49248\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4952\u001b[A\n",
      "Simulating N-1 Contingencies:  25%|█▉      | 2495/10000 [04:15<07:29, 16.69it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:  25%|██      | 2504/10000 [04:15<04:47, 26.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4917/12392 [00:00<00:00, 49168\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3244\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4883/12392 [00:00<00:00, 48820\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4922\u001b[A\n",
      "Simulating N-1 Contingencies:  25%|██      | 2509/10000 [04:16<08:15, 15.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4905/12392 [00:00<00:00, 49040\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4924\u001b[A\n",
      "Simulating N-1 Contingencies:  25%|██      | 2513/10000 [04:16<08:35, 14.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   1%| | 89/12392 [00:00<00:17, 705.17i\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4942/12392 [00:00<00:00, 26094\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3277\u001b[A\n",
      "Simulating N-1 Contingencies:  25%|██      | 2516/10000 [04:16<10:25, 11.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4802/12392 [00:00<00:00, 48018\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4879\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  10%| | 1223/12392 [00:00<00:01, 7945.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  49%|▍| 6112/12392 [00:00<00:00, 27651\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3245\u001b[A\n",
      "Simulating N-1 Contingencies:  25%|██      | 2519/10000 [04:17<14:30,  8.59it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:  25%|██      | 2528/10000 [04:17<08:10, 15.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4816/12392 [00:00<00:00, 48159\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4905\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4883/12392 [00:00<00:00, 48828\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4912\u001b[A\n",
      "Simulating N-1 Contingencies:  25%|██      | 2532/10000 [04:18<11:23, 10.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4894/12392 [00:00<00:00, 48938\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4911\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   6%| | 701/12392 [00:00<00:02, 5041.9\u001b[A\n",
      "Converting scenarios to PyG Data objects:  45%|▍| 5589/12392 [00:00<00:00, 27257\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3284\u001b[A\n",
      "Simulating N-1 Contingencies:  25%|██      | 2535/10000 [04:19<14:51,  8.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4870/12392 [00:00<00:00, 48692\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4919\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  16%|▏| 2006/12392 [00:00<00:00, 11986\u001b[A\n",
      "Converting scenarios to PyG Data objects:  56%|▌| 6886/12392 [00:00<00:00, 28939\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3264\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4941/12392 [00:00<00:00, 49407\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4950\u001b[A\n",
      "Simulating N-1 Contingencies:  25%|██      | 2538/10000 [04:20<20:23,  6.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  25%|▎| 3137/12392 [00:00<00:00, 16636\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3300\u001b[A\n",
      "Simulating N-1 Contingencies:  25%|██      | 2541/10000 [04:20<19:42,  6.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4929/12392 [00:00<00:00, 49287\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4961\u001b[A\n",
      "Simulating N-1 Contingencies:  25%|██      | 2543/10000 [04:20<19:20,  6.42it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  30%|▎| 3659/12392 [00:00<00:00, 18045\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3250\u001b[A\n",
      "Simulating N-1 Contingencies:  25%|██      | 2546/10000 [04:21<18:55,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4820/12392 [00:00<00:00, 48192\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4888\u001b[A\n",
      "Simulating N-1 Contingencies:  25%|██      | 2548/10000 [04:21<18:43,  6.63it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4874/12392 [00:00<00:00, 48735\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3265\u001b[A\n",
      "Simulating N-1 Contingencies:  26%|██      | 2555/10000 [04:21<13:24,  9.26it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4836/12392 [00:00<00:00, 48356\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4916\u001b[A\n",
      "Simulating N-1 Contingencies:  26%|██      | 2559/10000 [04:22<12:18, 10.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4885/12392 [00:00<00:00, 48841\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3270\u001b[A\n",
      "Simulating N-1 Contingencies:  26%|██      | 2562/10000 [04:22<13:36,  9.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4897/12392 [00:00<00:00, 48960\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4925\u001b[A\n",
      "Simulating N-1 Contingencies:  26%|██      | 2563/10000 [04:22<15:43,  7.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4889/12392 [00:00<00:00, 48883\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3219\u001b[A\n",
      "Simulating N-1 Contingencies:  26%|██      | 2565/10000 [04:23<18:06,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4939/12392 [00:00<00:00, 49389\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4936\u001b[A\n",
      "Simulating N-1 Contingencies:  26%|██      | 2567/10000 [04:23<18:02,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4900/12392 [00:00<00:00, 48990\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3235\u001b[A\n",
      "Simulating N-1 Contingencies:  26%|██      | 2569/10000 [04:24<20:07,  6.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4620/12392 [00:00<00:00, 46193\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4694\u001b[A\n",
      "Simulating N-1 Contingencies:  26%|██      | 2570/10000 [04:24<22:34,  5.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4879/12392 [00:00<00:00, 48789\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4924\u001b[A\n",
      "Simulating N-1 Contingencies:  26%|██      | 2571/10000 [04:24<24:41,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4904/12392 [00:00<00:00, 49031\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4907\u001b[A\n",
      "Simulating N-1 Contingencies:  26%|██      | 2573/10000 [04:25<25:02,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4895/12392 [00:00<00:00, 48940\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4910\u001b[A\n",
      "Simulating N-1 Contingencies:  26%|██      | 2574/10000 [04:25<26:51,  4.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   1%| | 91/12392 [00:00<00:16, 726.33i\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4878/12392 [00:00<00:00, 25839\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3280\u001b[A\n",
      "Simulating N-1 Contingencies:  26%|██      | 2577/10000 [04:25<22:36,  5.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4901/12392 [00:00<00:00, 48997\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4954\u001b[A\n",
      "Simulating N-1 Contingencies:  26%|██      | 2578/10000 [04:26<24:38,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  11%| | 1397/12392 [00:00<00:01, 9036.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  51%|▌| 6341/12392 [00:00<00:00, 28439\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3283\u001b[A\n",
      "Simulating N-1 Contingencies:  26%|██      | 2579/10000 [04:26<29:43,  4.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4888/12392 [00:00<00:00, 48876\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4932\u001b[A\n",
      "Simulating N-1 Contingencies:  26%|██      | 2580/10000 [04:26<30:41,  4.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   9%| | 1134/12392 [00:00<00:01, 7629.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  49%|▍| 6024/12392 [00:00<00:00, 27853\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3278\u001b[A\n",
      "Simulating N-1 Contingencies:  26%|██      | 2587/10000 [04:27<15:14,  8.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4916/12392 [00:00<00:00, 49152\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4928\u001b[A\n",
      "Simulating N-1 Contingencies:  26%|██      | 2591/10000 [04:27<13:12,  9.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4887/12392 [00:00<00:00, 48862\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4907\u001b[A\n",
      "Simulating N-1 Contingencies:  26%|██      | 2599/10000 [04:28<10:17, 11.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4884/12392 [00:00<00:00, 48836\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4890\u001b[A\n",
      "Simulating N-1 Contingencies:  26%|██      | 2601/10000 [04:28<11:26, 10.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  10%| | 1223/12392 [00:00<00:01, 7820.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  49%|▍| 6094/12392 [00:00<00:00, 27340\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3218\u001b[A\n",
      "Simulating N-1 Contingencies:  26%|██      | 2602/10000 [04:28<15:17,  8.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4852/12392 [00:00<00:00, 48512\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4895\u001b[A\n",
      "Simulating N-1 Contingencies:  26%|██      | 2603/10000 [04:28<17:37,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  20%|▏| 2528/12392 [00:00<00:00, 14224\u001b[A\n",
      "Converting scenarios to PyG Data objects:  60%|▌| 7396/12392 [00:00<00:00, 29576\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3255\u001b[A\n",
      "Simulating N-1 Contingencies:  26%|██      | 2604/10000 [04:29<22:28,  5.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4872/12392 [00:00<00:00, 48718\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4873\u001b[A\n",
      "Simulating N-1 Contingencies:  26%|██      | 2609/10000 [04:29<14:59,  8.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  28%|▎| 3485/12392 [00:00<00:00, 17250\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3225\u001b[A\n",
      "Simulating N-1 Contingencies:  26%|██      | 2610/10000 [04:30<19:35,  6.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4789/12392 [00:00<00:00, 47883\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4804\u001b[A\n",
      "Simulating N-1 Contingencies:  26%|██      | 2616/10000 [04:30<13:00,  9.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  30%|▎| 3657/12392 [00:00<00:00, 17840\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3226\u001b[A\n",
      "Simulating N-1 Contingencies:  26%|██      | 2619/10000 [04:30<14:19,  8.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4855/12392 [00:00<00:00, 48541\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4912\u001b[A\n",
      "Simulating N-1 Contingencies:  26%|██      | 2621/10000 [04:31<15:02,  8.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4616/12392 [00:00<00:00, 20836\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3258\u001b[A\n",
      "Simulating N-1 Contingencies:  26%|██      | 2625/10000 [04:31<14:30,  8.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4771/12392 [00:00<00:00, 47705\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4770\u001b[A\n",
      "Simulating N-1 Contingencies:  26%|██      | 2626/10000 [04:31<16:54,  7.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4881/12392 [00:00<00:00, 48807\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3249\u001b[A\n",
      "Simulating N-1 Contingencies:  26%|██      | 2627/10000 [04:32<21:37,  5.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4872/12392 [00:00<00:00, 48708\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4907\u001b[A\n",
      "Simulating N-1 Contingencies:  26%|██      | 2639/10000 [04:32<07:48, 15.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4876/12392 [00:00<00:00, 48663\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3258\u001b[A\n",
      "Simulating N-1 Contingencies:  26%|██      | 2643/10000 [04:33<09:24, 13.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4929/12392 [00:00<00:00, 49284\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4949\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4913/12392 [00:00<00:00, 49123\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3263\u001b[A\n",
      "Simulating N-1 Contingencies:  26%|██      | 2646/10000 [04:33<13:46,  8.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4875/12392 [00:00<00:00, 48749\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4912\u001b[A\n",
      "Simulating N-1 Contingencies:  26%|██      | 2650/10000 [04:34<12:28,  9.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4875/12392 [00:00<00:00, 48748\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3238\u001b[A\n",
      "Simulating N-1 Contingencies:  27%|██      | 2653/10000 [04:34<13:44,  8.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4803/12392 [00:00<00:00, 48023\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4876\u001b[A\n",
      "Simulating N-1 Contingencies:  27%|██▏     | 2659/10000 [04:34<10:53, 11.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4875/12392 [00:00<00:00, 48744\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3226\u001b[A\n",
      "Simulating N-1 Contingencies:  27%|██▏     | 2661/10000 [04:35<13:20,  9.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4837/12392 [00:00<00:00, 48360\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4905\u001b[A\n",
      "Simulating N-1 Contingencies:  27%|██▏     | 2663/10000 [04:35<14:10,  8.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4917/12392 [00:00<00:00, 49165\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4940\u001b[A\n",
      "Simulating N-1 Contingencies:  27%|██▏     | 2665/10000 [04:35<14:53,  8.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   7%| | 873/12392 [00:00<00:01, 6062.5\u001b[A\n",
      "Converting scenarios to PyG Data objects:  47%|▍| 5780/12392 [00:00<00:00, 27479\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3268\u001b[A\n",
      "Simulating N-1 Contingencies:  27%|██▏     | 2670/10000 [04:36<13:13,  9.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4907/12392 [00:00<00:00, 49060\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4764\u001b[A\n",
      "Simulating N-1 Contingencies:  27%|██▏     | 2671/10000 [04:36<15:36,  7.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   9%| | 1136/12392 [00:00<00:01, 7691.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  48%|▍| 5998/12392 [00:00<00:00, 27811\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3271\u001b[A\n",
      "Simulating N-1 Contingencies:  27%|██▏     | 2672/10000 [04:37<20:10,  6.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4926/12392 [00:00<00:00, 49256\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4947\u001b[A\n",
      "Simulating N-1 Contingencies:  27%|██▏     | 2675/10000 [04:37<17:13,  7.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  12%| | 1482/12392 [00:00<00:01, 9555.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  52%|▌| 6392/12392 [00:00<00:00, 28514\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3285\u001b[A\n",
      "Simulating N-1 Contingencies:  27%|██▏     | 2679/10000 [04:37<15:37,  7.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4873/12392 [00:00<00:00, 48724\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4934\u001b[A\n",
      "Simulating N-1 Contingencies:  27%|██▏     | 2681/10000 [04:38<16:03,  7.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   4%| | 438/12392 [00:00<00:03, 3267.1\u001b[A\n",
      "Converting scenarios to PyG Data objects:  43%|▍| 5313/12392 [00:00<00:00, 26728\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3278\u001b[A\n",
      "Simulating N-1 Contingencies:  27%|██▏     | 2690/10000 [04:38<10:31, 11.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4909/12392 [00:00<00:00, 49084\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4934\u001b[A\n",
      "Simulating N-1 Contingencies:  27%|██▏     | 2692/10000 [04:38<11:37, 10.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   9%| | 1134/12392 [00:00<00:01, 7696.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  47%|▍| 5833/12392 [00:00<00:00, 27036\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3208\u001b[A\n",
      "Simulating N-1 Contingencies:  27%|██▏     | 2693/10000 [04:39<15:33,  7.83it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:  27%|██▏     | 2702/10000 [04:39<07:34, 16.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4678/12392 [00:00<00:00, 46771\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4822\u001b[A\n",
      "Simulating N-1 Contingencies:  27%|██▏     | 2708/10000 [04:39<07:20, 16.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4866/12392 [00:00<00:00, 48651\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4911\u001b[A\n",
      "Simulating N-1 Contingencies:  27%|██▏     | 2711/10000 [04:40<09:19, 13.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4881/12392 [00:00<00:00, 48802\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4904\u001b[A\n",
      "Simulating N-1 Contingencies:  27%|██▏     | 2714/10000 [04:40<11:04, 10.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4881/12392 [00:00<00:00, 48807\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4921\u001b[A\n",
      "Simulating N-1 Contingencies:  27%|██▏     | 2716/10000 [04:40<12:11,  9.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4848/12392 [00:00<00:00, 48471\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4844\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   6%| | 788/12392 [00:00<00:02, 5453.0\u001b[A\n",
      "Converting scenarios to PyG Data objects:  45%|▍| 5519/12392 [00:00<00:00, 26259\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3205\u001b[A\n",
      "Simulating N-1 Contingencies:  27%|██▏     | 2718/10000 [04:41<18:10,  6.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4947/12392 [00:00<00:00, 49461\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4958\u001b[A\n",
      "Simulating N-1 Contingencies:  27%|██▏     | 2720/10000 [04:41<18:00,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  12%| | 1484/12392 [00:00<00:01, 9596.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  51%|▌| 6353/12392 [00:00<00:00, 28366\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3277\u001b[A\n",
      "Simulating N-1 Contingencies:  27%|██▏     | 2721/10000 [04:42<22:12,  5.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4914/12392 [00:00<00:00, 49133\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4944\u001b[A\n",
      "Simulating N-1 Contingencies:  27%|██▏     | 2725/10000 [04:42<16:35,  7.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  11%| | 1397/12392 [00:00<00:01, 9032.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  51%|▌| 6268/12392 [00:00<00:00, 28082\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3269\u001b[A\n",
      "Simulating N-1 Contingencies:  27%|██▏     | 2727/10000 [04:43<18:38,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4866/12392 [00:00<00:00, 48656\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4894\u001b[A\n",
      "Simulating N-1 Contingencies:  27%|██▏     | 2729/10000 [04:43<18:22,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  12%| | 1484/12392 [00:00<00:01, 9524.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  51%|▌| 6345/12392 [00:00<00:00, 28219\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3261\u001b[A\n",
      "Simulating N-1 Contingencies:  27%|██▏     | 2731/10000 [04:43<20:12,  6.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4903/12392 [00:00<00:00, 49028\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4945\u001b[A\n",
      "Simulating N-1 Contingencies:  27%|██▏     | 2732/10000 [04:43<22:17,  5.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  14%|▏| 1745/12392 [00:00<00:00, 10897\u001b[A\n",
      "Converting scenarios to PyG Data objects:  54%|▌| 6692/12392 [00:00<00:00, 29082\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3296\u001b[A\n",
      "Simulating N-1 Contingencies:  27%|██▏     | 2733/10000 [04:44<27:09,  4.46it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:  27%|██▏     | 2742/10000 [04:44<09:02, 13.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4882/12392 [00:00<00:00, 48813\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4940\u001b[A\n",
      "Simulating N-1 Contingencies:  27%|██▏     | 2749/10000 [04:44<08:18, 14.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4838/12392 [00:00<00:00, 48375\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4871\u001b[A\n",
      "Simulating N-1 Contingencies:  28%|██▏     | 2752/10000 [04:45<09:18, 12.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4845/12392 [00:00<00:00, 48444\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4899\u001b[A\n",
      "Simulating N-1 Contingencies:  28%|██▏     | 2754/10000 [04:45<10:53, 11.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   6%| | 701/12392 [00:00<00:02, 5025.7\u001b[A\n",
      "Converting scenarios to PyG Data objects:  45%|▍| 5601/12392 [00:00<00:00, 27274\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3284\u001b[A\n",
      "Simulating N-1 Contingencies:  28%|██▏     | 2756/10000 [04:45<13:58,  8.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4864/12392 [00:00<00:00, 48635\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4905\u001b[A\n",
      "Simulating N-1 Contingencies:  28%|██▏     | 2768/10000 [04:46<07:25, 16.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4811/12392 [00:00<00:00, 48102\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4791\u001b[A\n",
      "Simulating N-1 Contingencies:  28%|██▏     | 2771/10000 [04:46<08:29, 14.19it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4615/12392 [00:00<00:00, 46139\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3154\u001b[A\n",
      "Simulating N-1 Contingencies:  28%|██▏     | 2778/10000 [04:47<08:28, 14.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4785/12392 [00:00<00:00, 47840\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4852\u001b[A\n",
      "Simulating N-1 Contingencies:  28%|██▏     | 2780/10000 [04:47<09:48, 12.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4651/12392 [00:00<00:00, 46506\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4766\u001b[A\n",
      "Simulating N-1 Contingencies:  28%|██▏     | 2782/10000 [04:47<11:11, 10.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  17%|▏| 2093/12392 [00:00<00:00, 12212\u001b[A\n",
      "Converting scenarios to PyG Data objects:  56%|▌| 6940/12392 [00:00<00:00, 28693\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3232\u001b[A\n",
      "Simulating N-1 Contingencies:  28%|██▏     | 2784/10000 [04:48<13:59,  8.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4874/12392 [00:00<00:00, 48736\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4921\u001b[A\n",
      "Simulating N-1 Contingencies:  28%|██▏     | 2786/10000 [04:48<14:43,  8.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  23%|▏| 2789/12392 [00:00<00:00, 15151\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3267\u001b[A\n",
      "Simulating N-1 Contingencies:  28%|██▏     | 2787/10000 [04:49<19:19,  6.22it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:  28%|██▏     | 2796/10000 [04:49<07:58, 15.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4901/12392 [00:00<00:00, 48998\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4927\u001b[A\n",
      "Simulating N-1 Contingencies:  28%|██▏     | 2799/10000 [04:49<08:54, 13.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  16%|▏| 2006/12392 [00:00<00:00, 12009\u001b[A\n",
      "Converting scenarios to PyG Data objects:  56%|▌| 6918/12392 [00:00<00:00, 29114\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3270\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4865/12392 [00:00<00:00, 48644\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4914\u001b[A\n",
      "Simulating N-1 Contingencies:  28%|██▏     | 2802/10000 [04:50<13:34,  8.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  27%|▎| 3311/12392 [00:00<00:00, 17171\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3288\u001b[A\n",
      "Simulating N-1 Contingencies:  28%|██▏     | 2804/10000 [04:50<15:43,  7.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4792/12392 [00:00<00:00, 47913\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4848\u001b[A\n",
      "Simulating N-1 Contingencies:  28%|██▏     | 2811/10000 [04:50<10:57, 10.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  28%|▎| 3485/12392 [00:00<00:00, 17366\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3245\u001b[A\n",
      "Simulating N-1 Contingencies:  28%|██▎     | 2813/10000 [04:51<13:18,  9.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4901/12392 [00:00<00:00, 49003\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4918\u001b[A\n",
      "Simulating N-1 Contingencies:  28%|██▎     | 2815/10000 [04:51<14:04,  8.51it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  31%|▎| 3831/12392 [00:00<00:00, 18767\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3274\u001b[A\n",
      "Simulating N-1 Contingencies:  28%|██▎     | 2819/10000 [04:52<13:44,  8.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4893/12392 [00:00<00:00, 48927\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4935\u001b[A\n",
      "Simulating N-1 Contingencies:  28%|██▎     | 2821/10000 [04:52<14:26,  8.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4891/12392 [00:00<00:00, 48905\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3262\u001b[A\n",
      "Simulating N-1 Contingencies:  28%|██▎     | 2828/10000 [04:52<11:16, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4907/12392 [00:00<00:00, 49067\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4939\u001b[A\n",
      "Simulating N-1 Contingencies:  28%|██▎     | 2830/10000 [04:53<12:16,  9.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4871/12392 [00:00<00:00, 48704\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3257\u001b[A\n",
      "Simulating N-1 Contingencies:  28%|██▎     | 2835/10000 [04:53<11:42, 10.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4888/12392 [00:00<00:00, 48876\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4913\u001b[A\n",
      "Simulating N-1 Contingencies:  28%|██▎     | 2846/10000 [04:53<06:41, 17.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4873/12392 [00:00<00:00, 48718\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3235\u001b[A\n",
      "Simulating N-1 Contingencies:  28%|██▎     | 2850/10000 [04:54<08:20, 14.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4655/12392 [00:00<00:00, 46546\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4827\u001b[A\n",
      "Simulating N-1 Contingencies:  29%|██▎     | 2853/10000 [04:54<09:08, 13.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4877/12392 [00:00<00:00, 48660\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3235\u001b[A\n",
      "Simulating N-1 Contingencies:  29%|██▎     | 2856/10000 [04:55<11:00, 10.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4888/12392 [00:00<00:00, 48879\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4920\u001b[A\n",
      "Simulating N-1 Contingencies:  29%|██▎     | 2865/10000 [04:55<07:56, 14.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4878/12392 [00:00<00:00, 48779\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3229\u001b[A\n",
      "Simulating N-1 Contingencies:  29%|██▎     | 2867/10000 [04:55<10:16, 11.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4934/12392 [00:00<00:00, 49330\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4954\u001b[A\n",
      "Simulating N-1 Contingencies:  29%|██▎     | 2872/10000 [04:56<09:24, 12.62it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:  29%|██▎     | 2881/10000 [04:56<05:45, 20.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4875/12392 [00:00<00:00, 48728\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3233\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4912/12392 [00:00<00:00, 49118\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4935\u001b[A\n",
      "Simulating N-1 Contingencies:  29%|██▎     | 2885/10000 [04:57<09:10, 12.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4871/12392 [00:00<00:00, 48708\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3106\u001b[A\n",
      "Simulating N-1 Contingencies:  29%|██▎     | 2889/10000 [04:57<10:16, 11.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  36%|▎| 4468/12392 [00:00<00:00, 44676\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4741\u001b[A\n",
      "Simulating N-1 Contingencies:  29%|██▎     | 2892/10000 [04:57<10:41, 11.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4714/12392 [00:00<00:00, 47132\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4838\u001b[A\n",
      "Simulating N-1 Contingencies:  29%|██▎     | 2895/10000 [04:58<11:00, 10.76it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  18%|▏| 2178/12392 [00:00<00:00, 12603\u001b[A\n",
      "Converting scenarios to PyG Data objects:  58%|▌| 7132/12392 [00:00<00:00, 29316\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3270\u001b[A\n",
      "Simulating N-1 Contingencies:  29%|██▎     | 2898/10000 [04:58<12:26,  9.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4959/12392 [00:00<00:00, 49581\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4979\u001b[A\n",
      "Simulating N-1 Contingencies:  29%|██▎     | 2902/10000 [04:58<11:23, 10.39it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  15%|▏| 1917/12392 [00:00<00:00, 11568\u001b[A\n",
      "Converting scenarios to PyG Data objects:  55%|▌| 6788/12392 [00:00<00:00, 28763\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3262\u001b[A\n",
      "Simulating N-1 Contingencies:  29%|██▎     | 2906/10000 [04:59<11:54,  9.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4861/12392 [00:00<00:00, 48604\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4890\u001b[A\n",
      "Simulating N-1 Contingencies:  29%|██▎     | 2909/10000 [04:59<11:53,  9.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  20%|▏| 2441/12392 [00:00<00:00, 13860\u001b[A\n",
      "Converting scenarios to PyG Data objects:  59%|▌| 7357/12392 [00:00<00:00, 29666\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3259\u001b[A\n",
      "Simulating N-1 Contingencies:  29%|██▎     | 2911/10000 [05:00<14:21,  8.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4888/12392 [00:00<00:00, 48874\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4935\u001b[A\n",
      "Simulating N-1 Contingencies:  29%|██▎     | 2913/10000 [05:00<14:55,  7.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  27%|▎| 3396/12392 [00:00<00:00, 16116\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3067\u001b[A\n",
      "Simulating N-1 Contingencies:  29%|██▎     | 2917/10000 [05:00<14:30,  8.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4765/12392 [00:00<00:00, 47644\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4825\u001b[A\n",
      "Simulating N-1 Contingencies:  29%|██▎     | 2923/10000 [05:01<11:09, 10.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  30%|▎| 3746/12392 [00:00<00:00, 16902\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3098\u001b[A\n",
      "Simulating N-1 Contingencies:  29%|██▎     | 2925/10000 [05:01<13:44,  8.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4731/12392 [00:00<00:00, 47305\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4830\u001b[A\n",
      "Simulating N-1 Contingencies:  29%|██▎     | 2928/10000 [05:01<13:14,  8.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4703/12392 [00:00<00:00, 20704\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3242\u001b[A\n",
      "Simulating N-1 Contingencies:  29%|██▎     | 2930/10000 [05:02<15:36,  7.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4894/12392 [00:00<00:00, 48934\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4940\u001b[A\n",
      "Simulating N-1 Contingencies:  29%|██▎     | 2942/10000 [05:02<07:01, 16.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4789/12392 [00:00<00:00, 21280\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3261\u001b[A\n",
      "Simulating N-1 Contingencies:  29%|██▎     | 2946/10000 [05:03<08:35, 13.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4836/12392 [00:00<00:00, 48359\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4871\u001b[A\n",
      "Simulating N-1 Contingencies:  30%|██▎     | 2951/10000 [05:03<08:18, 14.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4886/12392 [00:00<00:00, 48850\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3255\u001b[A\n",
      "Simulating N-1 Contingencies:  30%|██▎     | 2954/10000 [05:03<10:08, 11.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4861/12392 [00:00<00:00, 48605\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4905\u001b[A\n",
      "Simulating N-1 Contingencies:  30%|██▎     | 2956/10000 [05:04<11:17, 10.39it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:  30%|██▎     | 2965/10000 [05:04<06:08, 19.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4806/12392 [00:00<00:00, 48059\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3249\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4793/12392 [00:00<00:00, 47925\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4873\u001b[A\n",
      "Simulating N-1 Contingencies:  30%|██▍     | 2969/10000 [05:05<09:46, 11.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4865/12392 [00:00<00:00, 48641\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3242\u001b[A\n",
      "Simulating N-1 Contingencies:  30%|██▍     | 2972/10000 [05:05<11:16, 10.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4763/12392 [00:00<00:00, 47618\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4842\u001b[A\n",
      "Simulating N-1 Contingencies:  30%|██▍     | 2977/10000 [05:05<10:03, 11.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4826/12392 [00:00<00:00, 48253\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3219\u001b[A\n",
      "Simulating N-1 Contingencies:  30%|██▍     | 2983/10000 [05:06<09:44, 12.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4867/12392 [00:00<00:00, 48666\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4872\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4904/12392 [00:00<00:00, 49035\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4908\u001b[A\n",
      "Simulating N-1 Contingencies:  30%|██▍     | 2987/10000 [05:06<12:18,  9.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4859/12392 [00:00<00:00, 48584\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4922\u001b[A\n",
      "Simulating N-1 Contingencies:  30%|██▍     | 2990/10000 [05:07<12:07,  9.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4803/12392 [00:00<00:00, 48022\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4861\u001b[A\n",
      "Simulating N-1 Contingencies:  30%|██▍     | 2994/10000 [05:07<12:10,  9.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4845/12392 [00:00<00:00, 48447\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4887\u001b[A\n",
      "Simulating N-1 Contingencies:  30%|██▍     | 2996/10000 [05:07<13:19,  8.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4912/12392 [00:00<00:00, 49112\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4923\u001b[A\n",
      "Simulating N-1 Contingencies:  30%|██▍     | 3002/10000 [05:08<10:55, 10.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4840/12392 [00:00<00:00, 48392\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4838\u001b[A\n",
      "Simulating N-1 Contingencies:  30%|██▍     | 3004/10000 [05:08<12:27,  9.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  36%|▎| 4461/12392 [00:00<00:00, 44606\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3130\u001b[A\n",
      "Simulating N-1 Contingencies:  30%|██▍     | 3006/10000 [05:09<15:45,  7.39it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4837/12392 [00:00<00:00, 48361\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4870\u001b[A\n",
      "Simulating N-1 Contingencies:  30%|██▍     | 3012/10000 [05:09<10:55, 10.66it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4823/12392 [00:00<00:00, 48222\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4884\u001b[A\n",
      "Simulating N-1 Contingencies:  30%|██▍     | 3014/10000 [05:09<12:07,  9.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  23%|▏| 2789/12392 [00:00<00:00, 15221\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3264\u001b[A\n",
      "Simulating N-1 Contingencies:  30%|██▍     | 3016/10000 [05:10<14:48,  7.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4916/12392 [00:00<00:00, 49157\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4908\u001b[A\n",
      "Simulating N-1 Contingencies:  30%|██▍     | 3017/10000 [05:10<17:11,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4529/12392 [00:00<00:00, 20614\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3255\u001b[A\n",
      "Simulating N-1 Contingencies:  30%|██▍     | 3019/10000 [05:10<19:11,  6.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4852/12392 [00:00<00:00, 48511\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4896\u001b[A\n",
      "Simulating N-1 Contingencies:  30%|██▍     | 3022/10000 [05:11<16:22,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4882/12392 [00:00<00:00, 48810\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3255\u001b[A\n",
      "Simulating N-1 Contingencies:  30%|██▍     | 3024/10000 [05:11<18:27,  6.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4877/12392 [00:00<00:00, 48755\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4925\u001b[A\n",
      "Simulating N-1 Contingencies:  30%|██▍     | 3029/10000 [05:11<13:08,  8.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4838/12392 [00:00<00:00, 48372\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3230\u001b[A\n",
      "Simulating N-1 Contingencies:  30%|██▍     | 3036/10000 [05:12<10:35, 10.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4855/12392 [00:00<00:00, 48546\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4898\u001b[A\n",
      "Simulating N-1 Contingencies:  30%|██▍     | 3044/10000 [05:12<08:11, 14.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4912/12392 [00:00<00:00, 49117\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3248\u001b[A\n",
      "Simulating N-1 Contingencies:  30%|██▍     | 3046/10000 [05:13<10:23, 11.15it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4881/12392 [00:00<00:00, 48803\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4926\u001b[A\n",
      "Simulating N-1 Contingencies:  30%|██▍     | 3048/10000 [05:13<11:25, 10.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4928/12392 [00:00<00:00, 49271\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3089\u001b[A\n",
      "Simulating N-1 Contingencies:  31%|██▍     | 3051/10000 [05:13<12:58,  8.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4841/12392 [00:00<00:00, 48403\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4834\u001b[A\n",
      "Simulating N-1 Contingencies:  31%|██▍     | 3064/10000 [05:14<06:23, 18.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4827/12392 [00:00<00:00, 48262\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3204\u001b[A\n",
      "Simulating N-1 Contingencies:  31%|██▍     | 3068/10000 [05:14<08:00, 14.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4886/12392 [00:00<00:00, 48854\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4933\u001b[A\n",
      "Simulating N-1 Contingencies:  31%|██▍     | 3071/10000 [05:15<08:44, 13.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4883/12392 [00:00<00:00, 48829\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4917\u001b[A\n",
      "Simulating N-1 Contingencies:  31%|██▍     | 3074/10000 [05:15<09:23, 12.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   6%| | 788/12392 [00:00<00:02, 5448.1\u001b[A\n",
      "Converting scenarios to PyG Data objects:  44%|▍| 5480/12392 [00:00<00:00, 26054\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3201\u001b[A\n",
      "Simulating N-1 Contingencies:  31%|██▍     | 3076/10000 [05:15<12:06,  9.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4748/12392 [00:00<00:00, 47474\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4827\u001b[A\n",
      "Simulating N-1 Contingencies:  31%|██▍     | 3078/10000 [05:16<13:08,  8.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  12%| | 1484/12392 [00:00<00:01, 9252.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  52%|▌| 6449/12392 [00:00<00:00, 28280\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3248\u001b[A\n",
      "Simulating N-1 Contingencies:  31%|██▍     | 3080/10000 [05:16<15:37,  7.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4860/12392 [00:00<00:00, 48588\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4893\u001b[A\n",
      "Simulating N-1 Contingencies:  31%|██▍     | 3083/10000 [05:16<14:18,  8.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  13%|▏| 1656/12392 [00:00<00:01, 10297\u001b[A\n",
      "Converting scenarios to PyG Data objects:  52%|▌| 6405/12392 [00:00<00:00, 27791\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3164\u001b[A\n",
      "Simulating N-1 Contingencies:  31%|██▍     | 3088/10000 [05:17<12:44,  9.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4615/12392 [00:00<00:00, 46020\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4678\u001b[A\n",
      "Simulating N-1 Contingencies:  31%|██▍     | 3092/10000 [05:17<11:39,  9.87it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  15%|▏| 1830/12392 [00:00<00:00, 10669\u001b[A\n",
      "Converting scenarios to PyG Data objects:  53%|▌| 6614/12392 [00:00<00:00, 27556\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3172\u001b[A\n",
      "Simulating N-1 Contingencies:  31%|██▍     | 3097/10000 [05:18<11:20, 10.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  29%|▎| 3536/12392 [00:00<00:00, 35355\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4293\u001b[A\n",
      "Simulating N-1 Contingencies:  31%|██▍     | 3099/10000 [05:18<12:40,  9.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  20%|▏| 2526/12392 [00:00<00:00, 13215\u001b[A\n",
      "Converting scenarios to PyG Data objects:  59%|▌| 7291/12392 [00:00<00:00, 27943\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3114\u001b[A\n",
      "Simulating N-1 Contingencies:  31%|██▍     | 3100/10000 [05:18<16:42,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4754/12392 [00:00<00:00, 47532\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4777\u001b[A\n",
      "Simulating N-1 Contingencies:  31%|██▍     | 3105/10000 [05:19<12:42,  9.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  28%|▎| 3485/12392 [00:00<00:00, 14030\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 2824\u001b[A\n",
      "Simulating N-1 Contingencies:  31%|██▍     | 3106/10000 [05:19<17:16,  6.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4700/12392 [00:00<00:00, 46988\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4721\u001b[A\n",
      "Simulating N-1 Contingencies:  31%|██▍     | 3117/10000 [05:20<07:46, 14.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  25%|▎| 3136/12392 [00:00<00:00, 15535\u001b[A\n",
      "Converting scenarios to PyG Data objects:  62%|▌| 7698/12392 [00:00<00:00, 28002\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3049\u001b[A\n",
      "Simulating N-1 Contingencies:  31%|██▍     | 3121/10000 [05:20<09:22, 12.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4623/12392 [00:00<00:00, 46228\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4806\u001b[A\n",
      "Simulating N-1 Contingencies:  31%|██▌     | 3125/10000 [05:20<09:18, 12.31it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  30%|▎| 3746/12392 [00:00<00:00, 16893\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3074\u001b[A\n",
      "Simulating N-1 Contingencies:  31%|██▌     | 3131/10000 [05:21<09:18, 12.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4568/12392 [00:00<00:00, 45669\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4693\u001b[A\n",
      "Simulating N-1 Contingencies:  31%|██▌     | 3135/10000 [05:21<09:19, 12.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  35%|▎| 4355/12392 [00:00<00:00, 19359\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3176\u001b[A\n",
      "Simulating N-1 Contingencies:  31%|██▌     | 3141/10000 [05:22<09:13, 12.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4827/12392 [00:00<00:00, 48266\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4881\u001b[A\n",
      "Simulating N-1 Contingencies:  32%|██▌     | 3150/10000 [05:22<07:16, 15.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4790/12392 [00:00<00:00, 20812\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3212\u001b[A\n",
      "Simulating N-1 Contingencies:  32%|██▌     | 3153/10000 [05:23<08:53, 12.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4856/12392 [00:00<00:00, 48548\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4868\u001b[A\n",
      "Simulating N-1 Contingencies:  32%|██▌     | 3156/10000 [05:23<09:25, 12.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4880/12392 [00:00<00:00, 48792\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3189\u001b[A\n",
      "Simulating N-1 Contingencies:  32%|██▌     | 3158/10000 [05:23<11:47,  9.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4805/12392 [00:00<00:00, 48046\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4777\u001b[A\n",
      "Simulating N-1 Contingencies:  32%|██▌     | 3165/10000 [05:24<09:10, 12.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4821/12392 [00:00<00:00, 48204\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 2987\u001b[A\n",
      "Simulating N-1 Contingencies:  32%|██▌     | 3167/10000 [05:24<11:43,  9.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4862/12392 [00:00<00:00, 48617\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4801\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4811/12392 [00:00<00:00, 48107\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3003\u001b[A\n",
      "Simulating N-1 Contingencies:  32%|██▌     | 3169/10000 [05:25<16:57,  6.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4870/12392 [00:00<00:00, 48689\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4912\u001b[A\n",
      "Simulating N-1 Contingencies:  32%|██▌     | 3175/10000 [05:25<12:21,  9.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4893/12392 [00:00<00:00, 48923\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3220\u001b[A\n",
      "Simulating N-1 Contingencies:  32%|██▌     | 3177/10000 [05:26<14:21,  7.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4877/12392 [00:00<00:00, 48736\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4924\u001b[A\n",
      "Simulating N-1 Contingencies:  32%|██▌     | 3180/10000 [05:26<13:33,  8.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4872/12392 [00:00<00:00, 48713\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4918\u001b[A\n",
      "Simulating N-1 Contingencies:  32%|██▌     | 3182/10000 [05:26<15:39,  7.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  36%|▎| 4467/12392 [00:00<00:00, 44661\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4590\u001b[A\n",
      "Simulating N-1 Contingencies:  32%|██▌     | 3183/10000 [05:27<18:37,  6.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4844/12392 [00:00<00:00, 48432\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4881\u001b[A\n",
      "Simulating N-1 Contingencies:  32%|██▌     | 3185/10000 [05:27<19:59,  5.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4826/12392 [00:00<00:00, 48251\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4877\u001b[A\n",
      "Simulating N-1 Contingencies:  32%|██▌     | 3188/10000 [05:27<15:54,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4676/12392 [00:00<00:00, 46753\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4799\u001b[A\n",
      "Simulating N-1 Contingencies:  32%|██▌     | 3191/10000 [05:28<15:29,  7.33it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  36%|▎| 4504/12392 [00:00<00:00, 45031\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4576\u001b[A\n",
      "Simulating N-1 Contingencies:  32%|██▌     | 3193/10000 [05:28<16:09,  7.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4849/12392 [00:00<00:00, 48486\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4870\u001b[A\n",
      "Simulating N-1 Contingencies:  32%|██▌     | 3194/10000 [05:28<19:07,  5.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4853/12392 [00:00<00:00, 48522\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4847\u001b[A\n",
      "Simulating N-1 Contingencies:  32%|██▌     | 3195/10000 [05:29<24:55,  4.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4838/12392 [00:00<00:00, 48374\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4865\u001b[A\n",
      "Simulating N-1 Contingencies:  32%|██▌     | 3202/10000 [05:29<13:24,  8.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4692/12392 [00:00<00:00, 46915\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4795\u001b[A\n",
      "Simulating N-1 Contingencies:  32%|██▌     | 3209/10000 [05:30<09:02, 12.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4759/12392 [00:00<00:00, 47587\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3174\u001b[A\n",
      "Simulating N-1 Contingencies:  32%|██▌     | 3213/10000 [05:30<10:13, 11.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4806/12392 [00:00<00:00, 48055\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4870\u001b[A\n",
      "Simulating N-1 Contingencies:  32%|██▌     | 3217/10000 [05:30<09:49, 11.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4853/12392 [00:00<00:00, 48523\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4909\u001b[A\n",
      "Simulating N-1 Contingencies:  32%|██▌     | 3223/10000 [05:31<08:25, 13.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  18%|▏| 2265/12392 [00:00<00:00, 12646\u001b[A\n",
      "Converting scenarios to PyG Data objects:  57%|▌| 7006/12392 [00:00<00:00, 28070\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3168\u001b[A\n",
      "Simulating N-1 Contingencies:  32%|██▌     | 3227/10000 [05:31<09:37, 11.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4733/12392 [00:00<00:00, 47323\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4795\u001b[A\n",
      "Simulating N-1 Contingencies:  32%|██▌     | 3233/10000 [05:31<08:27, 13.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   7%| | 873/12392 [00:00<00:01, 5832.1\u001b[A\n",
      "Converting scenarios to PyG Data objects:  46%|▍| 5711/12392 [00:00<00:00, 26606\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3207\u001b[A\n",
      "Simulating N-1 Contingencies:  32%|██▌     | 3242/10000 [05:32<07:31, 14.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4782/12392 [00:00<00:00, 47813\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4868\u001b[A\n",
      "Simulating N-1 Contingencies:  32%|██▌     | 3245/10000 [05:32<08:11, 13.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   8%| | 960/12392 [00:00<00:01, 6591.0\u001b[A\n",
      "Converting scenarios to PyG Data objects:  47%|▍| 5821/12392 [00:00<00:00, 27396\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3261\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4709/12392 [00:00<00:00, 47079\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4828\u001b[A\n",
      "Simulating N-1 Contingencies:  32%|██▌     | 3247/10000 [05:33<12:32,  8.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  17%|▏| 2091/12392 [00:00<00:00, 11973\u001b[A\n",
      "Converting scenarios to PyG Data objects:  56%|▌| 6885/12392 [00:00<00:00, 28155\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3195\u001b[A\n",
      "Simulating N-1 Contingencies:  32%|██▌     | 3250/10000 [05:33<13:27,  8.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4828/12392 [00:00<00:00, 48270\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4378\u001b[A\n",
      "Simulating N-1 Contingencies:  33%|██▌     | 3254/10000 [05:34<12:17,  9.14it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  15%|▏| 1830/12392 [00:00<00:00, 11064\u001b[A\n",
      "Converting scenarios to PyG Data objects:  54%|▌| 6663/12392 [00:00<00:00, 28332\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3214\u001b[A\n",
      "Simulating N-1 Contingencies:  33%|██▌     | 3258/10000 [05:34<12:22,  9.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4787/12392 [00:00<00:00, 47861\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4862\u001b[A\n",
      "Simulating N-1 Contingencies:  33%|██▌     | 3265/10000 [05:35<09:27, 11.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  11%| | 1395/12392 [00:00<00:01, 8482.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  49%|▍| 6119/12392 [00:00<00:00, 26498\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3150\u001b[A\n",
      "Simulating N-1 Contingencies:  33%|██▌     | 3268/10000 [05:35<10:57, 10.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4777/12392 [00:00<00:00, 47762\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4845\u001b[A\n",
      "Simulating N-1 Contingencies:  33%|██▌     | 3270/10000 [05:35<11:52,  9.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  17%|▏| 2093/12392 [00:00<00:00, 12237\u001b[A\n",
      "Converting scenarios to PyG Data objects:  56%|▌| 6943/12392 [00:00<00:00, 28741\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3206\u001b[A\n",
      "Simulating N-1 Contingencies:  33%|██▌     | 3271/10000 [05:36<15:30,  7.23it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4774/12392 [00:00<00:00, 47732\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4792\u001b[A\n",
      "Simulating N-1 Contingencies:  33%|██▌     | 3276/10000 [05:36<12:03,  9.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  11%| | 1310/12392 [00:00<00:01, 8282.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  50%|▍| 6147/12392 [00:00<00:00, 27305\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3215\u001b[A\n",
      "Simulating N-1 Contingencies:  33%|██▋     | 3285/10000 [05:37<09:01, 12.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4867/12392 [00:00<00:00, 48664\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4901\u001b[A\n",
      "Simulating N-1 Contingencies:  33%|██▋     | 3287/10000 [05:37<10:03, 11.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   8%| | 1047/12392 [00:00<00:01, 6973.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  47%|▍| 5878/12392 [00:00<00:00, 27124\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3232\u001b[A\n",
      "Simulating N-1 Contingencies:  33%|██▋     | 3293/10000 [05:37<09:33, 11.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4880/12392 [00:00<00:00, 48799\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4902\u001b[A\n",
      "Simulating N-1 Contingencies:  33%|██▋     | 3295/10000 [05:38<10:34, 10.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  13%|▏| 1569/12392 [00:00<00:01, 9770.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  51%|▌| 6328/12392 [00:00<00:00, 27572\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3207\u001b[A\n",
      "Simulating N-1 Contingencies:  33%|██▋     | 3298/10000 [05:38<11:58,  9.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4749/12392 [00:00<00:00, 47485\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4833\u001b[A\n",
      "Simulating N-1 Contingencies:  33%|██▋     | 3300/10000 [05:38<12:49,  8.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  27%|▎| 3311/12392 [00:00<00:00, 16476\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3202\u001b[A\n",
      "Simulating N-1 Contingencies:  33%|██▋     | 3301/10000 [05:39<16:48,  6.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4808/12392 [00:00<00:00, 48070\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4871\u001b[A\n",
      "Simulating N-1 Contingencies:  33%|██▋     | 3303/10000 [05:39<16:40,  6.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4560/12392 [00:00<00:00, 45594\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3133\u001b[A\n",
      "Simulating N-1 Contingencies:  33%|██▋     | 3304/10000 [05:39<21:21,  5.23it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4697/12392 [00:00<00:00, 46961\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4818\u001b[A\n",
      "Simulating N-1 Contingencies:  33%|██▋     | 3311/10000 [05:40<11:49,  9.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4825/12392 [00:00<00:00, 48244\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3183\u001b[A\n",
      "Simulating N-1 Contingencies:  33%|██▋     | 3313/10000 [05:40<14:11,  7.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4863/12392 [00:00<00:00, 48627\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4672\u001b[A\n",
      "Simulating N-1 Contingencies:  33%|██▋     | 3320/10000 [05:41<09:59, 11.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4608/12392 [00:00<00:00, 46068\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3136\u001b[A\n",
      "Simulating N-1 Contingencies:  33%|██▋     | 3328/10000 [05:41<08:43, 12.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4551/12392 [00:00<00:00, 45504\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4703\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4858/12392 [00:00<00:00, 48575\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3193\u001b[A\n",
      "Simulating N-1 Contingencies:  33%|██▋     | 3338/10000 [05:42<07:49, 14.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4680/12392 [00:00<00:00, 46796\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4756\u001b[A\n",
      "Simulating N-1 Contingencies:  33%|██▋     | 3343/10000 [05:42<07:43, 14.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4810/12392 [00:00<00:00, 48097\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3083\u001b[A\n",
      "Simulating N-1 Contingencies:  33%|██▋     | 3347/10000 [05:43<08:59, 12.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4547/12392 [00:00<00:00, 45469\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4672\u001b[A\n",
      "Simulating N-1 Contingencies:  34%|██▋     | 3350/10000 [05:43<09:32, 11.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4876/12392 [00:00<00:00, 48756\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3130\u001b[A\n",
      "Simulating N-1 Contingencies:  34%|██▋     | 3352/10000 [05:43<11:55,  9.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4725/12392 [00:00<00:00, 47243\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4771\u001b[A\n",
      "Simulating N-1 Contingencies:  34%|██▋     | 3359/10000 [05:44<09:05, 12.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4778/12392 [00:00<00:00, 47777\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4769\u001b[A\n",
      "Simulating N-1 Contingencies:  34%|██▋     | 3364/10000 [05:44<09:37, 11.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  36%|▎| 4447/12392 [00:00<00:00, 44461\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4693\u001b[A\n",
      "Simulating N-1 Contingencies:  34%|██▋     | 3366/10000 [05:45<11:02, 10.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4701/12392 [00:00<00:00, 47002\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4797\u001b[A\n",
      "Simulating N-1 Contingencies:  34%|██▋     | 3369/10000 [05:45<12:49,  8.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4750/12392 [00:00<00:00, 47494\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4804\u001b[A\n",
      "Simulating N-1 Contingencies:  34%|██▋     | 3370/10000 [05:45<15:49,  6.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4567/12392 [00:00<00:00, 45665\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4638\u001b[A\n",
      "Simulating N-1 Contingencies:  34%|██▋     | 3376/10000 [05:46<10:25, 10.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  28%|▎| 3488/12392 [00:00<00:00, 34877\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4211\u001b[A\n",
      "Simulating N-1 Contingencies:  34%|██▋     | 3384/10000 [05:46<08:07, 13.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  33%|▎| 4124/12392 [00:00<00:00, 41233\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 2642\u001b[A\n",
      "Simulating N-1 Contingencies:  34%|██▋     | 3387/10000 [05:47<11:00, 10.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4683/12392 [00:00<00:00, 46824\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4804\u001b[A\n",
      "Simulating N-1 Contingencies:  34%|██▋     | 3389/10000 [05:47<12:10,  9.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4718/12392 [00:00<00:00, 47169\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4816\u001b[A\n",
      "Simulating N-1 Contingencies:  34%|██▋     | 3394/10000 [05:47<10:09, 10.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  13%|▏| 1571/12392 [00:00<00:01, 9138.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  51%|▌| 6278/12392 [00:00<00:00, 26351\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3119\u001b[A\n",
      "Simulating N-1 Contingencies:  34%|██▋     | 3396/10000 [05:48<12:47,  8.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4632/12392 [00:00<00:00, 46319\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4710\u001b[A\n",
      "Simulating N-1 Contingencies:  34%|██▋     | 3399/10000 [05:48<12:23,  8.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  14%|▏| 1743/12392 [00:00<00:01, 10631\u001b[A\n",
      "Converting scenarios to PyG Data objects:  53%|▌| 6580/12392 [00:00<00:00, 28203\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3235\u001b[A\n",
      "Simulating N-1 Contingencies:  34%|██▋     | 3405/10000 [05:49<10:40, 10.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4891/12392 [00:00<00:00, 48900\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4895\u001b[A\n",
      "Simulating N-1 Contingencies:  34%|██▋     | 3407/10000 [05:49<11:37,  9.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  19%|▏| 2354/12392 [00:00<00:00, 13324\u001b[A\n",
      "Converting scenarios to PyG Data objects:  58%|▌| 7183/12392 [00:00<00:00, 28956\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3222\u001b[A\n",
      "Simulating N-1 Contingencies:  34%|██▋     | 3415/10000 [05:49<09:11, 11.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4825/12392 [00:00<00:00, 48247\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4857\u001b[A\n",
      "Simulating N-1 Contingencies:  34%|██▋     | 3417/10000 [05:50<10:14, 10.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  27%|▎| 3309/12392 [00:00<00:00, 16652\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3222\u001b[A\n",
      "Simulating N-1 Contingencies:  34%|██▋     | 3421/10000 [05:50<10:50, 10.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4628/12392 [00:00<00:00, 46270\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4761\u001b[A\n",
      "Simulating N-1 Contingencies:  34%|██▋     | 3429/10000 [05:51<08:10, 13.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  32%|▎| 3920/12392 [00:00<00:00, 18429\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3202\u001b[A\n",
      "Simulating N-1 Contingencies:  34%|██▋     | 3431/10000 [05:51<10:19, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4831/12392 [00:00<00:00, 48304\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4865\u001b[A\n",
      "Simulating N-1 Contingencies:  34%|██▊     | 3438/10000 [05:51<08:18, 13.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4527/12392 [00:00<00:00, 20625\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3253\u001b[A\n",
      "Simulating N-1 Contingencies:  34%|██▊     | 3441/10000 [05:52<09:48, 11.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4854/12392 [00:00<00:00, 48533\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4906\u001b[A\n",
      "Simulating N-1 Contingencies:  34%|██▊     | 3444/10000 [05:52<10:03, 10.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4897/12392 [00:00<00:00, 48960\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3235\u001b[A\n",
      "Simulating N-1 Contingencies:  34%|██▊     | 3446/10000 [05:53<12:20,  8.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4869/12392 [00:00<00:00, 48686\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4852\u001b[A\n",
      "Simulating N-1 Contingencies:  34%|██▊     | 3450/10000 [05:53<11:05,  9.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4850/12392 [00:00<00:00, 48495\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3233\u001b[A\n",
      "Simulating N-1 Contingencies:  35%|██▊     | 3459/10000 [05:53<08:29, 12.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4865/12392 [00:00<00:00, 48646\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4886\u001b[A\n",
      "Simulating N-1 Contingencies:  35%|██▊     | 3461/10000 [05:54<09:31, 11.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4673/12392 [00:00<00:00, 46725\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3142\u001b[A\n",
      "Simulating N-1 Contingencies:  35%|██▊     | 3465/10000 [05:54<10:20, 10.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4782/12392 [00:00<00:00, 47811\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4804\u001b[A\n",
      "Simulating N-1 Contingencies:  35%|██▊     | 3470/10000 [05:54<09:17, 11.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4879/12392 [00:00<00:00, 48784\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3138\u001b[A\n",
      "Simulating N-1 Contingencies:  35%|██▊     | 3473/10000 [05:55<10:49, 10.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4803/12392 [00:00<00:00, 48025\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4859\u001b[A\n",
      "Simulating N-1 Contingencies:  35%|██▊     | 3480/10000 [05:55<08:34, 12.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4676/12392 [00:00<00:00, 46752\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3100\u001b[A\n",
      "Simulating N-1 Contingencies:  35%|██▊     | 3487/10000 [05:56<08:15, 13.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4587/12392 [00:00<00:00, 45860\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4661\u001b[A\n",
      "Simulating N-1 Contingencies:  35%|██▊     | 3489/10000 [05:56<09:21, 11.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4784/12392 [00:00<00:00, 47833\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4843\u001b[A\n",
      "Simulating N-1 Contingencies:  35%|██▊     | 3491/10000 [05:56<10:24, 10.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  15%|▏| 1832/12392 [00:00<00:00, 11052\u001b[A\n",
      "Converting scenarios to PyG Data objects:  54%|▌| 6687/12392 [00:00<00:00, 28408\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3227\u001b[A\n",
      "Simulating N-1 Contingencies:  35%|██▊     | 3498/10000 [05:57<09:04, 11.93it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4858/12392 [00:00<00:00, 48577\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4877\u001b[A\n",
      "Simulating N-1 Contingencies:  35%|██▊     | 3501/10000 [05:57<09:28, 11.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  24%|▏| 2963/12392 [00:00<00:00, 15880\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3265\u001b[A\n",
      "Simulating N-1 Contingencies:  35%|██▊     | 3503/10000 [05:58<11:41,  9.26it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4765/12392 [00:00<00:00, 47648\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4825\u001b[A\n",
      "Simulating N-1 Contingencies:  35%|██▊     | 3507/10000 [05:58<10:40, 10.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  35%|▎| 4355/12392 [00:00<00:00, 20100\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3249\u001b[A\n",
      "Simulating N-1 Contingencies:  35%|██▊     | 3509/10000 [05:58<12:55,  8.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4806/12392 [00:00<00:00, 48052\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4868\u001b[A\n",
      "Simulating N-1 Contingencies:  35%|██▊     | 3513/10000 [05:59<11:23,  9.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4842/12392 [00:00<00:00, 48416\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3239\u001b[A\n",
      "Simulating N-1 Contingencies:  35%|██▊     | 3514/10000 [05:59<15:00,  7.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4853/12392 [00:00<00:00, 48524\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4906\u001b[A\n",
      "Simulating N-1 Contingencies:  35%|██▊     | 3516/10000 [05:59<15:09,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4857/12392 [00:00<00:00, 48562\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3244\u001b[A\n",
      "Simulating N-1 Contingencies:  35%|██▊     | 3517/10000 [06:00<19:22,  5.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4790/12392 [00:00<00:00, 47891\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4848\u001b[A\n",
      "Simulating N-1 Contingencies:  35%|██▊     | 3522/10000 [06:00<13:04,  8.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4854/12392 [00:00<00:00, 48532\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3228\u001b[A\n",
      "Simulating N-1 Contingencies:  35%|██▊     | 3524/10000 [06:00<15:15,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4834/12392 [00:00<00:00, 48338\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4849\u001b[A\n",
      "Simulating N-1 Contingencies:  35%|██▊     | 3529/10000 [06:01<11:36,  9.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4614/12392 [00:00<00:00, 46134\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4669\u001b[A\n",
      "Simulating N-1 Contingencies:  35%|██▊     | 3532/10000 [06:01<13:05,  8.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4765/12392 [00:00<00:00, 47641\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4827\u001b[A\n",
      "Simulating N-1 Contingencies:  35%|██▊     | 3533/10000 [06:01<15:44,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4816/12392 [00:00<00:00, 48157\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3125\u001b[A\n",
      "Simulating N-1 Contingencies:  35%|██▊     | 3540/10000 [06:02<10:48,  9.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4808/12392 [00:00<00:00, 48076\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4865\u001b[A\n",
      "Simulating N-1 Contingencies:  35%|██▊     | 3542/10000 [06:02<11:46,  9.14it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4890/12392 [00:00<00:00, 48894\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4913\u001b[A\n",
      "Simulating N-1 Contingencies:  35%|██▊     | 3547/10000 [06:03<09:47, 10.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  11%| | 1395/12392 [00:00<00:01, 9009.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  50%|▌| 6224/12392 [00:00<00:00, 27856\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3246\u001b[A\n",
      "Simulating N-1 Contingencies:  36%|██▊     | 3551/10000 [06:03<10:27, 10.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4883/12392 [00:00<00:00, 48821\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4884\u001b[A\n",
      "Simulating N-1 Contingencies:  36%|██▊     | 3553/10000 [06:03<11:25,  9.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  17%|▏| 2093/12392 [00:00<00:00, 12301\u001b[A\n",
      "Converting scenarios to PyG Data objects:  56%|▌| 6940/12392 [00:00<00:00, 28806\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3249\u001b[A\n",
      "Simulating N-1 Contingencies:  36%|██▊     | 3554/10000 [06:04<15:11,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4898/12392 [00:00<00:00, 48976\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4931\u001b[A\n",
      "Simulating N-1 Contingencies:  36%|██▊     | 3556/10000 [06:04<15:15,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  15%|▏| 1830/12392 [00:00<00:00, 11174\u001b[A\n",
      "Converting scenarios to PyG Data objects:  54%|▌| 6679/12392 [00:00<00:00, 28558\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3242\u001b[A\n",
      "Simulating N-1 Contingencies:  36%|██▊     | 3562/10000 [06:04<11:40,  9.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4898/12392 [00:00<00:00, 48976\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4807\u001b[A\n",
      "Simulating N-1 Contingencies:  36%|██▊     | 3563/10000 [06:05<13:42,  7.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  19%|▏| 2352/12392 [00:00<00:00, 13074\u001b[A\n",
      "Converting scenarios to PyG Data objects:  58%|▌| 7195/12392 [00:00<00:00, 28722\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3203\u001b[A\n",
      "Simulating N-1 Contingencies:  36%|██▊     | 3567/10000 [06:05<13:04,  8.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4789/12392 [00:00<00:00, 47889\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4838\u001b[A\n",
      "Simulating N-1 Contingencies:  36%|██▊     | 3569/10000 [06:06<13:38,  7.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  17%|▏| 2091/12392 [00:00<00:00, 12315\u001b[A\n",
      "Converting scenarios to PyG Data objects:  56%|▌| 6991/12392 [00:00<00:00, 29075\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3255\u001b[A\n",
      "Simulating N-1 Contingencies:  36%|██▊     | 3575/10000 [06:06<11:04,  9.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4877/12392 [00:00<00:00, 48758\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4919\u001b[A\n",
      "Simulating N-1 Contingencies:  36%|██▊     | 3581/10000 [06:06<08:59, 11.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  22%|▏| 2700/12392 [00:00<00:00, 14913\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3279\u001b[A\n",
      "Simulating N-1 Contingencies:  36%|██▊     | 3585/10000 [06:07<09:45, 10.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4846/12392 [00:00<00:00, 48452\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4888\u001b[A\n",
      "Simulating N-1 Contingencies:  36%|██▊     | 3588/10000 [06:07<09:59, 10.69it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  25%|▏| 3048/12392 [00:00<00:00, 15748\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3214\u001b[A\n",
      "Simulating N-1 Contingencies:  36%|██▊     | 3592/10000 [06:08<10:36, 10.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4686/12392 [00:00<00:00, 46853\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4715\u001b[A\n",
      "Simulating N-1 Contingencies:  36%|██▉     | 3594/10000 [06:08<11:35,  9.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  29%|▎| 3570/12392 [00:00<00:00, 17411\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3216\u001b[A\n",
      "Simulating N-1 Contingencies:  36%|██▉     | 3597/10000 [06:08<12:40,  8.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4864/12392 [00:00<00:00, 48631\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4906\u001b[A\n",
      "Simulating N-1 Contingencies:  36%|██▉     | 3598/10000 [06:09<14:39,  7.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4529/12392 [00:00<00:00, 20008\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3192\u001b[A\n",
      "Simulating N-1 Contingencies:  36%|██▉     | 3603/10000 [06:09<12:29,  8.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4824/12392 [00:00<00:00, 48229\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4863\u001b[A\n",
      "Simulating N-1 Contingencies:  36%|██▉     | 3604/10000 [06:09<14:28,  7.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4877/12392 [00:00<00:00, 48767\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3228\u001b[A\n",
      "Simulating N-1 Contingencies:  36%|██▉     | 3608/10000 [06:10<13:26,  7.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4718/12392 [00:00<00:00, 47170\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4815\u001b[A\n",
      "Simulating N-1 Contingencies:  36%|██▉     | 3612/10000 [06:10<11:40,  9.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4761/12392 [00:00<00:00, 47602\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3214\u001b[A\n",
      "Simulating N-1 Contingencies:  36%|██▉     | 3613/10000 [06:10<15:20,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4808/12392 [00:00<00:00, 48073\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4856\u001b[A\n",
      "Simulating N-1 Contingencies:  36%|██▉     | 3614/10000 [06:11<17:22,  6.13it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:  36%|██▉     | 3631/10000 [06:11<04:24, 24.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4789/12392 [00:00<00:00, 47696\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3163\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4830/12392 [00:00<00:00, 48297\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4889\u001b[A\n",
      "Simulating N-1 Contingencies:  36%|██▉     | 3636/10000 [06:12<07:32, 14.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4807/12392 [00:00<00:00, 48062\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3198\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4863/12392 [00:00<00:00, 48624\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4911\u001b[A\n",
      "Simulating N-1 Contingencies:  36%|██▉     | 3640/10000 [06:12<10:18, 10.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4774/12392 [00:00<00:00, 47732\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3185\u001b[A\n",
      "Simulating N-1 Contingencies:  36%|██▉     | 3644/10000 [06:13<10:43,  9.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4686/12392 [00:00<00:00, 46856\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4746\u001b[A\n",
      "Simulating N-1 Contingencies:  36%|██▉     | 3646/10000 [06:13<11:32,  9.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4690/12392 [00:00<00:00, 46890\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3117\u001b[A\n",
      "Simulating N-1 Contingencies:  36%|██▉     | 3650/10000 [06:14<11:44,  9.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4799/12392 [00:00<00:00, 47979\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4852\u001b[A\n",
      "Simulating N-1 Contingencies:  37%|██▉     | 3655/10000 [06:14<10:02, 10.53it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4823/12392 [00:00<00:00, 48229\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4894\u001b[A\n",
      "Simulating N-1 Contingencies:  37%|██▉     | 3661/10000 [06:14<08:29, 12.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   8%| | 1048/12392 [00:00<00:01, 7110.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  48%|▍| 5892/12392 [00:00<00:00, 27450\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3259\u001b[A\n",
      "Simulating N-1 Contingencies:  37%|██▉     | 3672/10000 [06:15<05:57, 17.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4812/12392 [00:00<00:00, 48117\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3180\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4699/12392 [00:00<00:00, 46989\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4823\u001b[A\n",
      "Simulating N-1 Contingencies:  37%|██▉     | 3676/10000 [06:16<09:04, 11.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4877/12392 [00:00<00:00, 48751\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4902\u001b[A\n",
      "Simulating N-1 Contingencies:  37%|██▉     | 3679/10000 [06:16<09:23, 11.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  28%|▎| 3484/12392 [00:00<00:00, 17667\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3278\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4918/12392 [00:00<00:00, 49172\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4936\u001b[A\n",
      "Simulating N-1 Contingencies:  37%|██▉     | 3682/10000 [06:17<12:43,  8.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  31%|▎| 3833/12392 [00:00<00:00, 18579\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3255\u001b[A\n",
      "Simulating N-1 Contingencies:  37%|██▉     | 3687/10000 [06:17<11:36,  9.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4858/12392 [00:00<00:00, 48570\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4908\u001b[A\n",
      "Simulating N-1 Contingencies:  37%|██▉     | 3691/10000 [06:17<10:38,  9.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4828/12392 [00:00<00:00, 48274\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3232\u001b[A\n",
      "Simulating N-1 Contingencies:  37%|██▉     | 3693/10000 [06:18<12:34,  8.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4868/12392 [00:00<00:00, 48676\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4911\u001b[A\n",
      "Simulating N-1 Contingencies:  37%|██▉     | 3701/10000 [06:18<08:42, 12.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4728/12392 [00:00<00:00, 47269\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3092\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4539/12392 [00:00<00:00, 45383\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4677\u001b[A\n",
      "Simulating N-1 Contingencies:  37%|██▉     | 3703/10000 [06:19<13:01,  8.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4833/12392 [00:00<00:00, 48328\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3145\u001b[A\n",
      "Simulating N-1 Contingencies:  37%|██▉     | 3705/10000 [06:19<14:42,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4851/12392 [00:00<00:00, 48507\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4900\u001b[A\n",
      "Simulating N-1 Contingencies:  37%|██▉     | 3707/10000 [06:19<14:48,  7.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4775/12392 [00:00<00:00, 47741\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3155\u001b[A\n",
      "Simulating N-1 Contingencies:  37%|██▉     | 3714/10000 [06:20<11:04,  9.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4718/12392 [00:00<00:00, 47170\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4800\u001b[A\n",
      "Simulating N-1 Contingencies:  37%|██▉     | 3718/10000 [06:20<10:18, 10.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4745/12392 [00:00<00:00, 47442\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4830\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4777/12392 [00:00<00:00, 47761\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4849\u001b[A\n",
      "Simulating N-1 Contingencies:  37%|██▉     | 3729/10000 [06:21<07:39, 13.64it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4789/12392 [00:00<00:00, 47881\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 2969\u001b[A\n",
      "Simulating N-1 Contingencies:  37%|██▉     | 3737/10000 [06:22<07:21, 14.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4789/12392 [00:00<00:00, 47885\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4865\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4700/12392 [00:00<00:00, 46997\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4738\u001b[A\n",
      "Simulating N-1 Contingencies:  37%|██▉     | 3740/10000 [06:22<09:36, 10.85it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:  37%|██▉     | 3745/10000 [06:22<07:59, 13.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4755/12392 [00:00<00:00, 47540\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4778\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4753/12392 [00:00<00:00, 47523\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4800\u001b[A\n",
      "Simulating N-1 Contingencies:  37%|██▉     | 3748/10000 [06:23<10:26,  9.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4756/12392 [00:00<00:00, 47550\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4850\u001b[A\n",
      "Simulating N-1 Contingencies:  38%|███     | 3750/10000 [06:23<12:17,  8.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4801/12392 [00:00<00:00, 48007\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4830\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4587/12392 [00:00<00:00, 45864\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4702\u001b[A\n",
      "Simulating N-1 Contingencies:  38%|███     | 3752/10000 [06:24<16:47,  6.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4747/12392 [00:00<00:00, 47463\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4829\u001b[A\n",
      "Simulating N-1 Contingencies:  38%|███     | 3754/10000 [06:24<16:28,  6.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   3%| | 351/12392 [00:00<00:04, 2590.9\u001b[A\n",
      "Converting scenarios to PyG Data objects:  41%|▍| 5106/12392 [00:00<00:00, 25666\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3225\u001b[A\n",
      "Simulating N-1 Contingencies:  38%|███     | 3755/10000 [06:25<19:54,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4953/12392 [00:00<00:00, 49528\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4982\u001b[A\n",
      "Simulating N-1 Contingencies:  38%|███     | 3758/10000 [06:25<16:27,  6.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   4%| | 438/12392 [00:00<00:03, 3244.1\u001b[A\n",
      "Converting scenarios to PyG Data objects:  43%|▍| 5342/12392 [00:00<00:00, 26786\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3300\u001b[A\n",
      "Simulating N-1 Contingencies:  38%|███     | 3759/10000 [06:26<20:08,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4990/12392 [00:00<00:00, 49897\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4976\u001b[A\n",
      "Simulating N-1 Contingencies:  38%|███     | 3764/10000 [06:26<13:15,  7.84it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:  38%|███     | 3766/10000 [06:26<12:01,  8.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 5003/12392 [00:00<00:00, 50026\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5028\u001b[A\n",
      "Simulating N-1 Contingencies:  38%|███     | 3769/10000 [06:26<11:25,  9.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 5003/12392 [00:00<00:00, 50024\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3273\u001b[A\n",
      "Simulating N-1 Contingencies:  38%|███     | 3780/10000 [06:27<06:13, 16.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4983/12392 [00:00<00:00, 49820\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5023\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4950/12392 [00:00<00:00, 49489\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4968\u001b[A\n",
      "Simulating N-1 Contingencies:  38%|███     | 3784/10000 [06:27<08:34, 12.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  11%| | 1397/12392 [00:00<00:01, 9046.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  50%|▌| 6208/12392 [00:00<00:00, 27817\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3269\u001b[A\n",
      "Simulating N-1 Contingencies:  38%|███     | 3787/10000 [06:28<09:59, 10.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4555/12392 [00:00<00:00, 45544\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4730\u001b[A\n",
      "Simulating N-1 Contingencies:  38%|███     | 3790/10000 [06:28<10:12, 10.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  20%|▏| 2528/12392 [00:00<00:00, 14206\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3296\u001b[A\n",
      "Simulating N-1 Contingencies:  38%|███     | 3792/10000 [06:29<12:21,  8.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4724/12392 [00:00<00:00, 47232\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4827\u001b[A\n",
      "Simulating N-1 Contingencies:  38%|███     | 3794/10000 [06:29<12:57,  7.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  22%|▏| 2702/12392 [00:00<00:00, 12920\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3034\u001b[A\n",
      "Simulating N-1 Contingencies:  38%|███     | 3800/10000 [06:29<10:50,  9.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4765/12392 [00:00<00:00, 47638\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4853\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  32%|▎| 4007/12392 [00:00<00:00, 17717\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3126\u001b[A\n",
      "Simulating N-1 Contingencies:  38%|███     | 3802/10000 [06:30<15:32,  6.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4972/12392 [00:00<00:00, 49713\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4988\u001b[A\n",
      "Simulating N-1 Contingencies:  38%|███     | 3804/10000 [06:30<15:22,  6.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4965/12392 [00:00<00:00, 49639\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3206\u001b[A\n",
      "Simulating N-1 Contingencies:  38%|███     | 3806/10000 [06:31<16:51,  6.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4962/12392 [00:00<00:00, 49604\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5013\u001b[A\n",
      "Simulating N-1 Contingencies:  38%|███     | 3809/10000 [06:31<14:38,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4979/12392 [00:00<00:00, 49783\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3289\u001b[A\n",
      "Simulating N-1 Contingencies:  38%|███     | 3810/10000 [06:31<18:16,  5.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4978/12392 [00:00<00:00, 49772\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5016\u001b[A\n",
      "Simulating N-1 Contingencies:  38%|███     | 3821/10000 [06:32<06:58, 14.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4995/12392 [00:00<00:00, 49943\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3297\u001b[A\n",
      "Simulating N-1 Contingencies:  38%|███     | 3824/10000 [06:32<08:44, 11.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4930/12392 [00:00<00:00, 49296\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4975\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4966/12392 [00:00<00:00, 49653\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3276\u001b[A\n",
      "Simulating N-1 Contingencies:  38%|███     | 3836/10000 [06:33<06:38, 15.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4949/12392 [00:00<00:00, 49484\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4981\u001b[A\n",
      "/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:  38%|███     | 3840/10000 [06:33<06:58, 14.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4995/12392 [00:00<00:00, 49941\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3256\u001b[A\n",
      "Simulating N-1 Contingencies:  38%|███     | 3843/10000 [06:34<08:34, 11.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4964/12392 [00:00<00:00, 49634\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4965\u001b[A\n",
      "Simulating N-1 Contingencies:  38%|███     | 3846/10000 [06:34<08:57, 11.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4817/12392 [00:00<00:00, 48167\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3192\u001b[A\n",
      "Simulating N-1 Contingencies:  38%|███     | 3848/10000 [06:35<11:16,  9.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4881/12392 [00:00<00:00, 48808\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4966\u001b[A\n",
      "Simulating N-1 Contingencies:  38%|███     | 3850/10000 [06:35<11:58,  8.56it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:  39%|███     | 3859/10000 [06:35<05:52, 17.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 5001/12392 [00:00<00:00, 49998\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5022\u001b[A\n",
      "Simulating N-1 Contingencies:  39%|███     | 3863/10000 [06:35<06:23, 16.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   8%| | 1047/12392 [00:00<00:01, 7174.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  48%|▍| 6002/12392 [00:00<00:00, 28133\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3303\u001b[A\n",
      "Simulating N-1 Contingencies:  39%|███     | 3867/10000 [06:36<07:41, 13.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4960/12392 [00:00<00:00, 49591\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4911\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  14%|▏| 1745/12392 [00:00<00:01, 9181.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  52%|▌| 6420/12392 [00:00<00:00, 25300\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 2972\u001b[A\n",
      "Simulating N-1 Contingencies:  39%|███     | 3870/10000 [06:36<11:37,  8.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4671/12392 [00:00<00:00, 46701\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4734\u001b[A\n",
      "Simulating N-1 Contingencies:  39%|███     | 3872/10000 [06:37<12:17,  8.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  23%|▏| 2874/12392 [00:00<00:00, 15176\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3222\u001b[A\n",
      "Simulating N-1 Contingencies:  39%|███     | 3874/10000 [06:37<14:11,  7.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4963/12392 [00:00<00:00, 49616\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4994\u001b[A\n",
      "Simulating N-1 Contingencies:  39%|███     | 3878/10000 [06:37<11:53,  8.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  36%|▎| 4442/12392 [00:00<00:00, 20637\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3311\u001b[A\n",
      "Simulating N-1 Contingencies:  39%|███     | 3880/10000 [06:38<13:46,  7.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4972/12392 [00:00<00:00, 49718\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5006\u001b[A\n",
      "Simulating N-1 Contingencies:  39%|███     | 3881/10000 [06:38<15:34,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4877/12392 [00:00<00:00, 48766\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3237\u001b[A\n",
      "Simulating N-1 Contingencies:  39%|███     | 3882/10000 [06:39<19:37,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4875/12392 [00:00<00:00, 48744\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4960\u001b[A\n",
      "Simulating N-1 Contingencies:  39%|███     | 3883/10000 [06:39<21:08,  4.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4955/12392 [00:00<00:00, 49542\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3212\u001b[A\n",
      "Simulating N-1 Contingencies:  39%|███     | 3886/10000 [06:39<18:21,  5.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4755/12392 [00:00<00:00, 47540\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4804\u001b[A\n",
      "Simulating N-1 Contingencies:  39%|███     | 3888/10000 [06:40<17:24,  5.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4924/12392 [00:00<00:00, 49238\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3252\u001b[A\n",
      "Simulating N-1 Contingencies:  39%|███     | 3897/10000 [06:40<09:43, 10.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4888/12392 [00:00<00:00, 48870\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4952\u001b[A\n",
      "Simulating N-1 Contingencies:  39%|███     | 3901/10000 [06:40<09:12, 11.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4948/12392 [00:00<00:00, 49478\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3212\u001b[A\n",
      "Simulating N-1 Contingencies:  39%|███     | 3903/10000 [06:41<11:20,  8.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 5004/12392 [00:00<00:00, 50031\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5027\u001b[A\n",
      "Simulating N-1 Contingencies:  39%|███     | 3905/10000 [06:41<11:56,  8.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 5018/12392 [00:00<00:00, 50171\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4765\u001b[A\n",
      "Simulating N-1 Contingencies:  39%|███▏    | 3909/10000 [06:41<10:34,  9.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  15%|▏| 1919/12392 [00:00<00:00, 11367\u001b[A\n",
      "Converting scenarios to PyG Data objects:  56%|▌| 6906/12392 [00:00<00:00, 29013\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3265\u001b[A\n",
      "Simulating N-1 Contingencies:  39%|███▏    | 3911/10000 [06:42<12:46,  7.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4935/12392 [00:00<00:00, 49339\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4990\u001b[A\n",
      "Simulating N-1 Contingencies:  39%|███▏    | 3912/10000 [06:42<14:41,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  21%|▏| 2615/12392 [00:00<00:00, 14564\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3285\u001b[A\n",
      "Simulating N-1 Contingencies:  39%|███▏    | 3914/10000 [06:42<16:23,  6.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4951/12392 [00:00<00:00, 49507\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4975\u001b[A\n",
      "Simulating N-1 Contingencies:  39%|███▏    | 3916/10000 [06:43<15:52,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  30%|▎| 3746/12392 [00:00<00:00, 18257\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3251\u001b[A\n",
      "Simulating N-1 Contingencies:  39%|███▏    | 3918/10000 [06:43<17:23,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4895/12392 [00:00<00:00, 48942\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4936\u001b[A\n",
      "Simulating N-1 Contingencies:  39%|███▏    | 3920/10000 [06:43<16:36,  6.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  33%|▎| 4094/12392 [00:00<00:00, 18899\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3219\u001b[A\n",
      "Simulating N-1 Contingencies:  39%|███▏    | 3925/10000 [06:44<12:55,  7.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4919/12392 [00:00<00:00, 49184\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4992\u001b[A\n",
      "Simulating N-1 Contingencies:  39%|███▏    | 3933/10000 [06:44<08:23, 12.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  32%|▎| 3918/12392 [00:00<00:00, 19033\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3295\u001b[A\n",
      "Simulating N-1 Contingencies:  39%|███▏    | 3938/10000 [06:45<08:36, 11.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4958/12392 [00:00<00:00, 49572\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5013\u001b[A\n",
      "Simulating N-1 Contingencies:  39%|███▏    | 3945/10000 [06:45<07:09, 14.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4703/12392 [00:00<00:00, 21188\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3299\u001b[A\n",
      "Simulating N-1 Contingencies:  40%|███▏    | 3956/10000 [06:46<05:21, 18.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4992/12392 [00:00<00:00, 49917\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5017\u001b[A\n",
      "Simulating N-1 Contingencies:  40%|███▏    | 3960/10000 [06:46<05:54, 17.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  35%|▎| 4353/12392 [00:00<00:00, 20241\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3296\u001b[A\n",
      "/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:  40%|███▏    | 3963/10000 [06:46<07:33, 13.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4951/12392 [00:00<00:00, 49508\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4964\u001b[A\n",
      "Simulating N-1 Contingencies:  40%|███▏    | 3967/10000 [06:47<07:36, 13.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4964/12392 [00:00<00:00, 21879\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3296\u001b[A\n",
      "Simulating N-1 Contingencies:  40%|███▏    | 3980/10000 [06:47<05:04, 19.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4955/12392 [00:00<00:00, 49545\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4981\u001b[A\n",
      "Simulating N-1 Contingencies:  40%|███▏    | 3985/10000 [06:48<05:26, 18.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4877/12392 [00:00<00:00, 21652\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3303\u001b[A\n",
      "Simulating N-1 Contingencies:  40%|███▏    | 3989/10000 [06:48<06:44, 14.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4901/12392 [00:00<00:00, 49000\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4977\u001b[A\n",
      "Simulating N-1 Contingencies:  40%|███▏    | 3994/10000 [06:48<06:39, 15.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4971/12392 [00:00<00:00, 49699\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3284\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4882/12392 [00:00<00:00, 48818\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4967\u001b[A\n",
      "Simulating N-1 Contingencies:  40%|███▏    | 3997/10000 [06:49<09:57, 10.04it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4902/12392 [00:00<00:00, 49012\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3245\u001b[A\n",
      "Simulating N-1 Contingencies:  40%|███▏    | 4002/10000 [06:49<09:42, 10.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4700/12392 [00:00<00:00, 46991\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4786\u001b[A\n",
      "Simulating N-1 Contingencies:  40%|███▏    | 4008/10000 [06:50<08:22, 11.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4750/12392 [00:00<00:00, 47492\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3168\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4599/12392 [00:00<00:00, 45985\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4680\u001b[A\n",
      "Simulating N-1 Contingencies:  40%|███▏    | 4010/10000 [06:50<12:18,  8.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4931/12392 [00:00<00:00, 49305\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4985\u001b[A\n",
      "Simulating N-1 Contingencies:  40%|███▏    | 4012/10000 [06:51<12:38,  7.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   8%| | 962/12392 [00:00<00:01, 6227.8\u001b[A\n",
      "Converting scenarios to PyG Data objects:  47%|▍| 5869/12392 [00:00<00:00, 26810\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3214\u001b[A\n",
      "Simulating N-1 Contingencies:  40%|███▏    | 4014/10000 [06:51<14:19,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4780/12392 [00:00<00:00, 47796\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4905\u001b[A\n",
      "Simulating N-1 Contingencies:  40%|███▏    | 4019/10000 [06:52<11:05,  8.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   1%| | 89/12392 [00:00<00:17, 689.21i\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4898/12392 [00:00<00:00, 25583\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3268\u001b[A\n",
      "Simulating N-1 Contingencies:  40%|███▏    | 4023/10000 [06:52<11:03,  9.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4990/12392 [00:00<00:00, 49892\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3272\u001b[A\n",
      "Simulating N-1 Contingencies:  40%|███▏    | 4031/10000 [06:52<08:39, 11.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4998/12392 [00:00<00:00, 49976\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5025\u001b[A\n",
      "Simulating N-1 Contingencies:  40%|███▏    | 4033/10000 [06:53<09:27, 10.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4876/12392 [00:00<00:00, 48754\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4947\u001b[A\n",
      "Simulating N-1 Contingencies:  40%|███▏    | 4035/10000 [06:53<10:19,  9.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  22%|▏| 2700/12392 [00:00<00:00, 14938\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3287\u001b[A\n",
      "Simulating N-1 Contingencies:  40%|███▏    | 4039/10000 [06:53<10:30,  9.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4927/12392 [00:00<00:00, 49268\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4965\u001b[A\n",
      "Simulating N-1 Contingencies:  40%|███▏    | 4041/10000 [06:54<11:13,  8.85it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  27%|▎| 3311/12392 [00:00<00:00, 17085\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3295\u001b[A\n",
      "Simulating N-1 Contingencies:  40%|███▏    | 4049/10000 [06:54<08:30, 11.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4875/12392 [00:00<00:00, 48741\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4962\u001b[A\n",
      "Simulating N-1 Contingencies:  41%|███▏    | 4051/10000 [06:55<09:26, 10.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  28%|▎| 3485/12392 [00:00<00:00, 16782\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3113\u001b[A\n",
      "Simulating N-1 Contingencies:  41%|███▏    | 4058/10000 [06:55<08:26, 11.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4662/12392 [00:00<00:00, 46610\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4847\u001b[A\n",
      "Simulating N-1 Contingencies:  41%|███▏    | 4060/10000 [06:55<09:21, 10.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  34%|▎| 4180/12392 [00:00<00:00, 19506\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3276\u001b[A\n",
      "Simulating N-1 Contingencies:  41%|███▏    | 4061/10000 [06:56<12:21,  8.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4945/12392 [00:00<00:00, 49442\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5008\u001b[A\n",
      "Simulating N-1 Contingencies:  41%|███▏    | 4062/10000 [06:56<14:09,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4950/12392 [00:00<00:00, 49495\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3278\u001b[A\n",
      "Simulating N-1 Contingencies:  41%|███▎    | 4063/10000 [06:56<17:59,  5.50it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4940/12392 [00:00<00:00, 49395\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4969\u001b[A\n",
      "Simulating N-1 Contingencies:  41%|███▎    | 4067/10000 [06:57<13:14,  7.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4695/12392 [00:00<00:00, 46947\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3058\u001b[A\n",
      "Simulating N-1 Contingencies:  41%|███▎    | 4068/10000 [06:57<17:23,  5.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4555/12392 [00:00<00:00, 45543\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4811\u001b[A\n",
      "Simulating N-1 Contingencies:  41%|███▎    | 4075/10000 [06:58<10:08,  9.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4947/12392 [00:00<00:00, 49461\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3146\u001b[A\n",
      "Simulating N-1 Contingencies:  41%|███▎    | 4085/10000 [06:58<06:30, 15.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4932/12392 [00:00<00:00, 49313\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5003\u001b[A\n",
      "Simulating N-1 Contingencies:  41%|███▎    | 4088/10000 [06:58<07:13, 13.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4971/12392 [00:00<00:00, 49706\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3144\u001b[A\n",
      "Simulating N-1 Contingencies:  41%|███▎    | 4094/10000 [06:59<07:27, 13.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4723/12392 [00:00<00:00, 47225\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4851\u001b[A\n",
      "Simulating N-1 Contingencies:  41%|███▎    | 4097/10000 [06:59<08:02, 12.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4937/12392 [00:00<00:00, 49367\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4968\u001b[A\n",
      "Simulating N-1 Contingencies:  41%|███▎    | 4099/10000 [06:59<09:04, 10.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   4%| | 527/12392 [00:00<00:03, 3383.0\u001b[A\n",
      "Converting scenarios to PyG Data objects:  44%|▍| 5455/12392 [00:00<00:00, 25336\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3139\u001b[A\n",
      "Simulating N-1 Contingencies:  41%|███▎    | 4101/10000 [07:00<11:27,  8.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4963/12392 [00:00<00:00, 49627\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4980\u001b[A\n",
      "Simulating N-1 Contingencies:  41%|███▎    | 4108/10000 [07:00<08:11, 11.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4615/12392 [00:00<00:00, 46146\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4799\u001b[A\n",
      "Simulating N-1 Contingencies:  41%|███▎    | 4110/10000 [07:01<10:28,  9.37it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4945/12392 [00:00<00:00, 49448\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3200\u001b[A\n",
      "Simulating N-1 Contingencies:  41%|███▎    | 4116/10000 [07:01<09:18, 10.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4950/12392 [00:00<00:00, 49492\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5014\u001b[A\n",
      "Simulating N-1 Contingencies:  41%|███▎    | 4118/10000 [07:01<10:04,  9.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4901/12392 [00:00<00:00, 49006\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4935\u001b[A\n",
      "Simulating N-1 Contingencies:  41%|███▎    | 4125/10000 [07:02<07:42, 12.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  22%|▏| 2702/12392 [00:00<00:00, 14596\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3238\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4905/12392 [00:00<00:00, 49044\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4937\u001b[A\n",
      "Simulating N-1 Contingencies:  41%|███▎    | 4127/10000 [07:02<11:43,  8.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  32%|▎| 4007/12392 [00:00<00:00, 18887\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3250\u001b[A\n",
      "Simulating N-1 Contingencies:  41%|███▎    | 4129/10000 [07:03<13:19,  7.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4890/12392 [00:00<00:00, 48897\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4957\u001b[A\n",
      "Simulating N-1 Contingencies:  41%|███▎    | 4134/10000 [07:03<10:32,  9.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4790/12392 [00:00<00:00, 21282\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3288\u001b[A\n",
      "Simulating N-1 Contingencies:  41%|███▎    | 4136/10000 [07:04<12:18,  7.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4942/12392 [00:00<00:00, 49415\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4994\u001b[A\n",
      "Simulating N-1 Contingencies:  41%|███▎    | 4138/10000 [07:04<12:37,  7.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4940/12392 [00:00<00:00, 49392\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3269\u001b[A\n",
      "Simulating N-1 Contingencies:  41%|███▎    | 4143/10000 [07:04<11:00,  8.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4925/12392 [00:00<00:00, 49246\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4977\u001b[A\n",
      "Simulating N-1 Contingencies:  41%|███▎    | 4147/10000 [07:05<09:52,  9.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4708/12392 [00:00<00:00, 47072\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3192\u001b[A\n",
      "Simulating N-1 Contingencies:  42%|███▎    | 4151/10000 [07:05<10:12,  9.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4948/12392 [00:00<00:00, 49475\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4957\u001b[A\n",
      "Simulating N-1 Contingencies:  42%|███▎    | 4156/10000 [07:05<08:47, 11.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4936/12392 [00:00<00:00, 49359\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3194\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4886/12392 [00:00<00:00, 48856\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4932\u001b[A\n",
      "Simulating N-1 Contingencies:  42%|███▎    | 4158/10000 [07:06<13:02,  7.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4661/12392 [00:00<00:00, 46607\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4787\u001b[A\n",
      "Simulating N-1 Contingencies:  42%|███▎    | 4161/10000 [07:07<13:04,  7.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  36%|▎| 4511/12392 [00:00<00:00, 45105\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4775\u001b[A\n",
      "Simulating N-1 Contingencies:  42%|███▎    | 4164/10000 [07:07<12:04,  8.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4817/12392 [00:00<00:00, 48166\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4942\u001b[A\n",
      "Simulating N-1 Contingencies:  42%|███▎    | 4169/10000 [07:07<10:33,  9.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4606/12392 [00:00<00:00, 46056\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4694\u001b[A\n",
      "Simulating N-1 Contingencies:  42%|███▎    | 4171/10000 [07:08<11:36,  8.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4772/12392 [00:00<00:00, 47714\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3118\u001b[A\n",
      "Simulating N-1 Contingencies:  42%|███▎    | 4175/10000 [07:08<11:25,  8.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4789/12392 [00:00<00:00, 47884\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4910\u001b[A\n",
      "Simulating N-1 Contingencies:  42%|███▎    | 4178/10000 [07:08<10:54,  8.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4783/12392 [00:00<00:00, 47824\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4813\u001b[A\n",
      "Simulating N-1 Contingencies:  42%|███▎    | 4179/10000 [07:09<13:02,  7.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  17%|▏| 2093/12392 [00:00<00:00, 11279\u001b[A\n",
      "Converting scenarios to PyG Data objects:  57%|▌| 7035/12392 [00:00<00:00, 27867\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3148\u001b[A\n",
      "Simulating N-1 Contingencies:  42%|███▎    | 4180/10000 [07:09<17:21,  5.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4928/12392 [00:00<00:00, 49275\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4893\u001b[A\n",
      "Simulating N-1 Contingencies:  42%|███▎    | 4193/10000 [07:10<05:47, 16.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  14%|▏| 1745/12392 [00:00<00:01, 10615\u001b[A\n",
      "Converting scenarios to PyG Data objects:  53%|▌| 6510/12392 [00:00<00:00, 27834\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3229\u001b[A\n",
      "Simulating N-1 Contingencies:  42%|███▎    | 4197/10000 [07:10<07:09, 13.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4863/12392 [00:00<00:00, 48622\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4929\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  18%|▏| 2267/12392 [00:00<00:00, 12557\u001b[A\n",
      "Converting scenarios to PyG Data objects:  57%|▌| 7093/12392 [00:00<00:00, 28327\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3199\u001b[A\n",
      "Simulating N-1 Contingencies:  42%|███▎    | 4200/10000 [07:11<10:41,  9.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4932/12392 [00:00<00:00, 49315\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5004\u001b[A\n",
      "Simulating N-1 Contingencies:  42%|███▎    | 4209/10000 [07:11<07:20, 13.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  15%|▏| 1832/12392 [00:00<00:00, 11194\u001b[A\n",
      "Converting scenarios to PyG Data objects:  54%|▌| 6742/12392 [00:00<00:00, 28859\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3259\u001b[A\n",
      "Simulating N-1 Contingencies:  42%|███▎    | 4211/10000 [07:11<09:05, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4858/12392 [00:00<00:00, 48572\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4943\u001b[A\n",
      "Simulating N-1 Contingencies:  42%|███▎    | 4213/10000 [07:12<09:53,  9.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  19%|▏| 2354/12392 [00:00<00:00, 12412\u001b[A\n",
      "Converting scenarios to PyG Data objects:  58%|▌| 7175/12392 [00:00<00:00, 27791\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3123\u001b[A\n",
      "Simulating N-1 Contingencies:  42%|███▎    | 4215/10000 [07:12<12:00,  8.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4798/12392 [00:00<00:00, 47975\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4906\u001b[A\n",
      "Simulating N-1 Contingencies:  42%|███▎    | 4217/10000 [07:12<12:25,  7.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  27%|▎| 3309/12392 [00:00<00:00, 17001\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3297\u001b[A\n",
      "Simulating N-1 Contingencies:  42%|███▍    | 4221/10000 [07:13<11:41,  8.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4985/12392 [00:00<00:00, 49846\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4911\u001b[A\n",
      "Simulating N-1 Contingencies:  42%|███▍    | 4222/10000 [07:13<13:29,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4616/12392 [00:00<00:00, 20238\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3149\u001b[A\n",
      "Simulating N-1 Contingencies:  42%|███▍    | 4223/10000 [07:14<17:23,  5.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4809/12392 [00:00<00:00, 48079\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4768\u001b[A\n",
      "Simulating N-1 Contingencies:  42%|███▍    | 4232/10000 [07:14<08:43, 11.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  36%|▎| 4442/12392 [00:00<00:00, 19981\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3179\u001b[A\n",
      "Simulating N-1 Contingencies:  42%|███▍    | 4236/10000 [07:14<09:22, 10.25it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4774/12392 [00:00<00:00, 47737\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4922\u001b[A\n",
      "Simulating N-1 Contingencies:  42%|███▍    | 4243/10000 [07:15<07:28, 12.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  36%|▎| 4442/12392 [00:00<00:00, 19069\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3161\u001b[A\n",
      "Simulating N-1 Contingencies:  42%|███▍    | 4247/10000 [07:15<08:20, 11.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4837/12392 [00:00<00:00, 48363\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4884\u001b[A\n",
      "Simulating N-1 Contingencies:  42%|███▍    | 4249/10000 [07:16<09:12, 10.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4833/12392 [00:00<00:00, 48326\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3248\u001b[A\n",
      "Simulating N-1 Contingencies:  43%|███▍    | 4252/10000 [07:16<10:20,  9.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4936/12392 [00:00<00:00, 49354\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4971\u001b[A\n",
      "Simulating N-1 Contingencies:  43%|███▍    | 4259/10000 [07:16<07:47, 12.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4880/12392 [00:00<00:00, 48792\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3256\u001b[A\n",
      "Simulating N-1 Contingencies:  43%|███▍    | 4261/10000 [07:17<09:41,  9.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4940/12392 [00:00<00:00, 49396\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4972\u001b[A\n",
      "Simulating N-1 Contingencies:  43%|███▍    | 4267/10000 [07:17<07:56, 12.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4931/12392 [00:00<00:00, 49300\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3235\u001b[A\n",
      "Simulating N-1 Contingencies:  43%|███▍    | 4269/10000 [07:18<09:53,  9.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4942/12392 [00:00<00:00, 49414\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4875\u001b[A\n",
      "Simulating N-1 Contingencies:  43%|███▍    | 4275/10000 [07:18<08:03, 11.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4750/12392 [00:00<00:00, 47488\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3202\u001b[A\n",
      "Simulating N-1 Contingencies:  43%|███▍    | 4277/10000 [07:18<10:04,  9.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4765/12392 [00:00<00:00, 47640\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4933\u001b[A\n",
      "Simulating N-1 Contingencies:  43%|███▍    | 4283/10000 [07:19<08:07, 11.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4883/12392 [00:00<00:00, 48821\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4928\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  11%| | 1397/12392 [00:00<00:01, 8982.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  51%|▌| 6374/12392 [00:00<00:00, 28509\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3292\u001b[A\n",
      "Simulating N-1 Contingencies:  43%|███▍    | 4285/10000 [07:19<12:03,  7.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4952/12392 [00:00<00:00, 49515\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4973\u001b[A\n",
      "Simulating N-1 Contingencies:  43%|███▍    | 4286/10000 [07:20<13:31,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  12%| | 1484/12392 [00:00<00:01, 9540.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  52%|▌| 6415/12392 [00:00<00:00, 28578\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3282\u001b[A\n",
      "Simulating N-1 Contingencies:  43%|███▍    | 4289/10000 [07:20<13:31,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4938/12392 [00:00<00:00, 49374\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4926\u001b[A\n",
      "Simulating N-1 Contingencies:  43%|███▍    | 4292/10000 [07:20<12:18,  7.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  12%| | 1482/12392 [00:00<00:01, 9373.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  52%|▌| 6405/12392 [00:00<00:00, 28290\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3265\u001b[A\n",
      "Simulating N-1 Contingencies:  43%|███▍    | 4300/10000 [07:21<08:47, 10.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4922/12392 [00:00<00:00, 49218\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4957\u001b[A\n",
      "Simulating N-1 Contingencies:  43%|███▍    | 4302/10000 [07:21<09:34,  9.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  18%|▏| 2180/12392 [00:00<00:00, 12873\u001b[A\n",
      "Converting scenarios to PyG Data objects:  58%|▌| 7155/12392 [00:00<00:00, 29746\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3304\u001b[A\n",
      "Simulating N-1 Contingencies:  43%|███▍    | 4303/10000 [07:21<12:30,  7.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4730/12392 [00:00<00:00, 47297\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4801\u001b[A\n",
      "Simulating N-1 Contingencies:  43%|███▍    | 4304/10000 [07:22<14:22,  6.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  23%|▏| 2876/12392 [00:00<00:00, 15590\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3307\u001b[A\n",
      "Simulating N-1 Contingencies:  43%|███▍    | 4306/10000 [07:22<15:45,  6.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4958/12392 [00:00<00:00, 49569\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4981\u001b[A\n",
      "Simulating N-1 Contingencies:  43%|███▍    | 4312/10000 [07:22<10:08,  9.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  20%|▏| 2439/12392 [00:00<00:00, 13860\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3307\u001b[A\n",
      "Simulating N-1 Contingencies:  43%|███▍    | 4316/10000 [07:23<10:12,  9.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4966/12392 [00:00<00:00, 49653\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4946\u001b[A\n",
      "Simulating N-1 Contingencies:  43%|███▍    | 4318/10000 [07:23<10:52,  8.71it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:  43%|███▍    | 4326/10000 [07:23<05:46, 16.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  18%|▏| 2267/12392 [00:00<00:00, 12934\u001b[A\n",
      "Converting scenarios to PyG Data objects:  58%|▌| 7176/12392 [00:00<00:00, 29169\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3261\u001b[A\n",
      "Simulating N-1 Contingencies:  43%|███▍    | 4329/10000 [07:24<07:28, 12.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4616/12392 [00:00<00:00, 46158\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4745\u001b[A\n",
      "Simulating N-1 Contingencies:  43%|███▍    | 4334/10000 [07:24<07:04, 13.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  16%|▏| 2004/12392 [00:00<00:00, 11827\u001b[A\n",
      "Converting scenarios to PyG Data objects:  56%|▌| 6919/12392 [00:00<00:00, 28898\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3257\u001b[A\n",
      "Simulating N-1 Contingencies:  43%|███▍    | 4337/10000 [07:25<08:33, 11.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4916/12392 [00:00<00:00, 49158\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4839\u001b[A\n",
      "Simulating N-1 Contingencies:  43%|███▍    | 4339/10000 [07:25<09:31,  9.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  17%|▏| 2093/12392 [00:00<00:00, 11174\u001b[A\n",
      "Converting scenarios to PyG Data objects:  55%|▌| 6778/12392 [00:00<00:00, 26609\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3043\u001b[A\n",
      "Simulating N-1 Contingencies:  43%|███▍    | 4341/10000 [07:25<11:52,  7.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4769/12392 [00:00<00:00, 47686\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4724\u001b[A\n",
      "Simulating N-1 Contingencies:  43%|███▍    | 4343/10000 [07:26<12:23,  7.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  18%|▏| 2267/12392 [00:00<00:00, 12260\u001b[A\n",
      "Converting scenarios to PyG Data objects:  57%|▌| 7020/12392 [00:00<00:00, 27630\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3133\u001b[A\n",
      "Simulating N-1 Contingencies:  44%|███▍    | 4350/10000 [07:26<09:23, 10.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4896/12392 [00:00<00:00, 48950\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4954\u001b[A\n",
      "Simulating N-1 Contingencies:  44%|███▍    | 4352/10000 [07:26<10:07,  9.29it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  20%|▏| 2441/12392 [00:00<00:00, 13632\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3286\u001b[A\n",
      "Simulating N-1 Contingencies:  44%|███▍    | 4359/10000 [07:27<08:21, 11.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4759/12392 [00:00<00:00, 47584\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4869\u001b[A\n",
      "Simulating N-1 Contingencies:  44%|███▍    | 4367/10000 [07:27<06:35, 14.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  15%|▏| 1830/12392 [00:00<00:00, 10692\u001b[A\n",
      "Converting scenarios to PyG Data objects:  54%|▌| 6679/12392 [00:00<00:00, 27886\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3196\u001b[A\n",
      "Simulating N-1 Contingencies:  44%|███▍    | 4371/10000 [07:28<07:31, 12.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  30%|▎| 3666/12392 [00:00<00:00, 33518\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4141\u001b[A\n",
      "Simulating N-1 Contingencies:  44%|███▌    | 4381/10000 [07:28<05:21, 17.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   8%| | 1047/12392 [00:00<00:01, 6731.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  48%|▍| 5970/12392 [00:00<00:00, 27076\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3187\u001b[A\n",
      "Simulating N-1 Contingencies:  44%|███▌    | 4385/10000 [07:29<06:45, 13.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4811/12392 [00:00<00:00, 48102\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4893\u001b[A\n",
      "Simulating N-1 Contingencies:  44%|███▌    | 4393/10000 [07:29<06:04, 15.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4834/12392 [00:00<00:00, 48330\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4941\u001b[A\n",
      "Simulating N-1 Contingencies:  44%|███▌    | 4396/10000 [07:29<06:47, 13.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4979/12392 [00:00<00:00, 49781\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4913\u001b[A\n",
      "Simulating N-1 Contingencies:  44%|███▌    | 4398/10000 [07:30<07:57, 11.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   6%| | 700/12392 [00:00<00:02, 5016.9\u001b[A\n",
      "Converting scenarios to PyG Data objects:  46%|▍| 5665/12392 [00:00<00:00, 27594\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3304\u001b[A\n",
      "Simulating N-1 Contingencies:  44%|███▌    | 4400/10000 [07:30<10:11,  9.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4990/12392 [00:00<00:00, 49898\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5017\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  11%| | 1395/12392 [00:00<00:01, 9095.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  51%|▌| 6349/12392 [00:00<00:00, 28598\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3311\u001b[A\n",
      "Simulating N-1 Contingencies:  44%|███▌    | 4402/10000 [07:31<14:50,  6.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4980/12392 [00:00<00:00, 49796\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5026\u001b[A\n",
      "Simulating N-1 Contingencies:  44%|███▌    | 4407/10000 [07:31<10:54,  8.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  13%|▏| 1569/12392 [00:00<00:01, 9927.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  53%|▌| 6526/12392 [00:00<00:00, 28747\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3304\u001b[A\n",
      "Simulating N-1 Contingencies:  44%|███▌    | 4411/10000 [07:31<10:39,  8.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4904/12392 [00:00<00:00, 49036\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4867\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  23%|▏| 2876/12392 [00:00<00:00, 14784\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3144\u001b[A\n",
      "Simulating N-1 Contingencies:  44%|███▌    | 4413/10000 [07:32<14:53,  6.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4750/12392 [00:00<00:00, 47493\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4917\u001b[A\n",
      "Simulating N-1 Contingencies:  44%|███▌    | 4414/10000 [07:32<16:12,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  32%|▎| 4007/12392 [00:00<00:00, 18456\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3193\u001b[A\n",
      "Simulating N-1 Contingencies:  44%|███▌    | 4417/10000 [07:33<15:18,  6.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4781/12392 [00:00<00:00, 47805\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4850\u001b[A\n",
      "Simulating N-1 Contingencies:  44%|███▌    | 4418/10000 [07:33<16:49,  5.53it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4793/12392 [00:00<00:00, 47922\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3220\u001b[A\n",
      "Simulating N-1 Contingencies:  44%|███▌    | 4422/10000 [07:34<13:58,  6.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4692/12392 [00:00<00:00, 46910\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4766\u001b[A\n",
      "Simulating N-1 Contingencies:  44%|███▌    | 4424/10000 [07:34<13:57,  6.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4773/12392 [00:00<00:00, 47724\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3193\u001b[A\n",
      "Simulating N-1 Contingencies:  44%|███▌    | 4429/10000 [07:34<11:28,  8.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4815/12392 [00:00<00:00, 48140\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4894\u001b[A\n",
      "Simulating N-1 Contingencies:  44%|███▌    | 4430/10000 [07:35<13:08,  7.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4954/12392 [00:00<00:00, 49536\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3257\u001b[A\n",
      "Simulating N-1 Contingencies:  44%|███▌    | 4432/10000 [07:35<14:42,  6.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4975/12392 [00:00<00:00, 49739\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5008\u001b[A\n",
      "Simulating N-1 Contingencies:  44%|███▌    | 4433/10000 [07:35<16:17,  5.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4948/12392 [00:00<00:00, 49469\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3258\u001b[A\n",
      "Simulating N-1 Contingencies:  44%|███▌    | 4440/10000 [07:36<10:17,  9.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4959/12392 [00:00<00:00, 49581\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4994\u001b[A\n",
      "Simulating N-1 Contingencies:  44%|███▌    | 4443/10000 [07:36<09:59,  9.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4995/12392 [00:00<00:00, 49945\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5002\u001b[A\n",
      "Simulating N-1 Contingencies:  45%|███▌    | 4452/10000 [07:37<05:44, 16.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  10%| | 1222/12392 [00:00<00:01, 7740.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  50%|▌| 6201/12392 [00:00<00:00, 27715\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3248\u001b[A\n",
      "Simulating N-1 Contingencies:  45%|███▌    | 4458/10000 [07:37<06:18, 14.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4956/12392 [00:00<00:00, 49554\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4982\u001b[A\n",
      "Simulating N-1 Contingencies:  45%|███▌    | 4464/10000 [07:37<05:53, 15.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   8%| | 962/12392 [00:00<00:01, 6690.4\u001b[A\n",
      "Converting scenarios to PyG Data objects:  48%|▍| 5924/12392 [00:00<00:00, 28083\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3321\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4669/12392 [00:00<00:00, 46683\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4733\u001b[A\n",
      "Simulating N-1 Contingencies:  45%|███▌    | 4467/10000 [07:38<09:00, 10.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  13%|▏| 1656/12392 [00:00<00:01, 9319.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  51%|▌| 6280/12392 [00:00<00:00, 25770\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3048\u001b[A\n",
      "Simulating N-1 Contingencies:  45%|███▌    | 4469/10000 [07:38<10:52,  8.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4773/12392 [00:00<00:00, 47720\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4883\u001b[A\n",
      "Simulating N-1 Contingencies:  45%|███▌    | 4471/10000 [07:39<11:21,  8.11it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:  45%|███▌    | 4479/10000 [07:39<06:06, 15.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   7%| | 873/12392 [00:00<00:02, 5561.9\u001b[A\n",
      "Converting scenarios to PyG Data objects:  45%|▍| 5620/12392 [00:00<00:00, 25529\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3121\u001b[A\n",
      "Simulating N-1 Contingencies:  45%|███▌    | 4491/10000 [07:39<04:40, 19.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4704/12392 [00:00<00:00, 47020\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4818\u001b[A\n",
      "Simulating N-1 Contingencies:  45%|███▌    | 4496/10000 [07:40<05:43, 16.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4955/12392 [00:00<00:00, 49546\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4966\u001b[A\n",
      "Simulating N-1 Contingencies:  45%|███▌    | 4516/10000 [07:40<03:04, 29.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  33%|▎| 4090/12392 [00:00<00:00, 40891\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 2968\u001b[A\n",
      "Simulating N-1 Contingencies:  45%|███▌    | 4522/10000 [07:41<04:23, 20.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4700/12392 [00:00<00:00, 46993\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4789\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4836/12392 [00:00<00:00, 48352\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4900\u001b[A\n",
      "Simulating N-1 Contingencies:  45%|███▌    | 4526/10000 [07:42<06:56, 13.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4579/12392 [00:00<00:00, 45779\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4705\u001b[A\n",
      "Simulating N-1 Contingencies:  45%|███▌    | 4529/10000 [07:42<07:26, 12.26it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4738/12392 [00:00<00:00, 47370\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4872\u001b[A\n",
      "Simulating N-1 Contingencies:  45%|███▋    | 4533/10000 [07:42<07:22, 12.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4779/12392 [00:00<00:00, 47784\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4879\u001b[A\n",
      "Simulating N-1 Contingencies:  45%|███▋    | 4535/10000 [07:43<09:21,  9.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4865/12392 [00:00<00:00, 48641\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4868\u001b[A\n",
      "Simulating N-1 Contingencies:  45%|███▋    | 4539/10000 [07:43<09:25,  9.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4975/12392 [00:00<00:00, 49749\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5020\u001b[A\n",
      "Simulating N-1 Contingencies:  45%|███▋    | 4542/10000 [07:43<09:16,  9.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 5013/12392 [00:00<00:00, 50124\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5027\u001b[A\n",
      "Simulating N-1 Contingencies:  45%|███▋    | 4544/10000 [07:44<11:24,  7.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4754/12392 [00:00<00:00, 47535\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4864\u001b[A\n",
      "Simulating N-1 Contingencies:  45%|███▋    | 4545/10000 [07:44<13:22,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4614/12392 [00:00<00:00, 46132\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4798\u001b[A\n",
      "Simulating N-1 Contingencies:  45%|███▋    | 4548/10000 [07:45<13:19,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4961/12392 [00:00<00:00, 49604\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4992\u001b[A\n",
      "Simulating N-1 Contingencies:  46%|███▋    | 4560/10000 [07:45<04:49, 18.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4821/12392 [00:00<00:00, 48199\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3187\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4995/12392 [00:00<00:00, 49946\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5009\u001b[A\n",
      "Simulating N-1 Contingencies:  46%|███▋    | 4564/10000 [07:46<08:05, 11.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4888/12392 [00:00<00:00, 48864\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4952\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  13%|▏| 1658/12392 [00:00<00:01, 10434\u001b[A\n",
      "Converting scenarios to PyG Data objects:  53%|▌| 6582/12392 [00:00<00:00, 28804\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3278\u001b[A\n",
      "Simulating N-1 Contingencies:  46%|███▋    | 4575/10000 [07:47<06:22, 14.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4955/12392 [00:00<00:00, 49545\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4979\u001b[A\n",
      "Simulating N-1 Contingencies:  46%|███▋    | 4579/10000 [07:47<06:31, 13.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  12%| | 1484/12392 [00:00<00:01, 9247.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  49%|▍| 6116/12392 [00:00<00:00, 26706\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3197\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4807/12392 [00:00<00:00, 48058\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4907\u001b[A\n",
      "Simulating N-1 Contingencies:  46%|███▋    | 4582/10000 [07:48<09:38,  9.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   8%| | 960/12392 [00:00<00:01, 6236.6\u001b[A\n",
      "Converting scenarios to PyG Data objects:  47%|▍| 5837/12392 [00:00<00:00, 26708\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3211\u001b[A\n",
      "Simulating N-1 Contingencies:  46%|███▋    | 4585/10000 [07:48<10:27,  8.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4835/12392 [00:00<00:00, 48343\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4925\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  18%|▏| 2267/12392 [00:00<00:00, 12823\u001b[A\n",
      "Converting scenarios to PyG Data objects:  57%|▌| 7093/12392 [00:00<00:00, 28659\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3218\u001b[A\n",
      "Simulating N-1 Contingencies:  46%|███▋    | 4587/10000 [07:49<14:10,  6.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4901/12392 [00:00<00:00, 49006\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4943\u001b[A\n",
      "Simulating N-1 Contingencies:  46%|███▋    | 4589/10000 [07:49<13:56,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  21%|▏| 2613/12392 [00:00<00:00, 14288\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3239\u001b[A\n",
      "Simulating N-1 Contingencies:  46%|███▋    | 4594/10000 [07:49<11:31,  7.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4955/12392 [00:00<00:00, 49544\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4951\u001b[A\n",
      "Simulating N-1 Contingencies:  46%|███▋    | 4599/10000 [07:50<09:22,  9.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  29%|▎| 3572/12392 [00:00<00:00, 17762\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3284\u001b[A\n",
      "Simulating N-1 Contingencies:  46%|███▋    | 4601/10000 [07:50<11:01,  8.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4949/12392 [00:00<00:00, 49475\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4948\u001b[A\n",
      "Simulating N-1 Contingencies:  46%|███▋    | 4611/10000 [07:51<05:54, 15.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  22%|▏| 2788/12392 [00:00<00:00, 14871\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3250\u001b[A\n",
      "Simulating N-1 Contingencies:  46%|███▋    | 4614/10000 [07:51<07:27, 12.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4871/12392 [00:00<00:00, 48702\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4916\u001b[A\n",
      "Simulating N-1 Contingencies:  46%|███▋    | 4617/10000 [07:51<07:50, 11.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  35%|▎| 4355/12392 [00:00<00:00, 19730\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3244\u001b[A\n",
      "Simulating N-1 Contingencies:  46%|███▋    | 4619/10000 [07:52<09:53,  9.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4837/12392 [00:00<00:00, 48369\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4949\u001b[A\n",
      "Simulating N-1 Contingencies:  46%|███▋    | 4622/10000 [07:52<09:37,  9.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4943/12392 [00:00<00:00, 49424\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3219\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4973/12392 [00:00<00:00, 49725\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4991\u001b[A\n",
      "Simulating N-1 Contingencies:  46%|███▋    | 4624/10000 [07:53<14:06,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4944/12392 [00:00<00:00, 49438\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3224\u001b[A\n",
      "Simulating N-1 Contingencies:  46%|███▋    | 4632/10000 [07:53<09:22,  9.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4971/12392 [00:00<00:00, 49704\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4980\u001b[A\n",
      "Simulating N-1 Contingencies:  46%|███▋    | 4635/10000 [07:53<09:16,  9.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4870/12392 [00:00<00:00, 48691\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3221\u001b[A\n",
      "Simulating N-1 Contingencies:  46%|███▋    | 4638/10000 [07:54<10:10,  8.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4871/12392 [00:00<00:00, 48705\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4943\u001b[A\n",
      "Simulating N-1 Contingencies:  46%|███▋    | 4641/10000 [07:54<09:52,  9.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4922/12392 [00:00<00:00, 49214\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3229\u001b[A\n",
      "Simulating N-1 Contingencies:  46%|███▋    | 4645/10000 [07:55<09:53,  9.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 5009/12392 [00:00<00:00, 50082\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5008\u001b[A\n",
      "Simulating N-1 Contingencies:  47%|███▋    | 4651/10000 [07:55<07:49, 11.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4961/12392 [00:00<00:00, 49603\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4971\u001b[A\n",
      "Simulating N-1 Contingencies:  47%|███▋    | 4653/10000 [07:55<08:40, 10.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  20%|▏| 2528/12392 [00:00<00:00, 14214\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3297\u001b[A\n",
      "Simulating N-1 Contingencies:  47%|███▋    | 4655/10000 [07:56<10:31,  8.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4897/12392 [00:00<00:00, 48962\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4937\u001b[A\n",
      "Simulating N-1 Contingencies:  47%|███▋    | 4662/10000 [07:56<07:32, 11.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  17%|▏| 2093/12392 [00:00<00:00, 12465\u001b[A\n",
      "Converting scenarios to PyG Data objects:  57%|▌| 7088/12392 [00:00<00:00, 29697\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3306\u001b[A\n",
      "Simulating N-1 Contingencies:  47%|███▋    | 4665/10000 [07:56<08:41, 10.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4906/12392 [00:00<00:00, 49054\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4944\u001b[A\n",
      "Simulating N-1 Contingencies:  47%|███▋    | 4670/10000 [07:57<07:38, 11.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  20%|▏| 2441/12392 [00:00<00:00, 13696\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3290\u001b[A\n",
      "Simulating N-1 Contingencies:  47%|███▋    | 4672/10000 [07:57<09:27,  9.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 5006/12392 [00:00<00:00, 50058\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4974\u001b[A\n",
      "Simulating N-1 Contingencies:  47%|███▋    | 4673/10000 [07:57<11:02,  8.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  27%|▎| 3396/12392 [00:00<00:00, 17270\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3298\u001b[A\n",
      "Simulating N-1 Contingencies:  47%|███▋    | 4678/10000 [07:58<09:42,  9.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4946/12392 [00:00<00:00, 49454\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4973\u001b[A\n",
      "Simulating N-1 Contingencies:  47%|███▋    | 4680/10000 [07:58<10:17,  8.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  35%|▎| 4353/12392 [00:00<00:00, 19685\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3235\u001b[A\n",
      "Simulating N-1 Contingencies:  47%|███▋    | 4684/10000 [07:59<10:07,  8.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4947/12392 [00:00<00:00, 49467\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4955\u001b[A\n",
      "Simulating N-1 Contingencies:  47%|███▋    | 4685/10000 [07:59<11:45,  7.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4759/12392 [00:00<00:00, 47586\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3191\u001b[A\n",
      "Simulating N-1 Contingencies:  47%|███▋    | 4687/10000 [07:59<13:32,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4583/12392 [00:00<00:00, 45829\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4751\u001b[A\n",
      "Simulating N-1 Contingencies:  47%|███▊    | 4688/10000 [08:00<15:18,  5.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4877/12392 [00:00<00:00, 48697\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3206\u001b[A\n",
      "Simulating N-1 Contingencies:  47%|███▊    | 4693/10000 [08:00<11:36,  7.62it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4940/12392 [00:00<00:00, 49397\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4990\u001b[A\n",
      "Simulating N-1 Contingencies:  47%|███▊    | 4709/10000 [08:01<04:40, 18.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4802/12392 [00:00<00:00, 48017\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3221\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4997/12392 [00:00<00:00, 49964\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4975\u001b[A\n",
      "Simulating N-1 Contingencies:  47%|███▊    | 4713/10000 [08:01<07:16, 12.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4941/12392 [00:00<00:00, 49400\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3269\u001b[A\n",
      "Simulating N-1 Contingencies:  47%|███▊    | 4718/10000 [08:02<07:28, 11.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4912/12392 [00:00<00:00, 49116\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4945\u001b[A\n",
      "Simulating N-1 Contingencies:  47%|███▊    | 4721/10000 [08:02<07:45, 11.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4939/12392 [00:00<00:00, 49384\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3230\u001b[A\n",
      "Simulating N-1 Contingencies:  47%|███▊    | 4728/10000 [08:03<07:03, 12.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4891/12392 [00:00<00:00, 48907\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4959\u001b[A\n",
      "Simulating N-1 Contingencies:  47%|███▊    | 4731/10000 [08:03<07:23, 11.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4945/12392 [00:00<00:00, 49448\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4976\u001b[A\n",
      "Simulating N-1 Contingencies:  47%|███▊    | 4733/10000 [08:03<08:13, 10.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  10%| | 1221/12392 [00:00<00:01, 8127.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  50%|▍| 6148/12392 [00:00<00:00, 28179\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3302\u001b[A\n",
      "Simulating N-1 Contingencies:  47%|███▊    | 4740/10000 [08:04<07:11, 12.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 5003/12392 [00:00<00:00, 50027\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5008\u001b[A\n",
      "Simulating N-1 Contingencies:  47%|███▊    | 4742/10000 [08:04<08:00, 10.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  19%|▏| 2354/12392 [00:00<00:00, 13338\u001b[A\n",
      "Converting scenarios to PyG Data objects:  59%|▌| 7360/12392 [00:00<00:00, 29764\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3274\u001b[A\n",
      "Simulating N-1 Contingencies:  47%|███▊    | 4744/10000 [08:04<09:50,  8.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4788/12392 [00:00<00:00, 47867\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4877\u001b[A\n",
      "Simulating N-1 Contingencies:  47%|███▊    | 4747/10000 [08:05<09:35,  9.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  22%|▏| 2700/12392 [00:00<00:00, 14769\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3273\u001b[A\n",
      "Simulating N-1 Contingencies:  48%|███▊    | 4751/10000 [08:05<09:36,  9.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4633/12392 [00:00<00:00, 46322\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4828\u001b[A\n",
      "Simulating N-1 Contingencies:  48%|███▊    | 4753/10000 [08:05<10:15,  8.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  25%|▏| 3048/12392 [00:00<00:00, 15997\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3250\u001b[A\n",
      "Simulating N-1 Contingencies:  48%|███▊    | 4758/10000 [08:06<09:19,  9.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4853/12392 [00:00<00:00, 48526\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4902\u001b[A\n",
      "Simulating N-1 Contingencies:  48%|███▊    | 4767/10000 [08:06<05:32, 15.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  22%|▏| 2701/12392 [00:00<00:00, 14573\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3229\u001b[A\n",
      "Simulating N-1 Contingencies:  48%|███▊    | 4773/10000 [08:07<06:01, 14.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4936/12392 [00:00<00:00, 49352\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4939\u001b[A\n",
      "Simulating N-1 Contingencies:  48%|███▊    | 4776/10000 [08:07<06:35, 13.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  30%|▎| 3657/12392 [00:00<00:00, 17535\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3192\u001b[A\n",
      "Simulating N-1 Contingencies:  48%|███▊    | 4779/10000 [08:07<07:59, 10.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4786/12392 [00:00<00:00, 47856\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4881\u001b[A\n",
      "Simulating N-1 Contingencies:  48%|███▊    | 4781/10000 [08:08<08:50,  9.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4891/12392 [00:00<00:00, 48901\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 2948\u001b[A\n",
      "Simulating N-1 Contingencies:  48%|███▊    | 4784/10000 [08:08<10:09,  8.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4737/12392 [00:00<00:00, 47363\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4771\u001b[A\n",
      "Simulating N-1 Contingencies:  48%|███▊    | 4788/10000 [08:08<09:05,  9.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4731/12392 [00:00<00:00, 47307\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3155\u001b[A\n",
      "Simulating N-1 Contingencies:  48%|███▊    | 4791/10000 [08:09<10:07,  8.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4779/12392 [00:00<00:00, 47784\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4873\u001b[A\n",
      "Simulating N-1 Contingencies:  48%|███▊    | 4802/10000 [08:09<05:19, 16.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4777/12392 [00:00<00:00, 47765\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3206\u001b[A\n",
      "Simulating N-1 Contingencies:  48%|███▊    | 4805/10000 [08:10<06:55, 12.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4765/12392 [00:00<00:00, 47642\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4904\u001b[A\n",
      "Simulating N-1 Contingencies:  48%|███▊    | 4811/10000 [08:10<06:08, 14.08it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:  48%|███▊    | 4820/10000 [08:10<03:51, 22.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4935/12392 [00:00<00:00, 49344\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3237\u001b[A\n",
      "/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:  48%|███▊    | 4824/10000 [08:11<05:07, 16.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4797/12392 [00:00<00:00, 47964\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4889\u001b[A\n",
      "Simulating N-1 Contingencies:  48%|███▊    | 4829/10000 [08:11<05:15, 16.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4911/12392 [00:00<00:00, 49101\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3263\u001b[A\n",
      "Simulating N-1 Contingencies:  48%|███▊    | 4832/10000 [08:11<06:38, 12.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4935/12392 [00:00<00:00, 49348\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4955\u001b[A\n",
      "Simulating N-1 Contingencies:  48%|███▊    | 4835/10000 [08:12<07:04, 12.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4963/12392 [00:00<00:00, 49623\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3252\u001b[A\n",
      "Simulating N-1 Contingencies:  48%|███▊    | 4841/10000 [08:12<06:55, 12.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 5000/12392 [00:00<00:00, 49991\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4971\u001b[A\n",
      "Simulating N-1 Contingencies:  48%|███▊    | 4843/10000 [08:12<07:45, 11.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4788/12392 [00:00<00:00, 47872\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4876\u001b[A\n",
      "Simulating N-1 Contingencies:  48%|███▉    | 4845/10000 [08:13<08:38,  9.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   4%| | 527/12392 [00:00<00:03, 3687.6\u001b[A\n",
      "Converting scenarios to PyG Data objects:  44%|▍| 5434/12392 [00:00<00:00, 26372\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3242\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4693/12392 [00:00<00:00, 46929\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4810\u001b[A\n",
      "Simulating N-1 Contingencies:  48%|███▉    | 4847/10000 [08:13<12:56,  6.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  15%|▏| 1832/12392 [00:00<00:00, 11152\u001b[A\n",
      "Converting scenarios to PyG Data objects:  55%|▌| 6832/12392 [00:00<00:00, 29219\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3295\u001b[A\n",
      "Simulating N-1 Contingencies:  48%|███▉    | 4848/10000 [08:14<15:41,  5.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 5010/12392 [00:00<00:00, 50092\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5031\u001b[A\n",
      "Simulating N-1 Contingencies:  48%|███▉    | 4849/10000 [08:14<16:51,  5.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  25%|▎| 3137/12392 [00:00<00:00, 16677\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3331\u001b[A\n",
      "Simulating N-1 Contingencies:  48%|███▉    | 4850/10000 [08:15<19:57,  4.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4998/12392 [00:00<00:00, 49974\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5022\u001b[A\n",
      "Simulating N-1 Contingencies:  49%|███▉    | 4851/10000 [08:15<20:38,  4.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4861/12392 [00:00<00:00, 48606\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3248\u001b[A\n",
      "Simulating N-1 Contingencies:  49%|███▉    | 4853/10000 [08:15<19:39,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4933/12392 [00:00<00:00, 49328\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4972\u001b[A\n",
      "Simulating N-1 Contingencies:  49%|███▉    | 4854/10000 [08:15<20:27,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4959/12392 [00:00<00:00, 49585\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3285\u001b[A\n",
      "Simulating N-1 Contingencies:  49%|███▉    | 4857/10000 [08:16<16:32,  5.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4967/12392 [00:00<00:00, 49662\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4992\u001b[A\n",
      "Simulating N-1 Contingencies:  49%|███▉    | 4862/10000 [08:16<10:41,  8.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4902/12392 [00:00<00:00, 49015\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3173\u001b[A\n",
      "Simulating N-1 Contingencies:  49%|███▉    | 4864/10000 [08:17<12:27,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4931/12392 [00:00<00:00, 49304\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4915\u001b[A\n",
      "Simulating N-1 Contingencies:  49%|███▉    | 4867/10000 [08:17<11:11,  7.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4932/12392 [00:00<00:00, 49316\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3230\u001b[A\n",
      "Simulating N-1 Contingencies:  49%|███▉    | 4869/10000 [08:17<12:49,  6.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4985/12392 [00:00<00:00, 49840\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4994\u001b[A\n",
      "Simulating N-1 Contingencies:  49%|███▉    | 4870/10000 [08:18<14:21,  5.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4997/12392 [00:00<00:00, 49968\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5026\u001b[A\n",
      "Simulating N-1 Contingencies:  49%|███▉    | 4871/10000 [08:18<15:52,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  15%|▏| 1919/12392 [00:00<00:00, 11662\u001b[A\n",
      "Converting scenarios to PyG Data objects:  55%|▌| 6794/12392 [00:00<00:00, 28896\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3285\u001b[A\n",
      "Simulating N-1 Contingencies:  49%|███▉    | 4873/10000 [08:18<16:28,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4915/12392 [00:00<00:00, 49148\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4951\u001b[A\n",
      "Simulating N-1 Contingencies:  49%|███▉    | 4876/10000 [08:19<13:10,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  23%|▏| 2876/12392 [00:00<00:00, 15250\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3257\u001b[A\n",
      "Simulating N-1 Contingencies:  49%|███▉    | 4888/10000 [08:19<05:34, 15.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4966/12392 [00:00<00:00, 49652\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5013\u001b[A\n",
      "Simulating N-1 Contingencies:  49%|███▉    | 4891/10000 [08:19<06:12, 13.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  17%|▏| 2091/12392 [00:00<00:00, 12530\u001b[A\n",
      "Converting scenarios to PyG Data objects:  57%|▌| 7101/12392 [00:00<00:00, 29856\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3321\u001b[A\n",
      "Simulating N-1 Contingencies:  49%|███▉    | 4894/10000 [08:20<07:37, 11.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4962/12392 [00:00<00:00, 49609\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4958\u001b[A\n",
      "Simulating N-1 Contingencies:  49%|███▉    | 4897/10000 [08:20<07:49, 10.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  15%|▏| 1830/12392 [00:00<00:00, 10690\u001b[A\n",
      "Converting scenarios to PyG Data objects:  54%|▌| 6735/12392 [00:00<00:00, 28139\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3215\u001b[A\n",
      "Simulating N-1 Contingencies:  49%|███▉    | 4901/10000 [08:21<08:23, 10.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4894/12392 [00:00<00:00, 48934\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4914\u001b[A\n",
      "Simulating N-1 Contingencies:  49%|███▉    | 4908/10000 [08:21<06:30, 13.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  13%|▏| 1656/12392 [00:00<00:01, 10017\u001b[A\n",
      "Converting scenarios to PyG Data objects:  51%|▌| 6283/12392 [00:00<00:00, 26821\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3147\u001b[A\n",
      "Simulating N-1 Contingencies:  49%|███▉    | 4914/10000 [08:21<06:35, 12.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4741/12392 [00:00<00:00, 47404\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4793\u001b[A\n",
      "Simulating N-1 Contingencies:  49%|███▉    | 4916/10000 [08:22<07:28, 11.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  27%|▎| 3398/12392 [00:00<00:00, 16776\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3210\u001b[A\n",
      "Simulating N-1 Contingencies:  49%|███▉    | 4927/10000 [08:22<04:56, 17.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4673/12392 [00:00<00:00, 46728\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4801\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  26%|▎| 3224/12392 [00:00<00:00, 16816\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3291\u001b[A\n",
      "Simulating N-1 Contingencies:  49%|███▉    | 4931/10000 [08:23<07:27, 11.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4958/12392 [00:00<00:00, 49574\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5002\u001b[A\n",
      "Simulating N-1 Contingencies:  49%|███▉    | 4937/10000 [08:23<06:28, 13.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  25%|▏| 3048/12392 [00:00<00:00, 16292\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3314\u001b[A\n",
      "Simulating N-1 Contingencies:  49%|███▉    | 4943/10000 [08:24<06:27, 13.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4937/12392 [00:00<00:00, 49367\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4993\u001b[A\n",
      "Simulating N-1 Contingencies:  50%|███▉    | 4950/10000 [08:24<05:38, 14.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  26%|▎| 3224/12392 [00:00<00:00, 16915\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3306\u001b[A\n",
      "Simulating N-1 Contingencies:  50%|███▉    | 4952/10000 [08:25<07:07, 11.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4964/12392 [00:00<00:00, 49526\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4999\u001b[A\n",
      "Simulating N-1 Contingencies:  50%|███▉    | 4958/10000 [08:25<06:14, 13.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  25%|▏| 3050/12392 [00:00<00:00, 15931\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3214\u001b[A\n",
      "Simulating N-1 Contingencies:  50%|███▉    | 4965/10000 [08:25<06:04, 13.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4947/12392 [00:00<00:00, 49460\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4988\u001b[A\n",
      "Simulating N-1 Contingencies:  50%|███▉    | 4967/10000 [08:26<06:51, 12.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  30%|▎| 3746/12392 [00:00<00:00, 18407\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3287\u001b[A\n",
      "Simulating N-1 Contingencies:  50%|███▉    | 4969/10000 [08:26<08:30,  9.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4861/12392 [00:00<00:00, 48600\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4924\u001b[A\n",
      "Simulating N-1 Contingencies:  50%|███▉    | 4975/10000 [08:26<06:58, 12.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4529/12392 [00:00<00:00, 20700\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3288\u001b[A\n",
      "/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:  50%|███▉    | 4977/10000 [08:27<08:38,  9.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4948/12392 [00:00<00:00, 49469\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4970\u001b[A\n",
      "Simulating N-1 Contingencies:  50%|███▉    | 4982/10000 [08:27<07:26, 11.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4703/12392 [00:00<00:00, 21246\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3295\u001b[A\n",
      "Simulating N-1 Contingencies:  50%|███▉    | 4985/10000 [08:28<08:29,  9.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4959/12392 [00:00<00:00, 49588\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4986\u001b[A\n",
      "Simulating N-1 Contingencies:  50%|███▉    | 4987/10000 [08:28<09:08,  9.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4674/12392 [00:00<00:00, 46734\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3223\u001b[A\n",
      "Simulating N-1 Contingencies:  50%|███▉    | 4990/10000 [08:28<09:58,  8.37it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4982/12392 [00:00<00:00, 49812\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5032\u001b[A\n",
      "Simulating N-1 Contingencies:  50%|███▉    | 4993/10000 [08:29<09:27,  8.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4995/12392 [00:00<00:00, 49943\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3301\u001b[A\n",
      "Simulating N-1 Contingencies:  50%|███▉    | 4994/10000 [08:29<12:20,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4836/12392 [00:00<00:00, 48357\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4910\u001b[A\n",
      "Simulating N-1 Contingencies:  50%|███▉    | 4997/10000 [08:29<10:59,  7.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4847/12392 [00:00<00:00, 48463\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3159\u001b[A\n",
      "Simulating N-1 Contingencies:  50%|███▉    | 4999/10000 [08:30<12:41,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  36%|▎| 4516/12392 [00:00<00:00, 45152\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4683\u001b[A\n",
      "Simulating N-1 Contingencies:  50%|████    | 5003/10000 [08:30<10:15,  8.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4952/12392 [00:00<00:00, 49513\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4966\u001b[A\n",
      "Simulating N-1 Contingencies:  50%|████    | 5007/10000 [08:30<09:54,  8.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4950/12392 [00:00<00:00, 49494\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5006\u001b[A\n",
      "Simulating N-1 Contingencies:  50%|████    | 5012/10000 [08:31<07:43, 10.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4972/12392 [00:00<00:00, 49715\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3229\u001b[A\n",
      "Simulating N-1 Contingencies:  50%|████    | 5015/10000 [08:31<08:57,  9.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4934/12392 [00:00<00:00, 49330\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4989\u001b[A\n",
      "Simulating N-1 Contingencies:  50%|████    | 5016/10000 [08:32<10:37,  7.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4981/12392 [00:00<00:00, 49808\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4997\u001b[A\n",
      "Simulating N-1 Contingencies:  50%|████    | 5018/10000 [08:32<10:55,  7.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  23%|▏| 2876/12392 [00:00<00:00, 15480\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3291\u001b[A\n",
      "Simulating N-1 Contingencies:  50%|████    | 5020/10000 [08:32<12:35,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4845/12392 [00:00<00:00, 48439\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4922\u001b[A\n",
      "Simulating N-1 Contingencies:  50%|████    | 5021/10000 [08:32<14:15,  5.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4615/12392 [00:00<00:00, 20690\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3274\u001b[A\n",
      "Simulating N-1 Contingencies:  50%|████    | 5023/10000 [08:33<15:12,  5.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4863/12392 [00:00<00:00, 48624\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4949\u001b[A\n",
      "Simulating N-1 Contingencies:  50%|████    | 5026/10000 [08:33<12:24,  6.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4888/12392 [00:00<00:00, 48876\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3269\u001b[A\n",
      "Simulating N-1 Contingencies:  50%|████    | 5028/10000 [08:34<13:45,  6.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4964/12392 [00:00<00:00, 49629\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4990\u001b[A\n",
      "Simulating N-1 Contingencies:  50%|████    | 5035/10000 [08:34<08:07, 10.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4936/12392 [00:00<00:00, 49356\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3229\u001b[A\n",
      "Simulating N-1 Contingencies:  50%|████    | 5037/10000 [08:34<09:53,  8.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4972/12392 [00:00<00:00, 49712\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4976\u001b[A\n",
      "Simulating N-1 Contingencies:  50%|████    | 5042/10000 [08:35<08:01, 10.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4678/12392 [00:00<00:00, 46772\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3163\u001b[A\n",
      "Simulating N-1 Contingencies:  50%|████    | 5049/10000 [08:35<07:00, 11.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4982/12392 [00:00<00:00, 49811\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5004\u001b[A\n",
      "Simulating N-1 Contingencies:  51%|████    | 5060/10000 [08:36<04:22, 18.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4940/12392 [00:00<00:00, 49399\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3221\u001b[A\n",
      "Simulating N-1 Contingencies:  51%|████    | 5066/10000 [08:36<05:01, 16.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4995/12392 [00:00<00:00, 49943\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5023\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4931/12392 [00:00<00:00, 49304\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3238\u001b[A\n",
      "Simulating N-1 Contingencies:  51%|████    | 5069/10000 [08:37<07:37, 10.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4980/12392 [00:00<00:00, 49794\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5022\u001b[A\n",
      "Simulating N-1 Contingencies:  51%|████    | 5071/10000 [08:37<08:13,  9.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 5000/12392 [00:00<00:00, 49994\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5039\u001b[A\n",
      "Simulating N-1 Contingencies:  51%|████    | 5076/10000 [08:37<07:52, 10.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4634/12392 [00:00<00:00, 46336\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4723\u001b[A\n",
      "Simulating N-1 Contingencies:  51%|████    | 5082/10000 [08:38<06:28, 12.67it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:  51%|████    | 5091/10000 [08:38<03:47, 21.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4949/12392 [00:00<00:00, 49481\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3213\u001b[A\n",
      "Simulating N-1 Contingencies:  51%|████    | 5095/10000 [08:38<05:02, 16.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4999/12392 [00:00<00:00, 49987\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5019\u001b[A\n",
      "Simulating N-1 Contingencies:  51%|████    | 5098/10000 [08:39<05:39, 14.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 5009/12392 [00:00<00:00, 50085\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5022\u001b[A\n",
      "Simulating N-1 Contingencies:  51%|████    | 5103/10000 [08:39<06:09, 13.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4988/12392 [00:00<00:00, 49871\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5012\u001b[A\n",
      "Simulating N-1 Contingencies:  51%|████    | 5107/10000 [08:39<06:12, 13.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4793/12392 [00:00<00:00, 47923\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3178\u001b[A\n",
      "Simulating N-1 Contingencies:  51%|████    | 5111/10000 [08:40<07:10, 11.35it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4872/12392 [00:00<00:00, 48717\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4878\u001b[A\n",
      "Simulating N-1 Contingencies:  51%|████    | 5116/10000 [08:40<06:30, 12.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4857/12392 [00:00<00:00, 48569\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4923\u001b[A\n",
      "Simulating N-1 Contingencies:  51%|████    | 5118/10000 [08:41<07:24, 10.98it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  25%|▎| 3135/12392 [00:00<00:00, 15522\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3190\u001b[A\n",
      "Simulating N-1 Contingencies:  51%|████    | 5122/10000 [08:41<08:00, 10.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4909/12392 [00:00<00:00, 49087\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4980\u001b[A\n",
      "Simulating N-1 Contingencies:  51%|████    | 5124/10000 [08:41<08:42,  9.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  23%|▏| 2874/12392 [00:00<00:00, 15250\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3266\u001b[A\n",
      "Simulating N-1 Contingencies:  51%|████    | 5130/10000 [08:42<07:36, 10.67it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4964/12392 [00:00<00:00, 49573\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5023\u001b[A\n",
      "Simulating N-1 Contingencies:  51%|████    | 5132/10000 [08:42<08:17,  9.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  23%|▏| 2876/12392 [00:00<00:00, 15505\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3297\u001b[A\n",
      "Simulating N-1 Contingencies:  51%|████    | 5141/10000 [08:43<06:14, 12.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4992/12392 [00:00<00:00, 49910\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5027\u001b[A\n",
      "Simulating N-1 Contingencies:  51%|████    | 5145/10000 [08:43<06:14, 12.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  26%|▎| 3224/12392 [00:00<00:00, 16580\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3274\u001b[A\n",
      "Simulating N-1 Contingencies:  51%|████    | 5148/10000 [08:43<07:21, 10.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4941/12392 [00:00<00:00, 49405\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4998\u001b[A\n",
      "Simulating N-1 Contingencies:  52%|████    | 5153/10000 [08:44<06:37, 12.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  31%|▎| 3831/12392 [00:00<00:00, 17845\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3170\u001b[A\n",
      "Simulating N-1 Contingencies:  52%|████▏   | 5167/10000 [08:44<04:12, 19.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4709/12392 [00:00<00:00, 47084\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4918\u001b[A\n",
      "Simulating N-1 Contingencies:  52%|████▏   | 5171/10000 [08:44<04:40, 17.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  33%|▎| 4094/12392 [00:00<00:00, 19046\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3255\u001b[A\n",
      "Simulating N-1 Contingencies:  52%|████▏   | 5174/10000 [08:45<05:59, 13.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 5003/12392 [00:00<00:00, 50020\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5037\u001b[A\n",
      "Simulating N-1 Contingencies:  52%|████▏   | 5177/10000 [08:45<06:24, 12.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4876/12392 [00:00<00:00, 48751\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3251\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4927/12392 [00:00<00:00, 49268\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4997\u001b[A\n",
      "Simulating N-1 Contingencies:  52%|████▏   | 5179/10000 [08:46<09:57,  8.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4838/12392 [00:00<00:00, 48370\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3219\u001b[A\n",
      "Simulating N-1 Contingencies:  52%|████▏   | 5181/10000 [08:46<11:20,  7.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4913/12392 [00:00<00:00, 49127\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5008\u001b[A\n",
      "Simulating N-1 Contingencies:  52%|████▏   | 5194/10000 [08:47<04:55, 16.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4928/12392 [00:00<00:00, 49273\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3227\u001b[A\n",
      "Simulating N-1 Contingencies:  52%|████▏   | 5198/10000 [08:47<05:56, 13.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4670/12392 [00:00<00:00, 46698\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4859\u001b[A\n",
      "Simulating N-1 Contingencies:  52%|████▏   | 5201/10000 [08:47<06:23, 12.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4997/12392 [00:00<00:00, 49954\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3226\u001b[A\n",
      "Simulating N-1 Contingencies:  52%|████▏   | 5204/10000 [08:48<07:36, 10.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 5013/12392 [00:00<00:00, 50127\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4998\u001b[A\n",
      "Simulating N-1 Contingencies:  52%|████▏   | 5206/10000 [08:48<08:17,  9.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4955/12392 [00:00<00:00, 49540\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3237\u001b[A\n",
      "Simulating N-1 Contingencies:  52%|████▏   | 5208/10000 [08:49<10:02,  7.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4905/12392 [00:00<00:00, 49045\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4945\u001b[A\n",
      "Simulating N-1 Contingencies:  52%|████▏   | 5216/10000 [08:49<06:32, 12.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4952/12392 [00:00<00:00, 49510\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4970\u001b[A\n",
      "Simulating N-1 Contingencies:  52%|████▏   | 5223/10000 [08:49<05:50, 13.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4675/12392 [00:00<00:00, 46743\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4745\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4734/12392 [00:00<00:00, 47337\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4775\u001b[A\n",
      "Simulating N-1 Contingencies:  52%|████▏   | 5227/10000 [08:50<08:15,  9.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4873/12392 [00:00<00:00, 48727\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4930\u001b[A\n",
      "Simulating N-1 Contingencies:  52%|████▏   | 5232/10000 [08:50<06:57, 11.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4869/12392 [00:00<00:00, 48679\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3223\u001b[A\n",
      "Simulating N-1 Contingencies:  52%|████▏   | 5236/10000 [08:51<07:35, 10.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4960/12392 [00:00<00:00, 49592\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4968\u001b[A\n",
      "Simulating N-1 Contingencies:  52%|████▏   | 5239/10000 [08:51<07:40, 10.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4955/12392 [00:00<00:00, 49544\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4983\u001b[A\n",
      "Simulating N-1 Contingencies:  52%|████▏   | 5242/10000 [08:52<07:42, 10.28it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  11%| | 1310/12392 [00:00<00:01, 8615.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  51%|▌| 6319/12392 [00:00<00:00, 28706\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3261\u001b[A\n",
      "Simulating N-1 Contingencies:  52%|████▏   | 5245/10000 [08:52<08:43,  9.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4751/12392 [00:00<00:00, 47502\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4833\u001b[A\n",
      "Simulating N-1 Contingencies:  52%|████▏   | 5246/10000 [08:52<10:19,  7.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  21%|▏| 2615/12392 [00:00<00:00, 14471\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3301\u001b[A\n",
      "Simulating N-1 Contingencies:  52%|████▏   | 5247/10000 [08:53<13:22,  5.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4854/12392 [00:00<00:00, 48529\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4904\u001b[A\n",
      "Simulating N-1 Contingencies:  52%|████▏   | 5248/10000 [08:53<14:50,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  30%|▎| 3744/12392 [00:00<00:00, 18265\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3286\u001b[A\n",
      "Simulating N-1 Contingencies:  53%|████▏   | 5251/10000 [08:53<13:19,  5.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4946/12392 [00:00<00:00, 49455\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4888\u001b[A\n",
      "Simulating N-1 Contingencies:  53%|████▏   | 5252/10000 [08:54<14:46,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4756/12392 [00:00<00:00, 47552\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3122\u001b[A\n",
      "Simulating N-1 Contingencies:  53%|████▏   | 5253/10000 [08:54<18:21,  4.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4780/12392 [00:00<00:00, 47798\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4908\u001b[A\n",
      "Simulating N-1 Contingencies:  53%|████▏   | 5255/10000 [08:54<15:54,  4.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4995/12392 [00:00<00:00, 49944\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3226\u001b[A\n",
      "Simulating N-1 Contingencies:  53%|████▏   | 5256/10000 [08:55<19:13,  4.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4883/12392 [00:00<00:00, 48818\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4912\u001b[A\n",
      "Simulating N-1 Contingencies:  53%|████▏   | 5257/10000 [08:55<19:49,  3.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4907/12392 [00:00<00:00, 49063\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3232\u001b[A\n",
      "Simulating N-1 Contingencies:  53%|████▏   | 5258/10000 [08:55<22:51,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4994/12392 [00:00<00:00, 49935\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4985\u001b[A\n",
      "Simulating N-1 Contingencies:  53%|████▏   | 5262/10000 [08:56<13:07,  6.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4991/12392 [00:00<00:00, 49908\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3245\u001b[A\n",
      "Simulating N-1 Contingencies:  53%|████▏   | 5268/10000 [08:56<09:14,  8.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4948/12392 [00:00<00:00, 49478\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4974\u001b[A\n",
      "Simulating N-1 Contingencies:  53%|████▏   | 5270/10000 [08:56<09:40,  8.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4910/12392 [00:00<00:00, 49092\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4918\u001b[A\n",
      "Simulating N-1 Contingencies:  53%|████▏   | 5273/10000 [08:57<09:07,  8.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   2%| | 265/12392 [00:00<00:06, 2013.4\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4962/12392 [00:00<00:00, 25408\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3240\u001b[A\n",
      "Simulating N-1 Contingencies:  53%|████▏   | 5276/10000 [08:57<09:48,  8.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4877/12392 [00:00<00:00, 48764\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4923\u001b[A\n",
      "Simulating N-1 Contingencies:  53%|████▏   | 5279/10000 [08:58<09:13,  8.53it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4889/12392 [00:00<00:00, 48880\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4942\u001b[A\n",
      "Simulating N-1 Contingencies:  53%|████▏   | 5281/10000 [08:58<10:49,  7.26it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4794/12392 [00:00<00:00, 47933\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4833\u001b[A\n",
      "Simulating N-1 Contingencies:  53%|████▏   | 5289/10000 [08:58<07:22, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4798/12392 [00:00<00:00, 47969\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4758\u001b[A\n",
      "Simulating N-1 Contingencies:  53%|████▏   | 5292/10000 [08:59<07:35, 10.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4965/12392 [00:00<00:00, 49648\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3220\u001b[A\n",
      "Simulating N-1 Contingencies:  53%|████▏   | 5296/10000 [08:59<07:59,  9.81it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:  53%|████▏   | 5305/10000 [08:59<04:14, 18.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4924/12392 [00:00<00:00, 49237\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4953\u001b[A\n",
      "Simulating N-1 Contingencies:  53%|████▏   | 5309/10000 [09:00<04:42, 16.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4833/12392 [00:00<00:00, 48318\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4797\u001b[A\n",
      "Simulating N-1 Contingencies:  53%|████▏   | 5312/10000 [09:00<05:24, 14.44it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   5%| | 612/12392 [00:00<00:02, 4254.4\u001b[A\n",
      "Converting scenarios to PyG Data objects:  44%|▍| 5456/12392 [00:00<00:00, 26269\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3224\u001b[A\n",
      "Simulating N-1 Contingencies:  53%|████▎   | 5316/10000 [09:00<06:22, 12.25it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4962/12392 [00:00<00:00, 49609\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4973\u001b[A\n",
      "Simulating N-1 Contingencies:  53%|████▎   | 5320/10000 [09:01<06:16, 12.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   9%| | 1134/12392 [00:00<00:01, 7447.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  46%|▍| 5710/12392 [00:00<00:00, 25991\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3167\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4891/12392 [00:00<00:00, 48902\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4916\u001b[A\n",
      "Simulating N-1 Contingencies:  53%|████▎   | 5322/10000 [09:01<09:52,  7.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  15%|▏| 1832/12392 [00:00<00:00, 10608\u001b[A\n",
      "Converting scenarios to PyG Data objects:  52%|▌| 6501/12392 [00:00<00:00, 26941\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3106\u001b[A\n",
      "Simulating N-1 Contingencies:  53%|████▎   | 5324/10000 [09:02<11:17,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4600/12392 [00:00<00:00, 45994\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4726\u001b[A\n",
      "Simulating N-1 Contingencies:  53%|████▎   | 5342/10000 [09:02<03:28, 22.39it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:  53%|████▎   | 5347/10000 [09:03<03:28, 22.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4794/12392 [00:00<00:00, 47936\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4877\u001b[A\n",
      "Simulating N-1 Contingencies:  54%|████▎   | 5353/10000 [09:03<03:48, 20.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4666/12392 [00:00<00:00, 46654\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3006\u001b[A\n",
      "Simulating N-1 Contingencies:  54%|████▎   | 5357/10000 [09:03<05:03, 15.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4926/12392 [00:00<00:00, 49250\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4932\u001b[A\n",
      "Simulating N-1 Contingencies:  54%|████▎   | 5361/10000 [09:04<05:18, 14.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4681/12392 [00:00<00:00, 46806\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3138\u001b[A\n",
      "Simulating N-1 Contingencies:  54%|████▎   | 5367/10000 [09:04<05:38, 13.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4923/12392 [00:00<00:00, 49224\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4909\u001b[A\n",
      "Simulating N-1 Contingencies:  54%|████▎   | 5369/10000 [09:04<06:25, 12.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4891/12392 [00:00<00:00, 48905\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4938\u001b[A\n",
      "Simulating N-1 Contingencies:  54%|████▎   | 5374/10000 [09:05<05:57, 12.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  18%|▏| 2180/12392 [00:00<00:00, 12478\u001b[A\n",
      "Converting scenarios to PyG Data objects:  58%|▌| 7156/12392 [00:00<00:00, 29249\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3260\u001b[A\n",
      "Simulating N-1 Contingencies:  54%|████▎   | 5376/10000 [09:05<07:35, 10.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4950/12392 [00:00<00:00, 49493\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5008\u001b[A\n",
      "Simulating N-1 Contingencies:  54%|████▎   | 5381/10000 [09:06<06:37, 11.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  15%|▏| 1919/12392 [00:00<00:00, 11728\u001b[A\n",
      "Converting scenarios to PyG Data objects:  55%|▌| 6867/12392 [00:00<00:00, 29323\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3302\u001b[A\n",
      "Simulating N-1 Contingencies:  54%|████▎   | 5384/10000 [09:06<07:38, 10.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4953/12392 [00:00<00:00, 49527\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4976\u001b[A\n",
      "Simulating N-1 Contingencies:  54%|████▎   | 5387/10000 [09:06<07:37, 10.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  20%|▏| 2441/12392 [00:00<00:00, 13826\u001b[A\n",
      "Converting scenarios to PyG Data objects:  60%|▌| 7386/12392 [00:00<00:00, 29757\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3280\u001b[A\n",
      "Simulating N-1 Contingencies:  54%|████▎   | 5389/10000 [09:07<09:15,  8.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4964/12392 [00:00<00:00, 49629\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4998\u001b[A\n",
      "Simulating N-1 Contingencies:  54%|████▎   | 5391/10000 [09:07<09:37,  7.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  22%|▏| 2787/12392 [00:00<00:00, 15249\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3312\u001b[A\n",
      "Simulating N-1 Contingencies:  54%|████▎   | 5396/10000 [09:07<08:25,  9.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4979/12392 [00:00<00:00, 49785\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5020\u001b[A\n",
      "Simulating N-1 Contingencies:  54%|████▎   | 5399/10000 [09:08<08:11,  9.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  32%|▎| 3920/12392 [00:00<00:00, 16868\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3044\u001b[A\n",
      "Simulating N-1 Contingencies:  54%|████▎   | 5400/10000 [09:08<11:03,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4700/12392 [00:00<00:00, 46991\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4781\u001b[A\n",
      "Simulating N-1 Contingencies:  54%|████▎   | 5402/10000 [09:08<11:09,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4870/12392 [00:00<00:00, 48689\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3205\u001b[A\n",
      "Simulating N-1 Contingencies:  54%|████▎   | 5403/10000 [09:09<14:12,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4908/12392 [00:00<00:00, 49074\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4887\u001b[A\n",
      "Simulating N-1 Contingencies:  54%|████▎   | 5404/10000 [09:09<15:29,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4830/12392 [00:00<00:00, 48292\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3173\u001b[A\n",
      "Simulating N-1 Contingencies:  54%|████▎   | 5408/10000 [09:10<12:05,  6.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4797/12392 [00:00<00:00, 47959\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4925\u001b[A\n",
      "Simulating N-1 Contingencies:  54%|████▎   | 5409/10000 [09:10<13:29,  5.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4969/12392 [00:00<00:00, 49681\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3239\u001b[A\n",
      "Simulating N-1 Contingencies:  54%|████▎   | 5412/10000 [09:10<12:29,  6.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 5009/12392 [00:00<00:00, 50084\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5006\u001b[A\n",
      "Simulating N-1 Contingencies:  54%|████▎   | 5415/10000 [09:11<10:43,  7.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4677/12392 [00:00<00:00, 46767\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3139\u001b[A\n",
      "Simulating N-1 Contingencies:  54%|████▎   | 5416/10000 [09:11<13:51,  5.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 5014/12392 [00:00<00:00, 50130\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4907\u001b[A\n",
      "Simulating N-1 Contingencies:  54%|████▎   | 5418/10000 [09:11<13:02,  5.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4758/12392 [00:00<00:00, 47573\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4818\u001b[A\n",
      "Simulating N-1 Contingencies:  54%|████▎   | 5420/10000 [09:12<12:32,  6.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  10%| | 1223/12392 [00:00<00:01, 7696.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  49%|▍| 6095/12392 [00:00<00:00, 27115\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3224\u001b[A\n",
      "Simulating N-1 Contingencies:  54%|████▎   | 5422/10000 [09:12<13:36,  5.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4903/12392 [00:00<00:00, 49022\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4984\u001b[A\n",
      "Simulating N-1 Contingencies:  54%|████▎   | 5426/10000 [09:12<10:03,  7.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   9%| | 1136/12392 [00:00<00:01, 7500.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  49%|▍| 6110/12392 [00:00<00:00, 28002\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3290\u001b[A\n",
      "Simulating N-1 Contingencies:  54%|████▎   | 5428/10000 [09:13<11:27,  6.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4958/12392 [00:00<00:00, 49572\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4966\u001b[A\n",
      "Simulating N-1 Contingencies:  54%|████▎   | 5433/10000 [09:13<08:23,  9.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   7%| | 875/12392 [00:00<00:01, 6112.8\u001b[A\n",
      "Converting scenarios to PyG Data objects:  47%|▍| 5867/12392 [00:00<00:00, 27993\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3261\u001b[A\n",
      "Simulating N-1 Contingencies:  54%|████▎   | 5436/10000 [09:13<09:06,  8.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4655/12392 [00:00<00:00, 46545\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4795\u001b[A\n",
      "Simulating N-1 Contingencies:  54%|████▎   | 5438/10000 [09:14<09:35,  7.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  13%|▏| 1571/12392 [00:00<00:01, 9835.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  52%|▌| 6462/12392 [00:00<00:00, 28282\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3267\u001b[A\n",
      "Simulating N-1 Contingencies:  54%|████▎   | 5439/10000 [09:14<12:24,  6.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4989/12392 [00:00<00:00, 49882\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4980\u001b[A\n",
      "Simulating N-1 Contingencies:  54%|████▎   | 5440/10000 [09:14<13:44,  5.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  15%|▏| 1917/12392 [00:00<00:00, 11582\u001b[A\n",
      "Converting scenarios to PyG Data objects:  55%|▌| 6838/12392 [00:00<00:00, 29014\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3278\u001b[A\n",
      "Simulating N-1 Contingencies:  54%|████▎   | 5446/10000 [09:15<09:11,  8.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4984/12392 [00:00<00:00, 49832\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4950\u001b[A\n",
      "Simulating N-1 Contingencies:  55%|████▎   | 5452/10000 [09:15<06:56, 10.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  18%|▏| 2267/12392 [00:00<00:00, 13108\u001b[A\n",
      "Converting scenarios to PyG Data objects:  58%|▌| 7234/12392 [00:00<00:00, 29645\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3299\u001b[A\n",
      "Simulating N-1 Contingencies:  55%|████▎   | 5463/10000 [09:16<04:26, 17.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  41%|▍| 5036/12392 [00:00<00:00, 50350\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5052\u001b[A\n",
      "/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:  55%|████▎   | 5467/10000 [09:16<04:46, 15.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   7%| | 875/12392 [00:00<00:01, 6019.7\u001b[A\n",
      "Converting scenarios to PyG Data objects:  47%|▍| 5828/12392 [00:00<00:00, 27585\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3287\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4963/12392 [00:00<00:00, 49627\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4964\u001b[A\n",
      "Simulating N-1 Contingencies:  55%|████▍   | 5470/10000 [09:17<07:25, 10.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   6%| | 786/12392 [00:00<00:02, 5457.6\u001b[A\n",
      "Converting scenarios to PyG Data objects:  46%|▍| 5720/12392 [00:00<00:00, 27307\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3283\u001b[A\n",
      "Simulating N-1 Contingencies:  55%|████▍   | 5474/10000 [09:17<07:40,  9.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4988/12392 [00:00<00:00, 49875\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4988\u001b[A\n",
      "Simulating N-1 Contingencies:  55%|████▍   | 5483/10000 [09:18<05:29, 13.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4809/12392 [00:00<00:00, 48081\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4814\u001b[A\n",
      "Simulating N-1 Contingencies:  55%|████▍   | 5486/10000 [09:18<05:59, 12.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4787/12392 [00:00<00:00, 47866\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4850\u001b[A\n",
      "Simulating N-1 Contingencies:  55%|████▍   | 5490/10000 [09:18<06:37, 11.34it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4727/12392 [00:00<00:00, 47265\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4885\u001b[A\n",
      "Simulating N-1 Contingencies:  55%|████▍   | 5496/10000 [09:19<05:34, 13.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4968/12392 [00:00<00:00, 49673\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3200\u001b[A\n",
      "Simulating N-1 Contingencies:  55%|████▍   | 5500/10000 [09:19<06:28, 11.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  36%|▎| 4517/12392 [00:00<00:00, 45160\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4597\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4756/12392 [00:00<00:00, 47556\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4840\u001b[A\n",
      "Simulating N-1 Contingencies:  55%|████▍   | 5502/10000 [09:20<09:11,  8.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  30%|▎| 3659/12392 [00:00<00:00, 17974\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3262\u001b[A\n",
      "Simulating N-1 Contingencies:  55%|████▍   | 5504/10000 [09:20<10:30,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4858/12392 [00:00<00:00, 48577\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4939\u001b[A\n",
      "Simulating N-1 Contingencies:  55%|████▍   | 5507/10000 [09:21<09:35,  7.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  34%|▎| 4181/12392 [00:00<00:00, 18784\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3201\u001b[A\n",
      "Simulating N-1 Contingencies:  55%|████▍   | 5508/10000 [09:21<12:16,  6.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4898/12392 [00:00<00:00, 48973\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4968\u001b[A\n",
      "Simulating N-1 Contingencies:  55%|████▍   | 5518/10000 [09:21<05:09, 14.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  34%|▎| 4182/12392 [00:00<00:00, 19576\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3259\u001b[A\n",
      "Simulating N-1 Contingencies:  55%|████▍   | 5521/10000 [09:22<06:28, 11.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4904/12392 [00:00<00:00, 49031\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4957\u001b[A\n",
      "Simulating N-1 Contingencies:  55%|████▍   | 5524/10000 [09:22<06:43, 11.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4977/12392 [00:00<00:00, 49763\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3256\u001b[A\n",
      "Simulating N-1 Contingencies:  55%|████▍   | 5526/10000 [09:23<08:26,  8.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4996/12392 [00:00<00:00, 49950\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5018\u001b[A\n",
      "Simulating N-1 Contingencies:  55%|████▍   | 5528/10000 [09:23<08:54,  8.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4947/12392 [00:00<00:00, 49464\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3279\u001b[A\n",
      "Simulating N-1 Contingencies:  55%|████▍   | 5530/10000 [09:23<10:27,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4940/12392 [00:00<00:00, 49397\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4970\u001b[A\n",
      "Simulating N-1 Contingencies:  55%|████▍   | 5531/10000 [09:23<11:53,  6.26it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4958/12392 [00:00<00:00, 49572\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3272\u001b[A\n",
      "Simulating N-1 Contingencies:  55%|████▍   | 5540/10000 [09:24<06:50, 10.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4962/12392 [00:00<00:00, 49610\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4997\u001b[A\n",
      "Simulating N-1 Contingencies:  55%|████▍   | 5542/10000 [09:24<07:28,  9.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4859/12392 [00:00<00:00, 48585\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3228\u001b[A\n",
      "Simulating N-1 Contingencies:  55%|████▍   | 5543/10000 [09:25<09:57,  7.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4754/12392 [00:00<00:00, 47530\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4889\u001b[A\n",
      "Simulating N-1 Contingencies:  55%|████▍   | 5546/10000 [09:25<09:10,  8.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4925/12392 [00:00<00:00, 49244\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4952\u001b[A\n",
      "Simulating N-1 Contingencies:  56%|████▍   | 5553/10000 [09:25<06:56, 10.67it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4922/12392 [00:00<00:00, 49212\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4957\u001b[A\n",
      "Simulating N-1 Contingencies:  56%|████▍   | 5558/10000 [09:26<06:03, 12.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4836/12392 [00:00<00:00, 48350\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3211\u001b[A\n",
      "Simulating N-1 Contingencies:  56%|████▍   | 5562/10000 [09:26<06:45, 10.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4931/12392 [00:00<00:00, 49307\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4951\u001b[A\n",
      "Simulating N-1 Contingencies:  56%|████▍   | 5564/10000 [09:27<07:29,  9.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4938/12392 [00:00<00:00, 49375\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4986\u001b[A\n",
      "Simulating N-1 Contingencies:  56%|████▍   | 5567/10000 [09:27<07:28,  9.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  10%| | 1221/12392 [00:00<00:01, 8141.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  50%|▍| 6157/12392 [00:00<00:00, 28248\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3299\u001b[A\n",
      "Simulating N-1 Contingencies:  56%|████▍   | 5572/10000 [09:27<07:07, 10.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4974/12392 [00:00<00:00, 49732\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4996\u001b[A\n",
      "Simulating N-1 Contingencies:  56%|████▍   | 5574/10000 [09:28<07:46,  9.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  15%|▏| 1919/12392 [00:00<00:00, 10762\u001b[A\n",
      "Converting scenarios to PyG Data objects:  55%|▌| 6849/12392 [00:00<00:00, 27902\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3162\u001b[A\n",
      "Simulating N-1 Contingencies:  56%|████▍   | 5575/10000 [09:28<10:31,  7.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4546/12392 [00:00<00:00, 45452\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4724\u001b[A\n",
      "Simulating N-1 Contingencies:  56%|████▍   | 5576/10000 [09:28<12:05,  6.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  26%|▎| 3224/12392 [00:00<00:00, 16515\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3270\u001b[A\n",
      "Simulating N-1 Contingencies:  56%|████▍   | 5577/10000 [09:29<15:06,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4921/12392 [00:00<00:00, 49207\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4922\u001b[A\n",
      "Simulating N-1 Contingencies:  56%|████▍   | 5583/10000 [09:29<08:35,  8.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  27%|▎| 3398/12392 [00:00<00:00, 17007\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3218\u001b[A\n",
      "Simulating N-1 Contingencies:  56%|████▍   | 5586/10000 [09:29<09:12,  7.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4753/12392 [00:00<00:00, 47518\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4856\u001b[A\n",
      "Simulating N-1 Contingencies:  56%|████▍   | 5587/10000 [09:30<10:38,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  32%|▎| 3920/12392 [00:00<00:00, 18086\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3117\u001b[A\n",
      "Simulating N-1 Contingencies:  56%|████▍   | 5591/10000 [09:30<09:43,  7.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  36%|▎| 4498/12392 [00:00<00:00, 44974\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4782\u001b[A\n",
      "Simulating N-1 Contingencies:  56%|████▍   | 5601/10000 [09:31<04:44, 15.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  35%|▎| 4354/12392 [00:00<00:00, 19301\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3182\u001b[A\n",
      "Simulating N-1 Contingencies:  56%|████▍   | 5604/10000 [09:31<06:06, 11.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4929/12392 [00:00<00:00, 49283\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4932\u001b[A\n",
      "Simulating N-1 Contingencies:  56%|████▍   | 5610/10000 [09:31<05:18, 13.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4529/12392 [00:00<00:00, 20153\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3224\u001b[A\n",
      "Simulating N-1 Contingencies:  56%|████▍   | 5613/10000 [09:32<06:28, 11.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4935/12392 [00:00<00:00, 49340\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4972\u001b[A\n",
      "Simulating N-1 Contingencies:  56%|████▍   | 5615/10000 [09:32<07:10, 10.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4941/12392 [00:00<00:00, 49403\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3276\u001b[A\n",
      "Simulating N-1 Contingencies:  56%|████▍   | 5617/10000 [09:32<08:45,  8.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  41%|▍| 5032/12392 [00:00<00:00, 50316\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5042\u001b[A\n",
      "Simulating N-1 Contingencies:  56%|████▍   | 5620/10000 [09:33<08:16,  8.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4893/12392 [00:00<00:00, 48923\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3269\u001b[A\n",
      "Simulating N-1 Contingencies:  56%|████▍   | 5623/10000 [09:33<08:54,  8.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4868/12392 [00:00<00:00, 48673\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4943\u001b[A\n",
      "Simulating N-1 Contingencies:  56%|████▌   | 5630/10000 [09:34<06:15, 11.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4899/12392 [00:00<00:00, 48987\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3232\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4964/12392 [00:00<00:00, 49636\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4994\u001b[A\n",
      "Simulating N-1 Contingencies:  56%|████▌   | 5632/10000 [09:34<09:23,  7.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4967/12392 [00:00<00:00, 49663\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5011\u001b[A\n",
      "Simulating N-1 Contingencies:  56%|████▌   | 5635/10000 [09:35<09:19,  7.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4847/12392 [00:00<00:00, 48464\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4915\u001b[A\n",
      "Simulating N-1 Contingencies:  56%|████▌   | 5636/10000 [09:35<10:53,  6.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4885/12392 [00:00<00:00, 48838\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4930\u001b[A\n",
      "Simulating N-1 Contingencies:  56%|████▌   | 5638/10000 [09:35<10:45,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4598/12392 [00:00<00:00, 45974\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4759\u001b[A\n",
      "Simulating N-1 Contingencies:  56%|████▌   | 5639/10000 [09:36<14:10,  5.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4928/12392 [00:00<00:00, 49277\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4930\u001b[A\n",
      "Simulating N-1 Contingencies:  56%|████▌   | 5642/10000 [09:36<11:50,  6.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4928/12392 [00:00<00:00, 49271\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4920\u001b[A\n",
      "Simulating N-1 Contingencies:  56%|████▌   | 5644/10000 [09:36<11:23,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4957/12392 [00:00<00:00, 49564\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4982\u001b[A\n",
      "Simulating N-1 Contingencies:  56%|████▌   | 5645/10000 [09:37<13:03,  5.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4979/12392 [00:00<00:00, 49782\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5024\u001b[A\n",
      "Simulating N-1 Contingencies:  56%|████▌   | 5646/10000 [09:37<16:26,  4.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4984/12392 [00:00<00:00, 49834\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5024\u001b[A\n",
      "Simulating N-1 Contingencies:  56%|████▌   | 5647/10000 [09:37<17:11,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   7%| | 873/12392 [00:00<00:01, 6067.5\u001b[A\n",
      "Converting scenarios to PyG Data objects:  47%|▍| 5778/12392 [00:00<00:00, 27481\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3284\u001b[A\n",
      "Simulating N-1 Contingencies:  56%|████▌   | 5648/10000 [09:38<20:13,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4877/12392 [00:00<00:00, 48757\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4983\u001b[A\n",
      "Simulating N-1 Contingencies:  57%|████▌   | 5651/10000 [09:38<13:26,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   8%| | 960/12392 [00:00<00:01, 6539.0\u001b[A\n",
      "Converting scenarios to PyG Data objects:  46%|▍| 5728/12392 [00:00<00:00, 26826\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3243\u001b[A\n",
      "Simulating N-1 Contingencies:  57%|████▌   | 5652/10000 [09:38<16:37,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4729/12392 [00:00<00:00, 47287\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4910\u001b[A\n",
      "Simulating N-1 Contingencies:  57%|████▌   | 5655/10000 [09:39<12:19,  5.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  12%| | 1484/12392 [00:00<00:01, 9340.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  52%|▌| 6455/12392 [00:00<00:00, 28453\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3275\u001b[A\n",
      "Simulating N-1 Contingencies:  57%|████▌   | 5657/10000 [09:39<13:08,  5.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4991/12392 [00:00<00:00, 49901\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5018\u001b[A\n",
      "Simulating N-1 Contingencies:  57%|████▌   | 5658/10000 [09:39<14:18,  5.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   8%| | 960/12392 [00:00<00:01, 6571.1\u001b[A\n",
      "Converting scenarios to PyG Data objects:  47%|▍| 5814/12392 [00:00<00:00, 27317\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3271\u001b[A\n",
      "Simulating N-1 Contingencies:  57%|████▌   | 5662/10000 [09:40<11:05,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4963/12392 [00:00<00:00, 49610\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4964\u001b[A\n",
      "Simulating N-1 Contingencies:  57%|████▌   | 5664/10000 [09:40<10:54,  6.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   8%| | 1049/12392 [00:00<00:01, 7122.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  48%|▍| 5995/12392 [00:00<00:00, 27966\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3267\u001b[A\n",
      "Simulating N-1 Contingencies:  57%|████▌   | 5666/10000 [09:41<12:06,  5.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4779/12392 [00:00<00:00, 47782\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4779\u001b[A\n",
      "Simulating N-1 Contingencies:  57%|████▌   | 5667/10000 [09:41<13:30,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   6%| | 786/12392 [00:00<00:02, 4510.3\u001b[A\n",
      "Converting scenarios to PyG Data objects:  44%|▍| 5508/12392 [00:00<00:00, 23747\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 2989\u001b[A\n",
      "Simulating N-1 Contingencies:  57%|████▌   | 5674/10000 [09:41<08:25,  8.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  33%|▎| 4059/12392 [00:00<00:00, 40584\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4240\u001b[A\n",
      "Simulating N-1 Contingencies:  57%|████▌   | 5681/10000 [09:42<06:24, 11.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   4%| | 525/12392 [00:00<00:03, 3276.7\u001b[A\n",
      "Converting scenarios to PyG Data objects:  41%|▍| 5046/12392 [00:00<00:00, 23038\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3022\u001b[A\n",
      "Simulating N-1 Contingencies:  57%|████▌   | 5683/10000 [09:42<07:59,  9.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4732/12392 [00:00<00:00, 47311\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4486\u001b[A\n",
      "Simulating N-1 Contingencies:  57%|████▌   | 5689/10000 [09:43<06:47, 10.58it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4933/12392 [00:00<00:00, 49322\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4908\u001b[A\n",
      "Simulating N-1 Contingencies:  57%|████▌   | 5695/10000 [09:43<05:37, 12.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  34%|▎| 4155/12392 [00:00<00:00, 41544\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 2988\u001b[A\n",
      "Simulating N-1 Contingencies:  57%|████▌   | 5697/10000 [09:44<07:24,  9.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4636/12392 [00:00<00:00, 46350\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4481\u001b[A\n",
      "Simulating N-1 Contingencies:  57%|████▌   | 5699/10000 [09:44<08:09,  8.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4880/12392 [00:00<00:00, 48788\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4943\u001b[A\n",
      "Simulating N-1 Contingencies:  57%|████▌   | 5701/10000 [09:44<08:37,  8.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  11%| | 1395/12392 [00:00<00:01, 9031.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  52%|▌| 6403/12392 [00:00<00:00, 28754\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3314\u001b[A\n",
      "Simulating N-1 Contingencies:  57%|████▌   | 5705/10000 [09:45<08:18,  8.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4917/12392 [00:00<00:00, 49164\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4967\u001b[A\n",
      "Simulating N-1 Contingencies:  57%|████▌   | 5707/10000 [09:45<08:43,  8.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  11%| | 1308/12392 [00:00<00:01, 8629.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  51%|▌| 6303/12392 [00:00<00:00, 28675\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3314\u001b[A\n",
      "Simulating N-1 Contingencies:  57%|████▌   | 5711/10000 [09:45<08:21,  8.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4952/12392 [00:00<00:00, 49510\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4983\u001b[A\n",
      "Simulating N-1 Contingencies:  57%|████▌   | 5716/10000 [09:46<06:49, 10.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  12%| | 1482/12392 [00:00<00:01, 9342.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  51%|▌| 6315/12392 [00:00<00:00, 27814\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3239\u001b[A\n",
      "Simulating N-1 Contingencies:  57%|████▌   | 5720/10000 [09:46<07:10,  9.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4884/12392 [00:00<00:00, 48830\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4936\u001b[A\n",
      "Simulating N-1 Contingencies:  57%|████▌   | 5726/10000 [09:46<05:53, 12.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  10%| | 1223/12392 [00:00<00:01, 7983.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  50%|▍| 6159/12392 [00:00<00:00, 27949\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3271\u001b[A\n",
      "Simulating N-1 Contingencies:  57%|████▌   | 5728/10000 [09:47<07:19,  9.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4893/12392 [00:00<00:00, 48927\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4941\u001b[A\n",
      "Simulating N-1 Contingencies:  57%|████▌   | 5730/10000 [09:47<07:52,  9.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   9%| | 1134/12392 [00:00<00:01, 7571.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  48%|▍| 5966/12392 [00:00<00:00, 27463\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3277\u001b[A\n",
      "Simulating N-1 Contingencies:  57%|████▌   | 5734/10000 [09:48<07:51,  9.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4798/12392 [00:00<00:00, 47976\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4878\u001b[A\n",
      "Simulating N-1 Contingencies:  57%|████▌   | 5735/10000 [09:48<09:10,  7.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  11%| | 1308/12392 [00:00<00:01, 8231.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  48%|▍| 6007/12392 [00:00<00:00, 26579\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3202\u001b[A\n",
      "Simulating N-1 Contingencies:  57%|████▌   | 5743/10000 [09:48<06:30, 10.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4875/12392 [00:00<00:00, 48739\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4934\u001b[A\n",
      "Simulating N-1 Contingencies:  57%|████▌   | 5745/10000 [09:49<07:07,  9.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  16%|▏| 2006/12392 [00:00<00:00, 11998\u001b[A\n",
      "Converting scenarios to PyG Data objects:  56%|▌| 6981/12392 [00:00<00:00, 29392\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3291\u001b[A\n",
      "Simulating N-1 Contingencies:  57%|████▌   | 5746/10000 [09:49<09:23,  7.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4972/12392 [00:00<00:00, 49717\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5008\u001b[A\n",
      "Simulating N-1 Contingencies:  57%|████▌   | 5750/10000 [09:49<07:54,  8.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  24%|▏| 2963/12392 [00:00<00:00, 15928\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3307\u001b[A\n",
      "Simulating N-1 Contingencies:  58%|████▌   | 5752/10000 [09:50<09:18,  7.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4929/12392 [00:00<00:00, 49287\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4966\u001b[A\n",
      "Simulating N-1 Contingencies:  58%|████▌   | 5753/10000 [09:50<10:37,  6.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4701/12392 [00:00<00:00, 21252\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3300\u001b[A\n",
      "Simulating N-1 Contingencies:  58%|████▌   | 5755/10000 [09:50<11:43,  6.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4860/12392 [00:00<00:00, 48595\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4840\u001b[A\n",
      "Simulating N-1 Contingencies:  58%|████▌   | 5756/10000 [09:51<13:03,  5.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4998/12392 [00:00<00:00, 49970\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3278\u001b[A\n",
      "Simulating N-1 Contingencies:  58%|████▌   | 5758/10000 [09:51<13:34,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4959/12392 [00:00<00:00, 49581\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4963\u001b[A\n",
      "Simulating N-1 Contingencies:  58%|████▌   | 5760/10000 [09:51<12:29,  5.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4779/12392 [00:00<00:00, 47783\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3178\u001b[A\n",
      "Simulating N-1 Contingencies:  58%|████▌   | 5761/10000 [09:52<15:35,  4.53it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4751/12392 [00:00<00:00, 47503\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4746\u001b[A\n",
      "Simulating N-1 Contingencies:  58%|████▌   | 5766/10000 [09:52<09:27,  7.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4942/12392 [00:00<00:00, 49418\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3256\u001b[A\n",
      "Simulating N-1 Contingencies:  58%|████▌   | 5768/10000 [09:53<10:45,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4946/12392 [00:00<00:00, 49456\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4827\u001b[A\n",
      "Simulating N-1 Contingencies:  58%|████▌   | 5777/10000 [09:53<05:02, 13.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4918/12392 [00:00<00:00, 49174\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4927\u001b[A\n",
      "Simulating N-1 Contingencies:  58%|████▋   | 5784/10000 [09:53<04:49, 14.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4879/12392 [00:00<00:00, 48787\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4975\u001b[A\n",
      "Simulating N-1 Contingencies:  58%|████▋   | 5793/10000 [09:54<03:48, 18.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4971/12392 [00:00<00:00, 49701\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3226\u001b[A\n",
      "Simulating N-1 Contingencies:  58%|████▋   | 5796/10000 [09:54<05:03, 13.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4806/12392 [00:00<00:00, 48050\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4889\u001b[A\n",
      "Simulating N-1 Contingencies:  58%|████▋   | 5798/10000 [09:55<05:52, 11.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4950/12392 [00:00<00:00, 49499\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4994\u001b[A\n",
      "Simulating N-1 Contingencies:  58%|████▋   | 5803/10000 [09:55<05:22, 13.03it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:  58%|████▋   | 5812/10000 [09:55<03:39, 19.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4926/12392 [00:00<00:00, 49259\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4982\u001b[A\n",
      "Simulating N-1 Contingencies:  58%|████▋   | 5815/10000 [09:55<04:15, 16.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4927/12392 [00:00<00:00, 49261\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4954\u001b[A\n",
      "Simulating N-1 Contingencies:  58%|████▋   | 5821/10000 [09:56<04:40, 14.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4931/12392 [00:00<00:00, 49308\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4957\u001b[A\n",
      "/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:  58%|████▋   | 5823/10000 [09:56<05:38, 12.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4922/12392 [00:00<00:00, 49214\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3188\u001b[A\n",
      "Simulating N-1 Contingencies:  58%|████▋   | 5827/10000 [09:57<06:23, 10.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4711/12392 [00:00<00:00, 47100\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4824\u001b[A\n",
      "Simulating N-1 Contingencies:  58%|████▋   | 5839/10000 [09:57<03:34, 19.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4834/12392 [00:00<00:00, 48332\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4884\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  19%|▏| 2353/12392 [00:00<00:00, 12563\u001b[A\n",
      "Converting scenarios to PyG Data objects:  59%|▌| 7257/12392 [00:00<00:00, 28346\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3099\u001b[A\n",
      "Simulating N-1 Contingencies:  58%|████▋   | 5843/10000 [09:58<05:53, 11.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4838/12392 [00:00<00:00, 48337\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4887\u001b[A\n",
      "Simulating N-1 Contingencies:  58%|████▋   | 5847/10000 [09:58<05:47, 11.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  22%|▏| 2702/12392 [00:00<00:00, 12803\u001b[A\n",
      "Converting scenarios to PyG Data objects:  60%|▌| 7472/12392 [00:00<00:00, 26889\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 2990\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4762/12392 [00:00<00:00, 47610\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4827\u001b[A\n",
      "Simulating N-1 Contingencies:  58%|████▋   | 5850/10000 [09:59<08:16,  8.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  26%|▎| 3222/12392 [00:00<00:00, 15683\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3115\u001b[A\n",
      "Simulating N-1 Contingencies:  59%|████▋   | 5853/10000 [09:59<08:47,  7.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4761/12392 [00:00<00:00, 47604\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4051\u001b[A\n",
      "Simulating N-1 Contingencies:  59%|████▋   | 5855/10000 [10:00<09:27,  7.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4852/12392 [00:00<00:00, 48517\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 2972\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4711/12392 [00:00<00:00, 47103\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4790\u001b[A\n",
      "Simulating N-1 Contingencies:  59%|████▋   | 5857/10000 [10:00<12:46,  5.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4657/12392 [00:00<00:00, 46566\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3005\u001b[A\n",
      "Simulating N-1 Contingencies:  59%|████▋   | 5859/10000 [10:01<13:25,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4746/12392 [00:00<00:00, 47457\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4812\u001b[A\n",
      "Simulating N-1 Contingencies:  59%|████▋   | 5860/10000 [10:01<14:18,  4.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4777/12392 [00:00<00:00, 47765\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3152\u001b[A\n",
      "Simulating N-1 Contingencies:  59%|████▋   | 5861/10000 [10:01<16:47,  4.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4860/12392 [00:00<00:00, 48591\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4879\u001b[A\n",
      "Simulating N-1 Contingencies:  59%|████▋   | 5863/10000 [10:02<14:36,  4.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4810/12392 [00:00<00:00, 48098\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3089\u001b[A\n",
      "Simulating N-1 Contingencies:  59%|████▋   | 5872/10000 [10:02<06:08, 11.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4746/12392 [00:00<00:00, 47453\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4818\u001b[A\n",
      "Simulating N-1 Contingencies:  59%|████▋   | 5875/10000 [10:03<06:24, 10.74it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:  59%|████▋   | 5883/10000 [10:03<03:37, 18.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  36%|▎| 4494/12392 [00:00<00:00, 44935\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4709\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4628/12392 [00:00<00:00, 46272\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4410\u001b[A\n",
      "Simulating N-1 Contingencies:  59%|████▋   | 5887/10000 [10:03<06:06, 11.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4538/12392 [00:00<00:00, 45378\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4707\u001b[A\n",
      "Simulating N-1 Contingencies:  59%|████▋   | 5890/10000 [10:04<07:06,  9.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4726/12392 [00:00<00:00, 47253\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4781\u001b[A\n",
      "Simulating N-1 Contingencies:  59%|████▋   | 5893/10000 [10:04<07:07,  9.61it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4614/12392 [00:00<00:00, 46135\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3054\u001b[A\n",
      "Simulating N-1 Contingencies:  59%|████▋   | 5900/10000 [10:05<06:13, 10.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4654/12392 [00:00<00:00, 46527\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4724\u001b[A\n",
      "/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:  59%|████▋   | 5902/10000 [10:05<06:50,  9.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4900/12392 [00:00<00:00, 48994\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4883\u001b[A\n",
      "Simulating N-1 Contingencies:  59%|████▋   | 5904/10000 [10:05<07:23,  9.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  18%|▏| 2178/12392 [00:00<00:00, 12170\u001b[A\n",
      "Converting scenarios to PyG Data objects:  55%|▌| 6871/12392 [00:00<00:00, 27599\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3146\u001b[A\n",
      "Simulating N-1 Contingencies:  59%|████▋   | 5907/10000 [10:06<08:08,  8.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4882/12392 [00:00<00:00, 48812\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4956\u001b[A\n",
      "Simulating N-1 Contingencies:  59%|████▋   | 5912/10000 [10:06<06:38, 10.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  20%|▏| 2528/12392 [00:00<00:00, 12620\u001b[A\n",
      "Converting scenarios to PyG Data objects:  59%|▌| 7278/12392 [00:00<00:00, 27138\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3045\u001b[A\n",
      "Simulating N-1 Contingencies:  59%|████▋   | 5914/10000 [10:07<08:13,  8.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4918/12392 [00:00<00:00, 49170\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4923\u001b[A\n",
      "Simulating N-1 Contingencies:  59%|████▋   | 5918/10000 [10:07<07:13,  9.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  28%|▎| 3485/12392 [00:00<00:00, 17225\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3260\u001b[A\n",
      "Simulating N-1 Contingencies:  59%|████▋   | 5920/10000 [10:07<08:36,  7.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4972/12392 [00:00<00:00, 49711\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5014\u001b[A\n",
      "Simulating N-1 Contingencies:  59%|████▋   | 5921/10000 [10:08<09:49,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4790/12392 [00:00<00:00, 21122\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3278\u001b[A\n",
      "Simulating N-1 Contingencies:  59%|████▋   | 5922/10000 [10:08<12:27,  5.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 5012/12392 [00:00<00:00, 50108\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5016\u001b[A\n",
      "Simulating N-1 Contingencies:  59%|████▋   | 5925/10000 [10:08<10:12,  6.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4789/12392 [00:00<00:00, 47887\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3118\u001b[A\n",
      "Simulating N-1 Contingencies:  59%|████▋   | 5927/10000 [10:09<11:28,  5.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4801/12392 [00:00<00:00, 47998\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4828\u001b[A\n",
      "Simulating N-1 Contingencies:  59%|████▋   | 5928/10000 [10:09<12:43,  5.33it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4796/12392 [00:00<00:00, 47953\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 2996\u001b[A\n",
      "Simulating N-1 Contingencies:  59%|████▋   | 5932/10000 [10:09<10:30,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4636/12392 [00:00<00:00, 46351\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4767\u001b[A\n",
      "Simulating N-1 Contingencies:  59%|████▋   | 5933/10000 [10:10<11:49,  5.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4708/12392 [00:00<00:00, 47078\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3030\u001b[A\n",
      "Simulating N-1 Contingencies:  59%|████▊   | 5939/10000 [10:10<08:23,  8.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4720/12392 [00:00<00:00, 47191\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4795\u001b[A\n",
      "Simulating N-1 Contingencies:  59%|████▊   | 5940/10000 [10:11<09:40,  7.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4736/12392 [00:00<00:00, 47357\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3069\u001b[A\n",
      "Simulating N-1 Contingencies:  59%|████▊   | 5948/10000 [10:11<06:36, 10.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4771/12392 [00:00<00:00, 47702\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4833\u001b[A\n",
      "Simulating N-1 Contingencies:  60%|████▊   | 5950/10000 [10:11<07:11,  9.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4848/12392 [00:00<00:00, 48476\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3077\u001b[A\n",
      "Simulating N-1 Contingencies:  60%|████▊   | 5951/10000 [10:12<09:32,  7.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4791/12392 [00:00<00:00, 47900\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4847\u001b[A\n",
      "Simulating N-1 Contingencies:  60%|████▊   | 5955/10000 [10:12<07:57,  8.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4780/12392 [00:00<00:00, 47793\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4909\u001b[A\n",
      "Simulating N-1 Contingencies:  60%|████▊   | 5956/10000 [10:12<09:14,  7.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  24%|▏| 2963/12392 [00:00<00:00, 15131\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3167\u001b[A\n",
      "Simulating N-1 Contingencies:  60%|████▊   | 5957/10000 [10:13<12:00,  5.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4811/12392 [00:00<00:00, 48106\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4870\u001b[A\n",
      "Simulating N-1 Contingencies:  60%|████▊   | 5959/10000 [10:13<11:22,  5.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4703/12392 [00:00<00:00, 20531\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3232\u001b[A\n",
      "Simulating N-1 Contingencies:  60%|████▊   | 5960/10000 [10:14<14:10,  4.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4980/12392 [00:00<00:00, 49793\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5017\u001b[A\n",
      "Simulating N-1 Contingencies:  60%|████▊   | 5962/10000 [10:14<12:37,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4983/12392 [00:00<00:00, 49827\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3287\u001b[A\n",
      "Simulating N-1 Contingencies:  60%|████▊   | 5963/10000 [10:14<15:22,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4882/12392 [00:00<00:00, 48809\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4939\u001b[A\n",
      "Simulating N-1 Contingencies:  60%|████▊   | 5964/10000 [10:14<16:04,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4637/12392 [00:00<00:00, 46363\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3015\u001b[A\n",
      "Simulating N-1 Contingencies:  60%|████▊   | 5966/10000 [10:15<15:40,  4.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4801/12392 [00:00<00:00, 48006\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4899\u001b[A\n",
      "Simulating N-1 Contingencies:  60%|████▊   | 5968/10000 [10:15<13:39,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4651/12392 [00:00<00:00, 46503\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3061\u001b[A\n",
      "Simulating N-1 Contingencies:  60%|████▊   | 5975/10000 [10:16<08:01,  8.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4712/12392 [00:00<00:00, 47110\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4797\u001b[A\n",
      "Simulating N-1 Contingencies:  60%|████▊   | 5977/10000 [10:16<08:25,  7.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4877/12392 [00:00<00:00, 48756\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3170\u001b[A\n",
      "Simulating N-1 Contingencies:  60%|████▊   | 5981/10000 [10:16<08:08,  8.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4663/12392 [00:00<00:00, 46622\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4766\u001b[A\n",
      "Simulating N-1 Contingencies:  60%|████▊   | 5983/10000 [10:17<08:34,  7.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4770/12392 [00:00<00:00, 47695\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4856\u001b[A\n",
      "Simulating N-1 Contingencies:  60%|████▊   | 5989/10000 [10:17<06:21, 10.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  11%| | 1310/12392 [00:00<00:01, 8496.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  50%|▍| 6160/12392 [00:00<00:00, 27734\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3270\u001b[A\n",
      "Simulating N-1 Contingencies:  60%|████▊   | 5991/10000 [10:18<07:44,  8.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4736/12392 [00:00<00:00, 47346\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4615\u001b[A\n",
      "Simulating N-1 Contingencies:  60%|████▊   | 5995/10000 [10:18<06:58,  9.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  13%|▏| 1656/12392 [00:00<00:01, 9406.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  53%|▌| 6559/12392 [00:00<00:00, 27156\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3146\u001b[A\n",
      "Simulating N-1 Contingencies:  60%|████▊   | 5997/10000 [10:18<08:27,  7.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4936/12392 [00:00<00:00, 49351\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4908\u001b[A\n",
      "Simulating N-1 Contingencies:  60%|████▊   | 5998/10000 [10:19<09:42,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  15%|▏| 1832/12392 [00:00<00:00, 10689\u001b[A\n",
      "Converting scenarios to PyG Data objects:  55%|▌| 6805/12392 [00:00<00:00, 28436\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3230\u001b[A\n",
      "Simulating N-1 Contingencies:  60%|████▊   | 6006/10000 [10:19<06:27, 10.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4953/12392 [00:00<00:00, 49522\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4966\u001b[A\n",
      "Simulating N-1 Contingencies:  60%|████▊   | 6008/10000 [10:19<06:59,  9.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  21%|▏| 2613/12392 [00:00<00:00, 14554\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3295\u001b[A\n",
      "Simulating N-1 Contingencies:  60%|████▊   | 6014/10000 [10:20<06:11, 10.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4940/12392 [00:00<00:00, 49390\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4935\u001b[A\n",
      "Simulating N-1 Contingencies:  60%|████▊   | 6016/10000 [10:20<06:45,  9.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  35%|▎| 4355/12392 [00:00<00:00, 18889\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3122\u001b[A\n",
      "Simulating N-1 Contingencies:  60%|████▊   | 6017/10000 [10:21<09:02,  7.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4875/12392 [00:00<00:00, 48747\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4909\u001b[A\n",
      "Simulating N-1 Contingencies:  60%|████▊   | 6018/10000 [10:21<10:18,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4729/12392 [00:00<00:00, 47286\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3205\u001b[A\n",
      "Simulating N-1 Contingencies:  60%|████▊   | 6021/10000 [10:21<10:06,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4758/12392 [00:00<00:00, 47577\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4866\u001b[A\n",
      "Simulating N-1 Contingencies:  60%|████▊   | 6027/10000 [10:22<06:52,  9.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4945/12392 [00:00<00:00, 49439\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3287\u001b[A\n",
      "Simulating N-1 Contingencies:  60%|████▊   | 6033/10000 [10:22<06:06, 10.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4990/12392 [00:00<00:00, 49891\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5008\u001b[A\n",
      "Simulating N-1 Contingencies:  60%|████▊   | 6036/10000 [10:22<06:12, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4954/12392 [00:00<00:00, 49535\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3247\u001b[A\n",
      "Simulating N-1 Contingencies:  60%|████▊   | 6041/10000 [10:23<06:07, 10.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4938/12392 [00:00<00:00, 49373\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4998\u001b[A\n",
      "Simulating N-1 Contingencies:  60%|████▊   | 6046/10000 [10:23<05:29, 12.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4923/12392 [00:00<00:00, 49221\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3241\u001b[A\n",
      "Simulating N-1 Contingencies:  60%|████▊   | 6050/10000 [10:24<05:59, 11.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4984/12392 [00:00<00:00, 49831\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4944\u001b[A\n",
      "Simulating N-1 Contingencies:  61%|████▊   | 6055/10000 [10:24<05:24, 12.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4927/12392 [00:00<00:00, 49254\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3237\u001b[A\n",
      "Simulating N-1 Contingencies:  61%|████▊   | 6058/10000 [10:24<06:18, 10.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 5006/12392 [00:00<00:00, 50056\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4941\u001b[A\n",
      "Simulating N-1 Contingencies:  61%|████▊   | 6060/10000 [10:25<06:51,  9.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4785/12392 [00:00<00:00, 47842\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4861\u001b[A\n",
      "Simulating N-1 Contingencies:  61%|████▊   | 6065/10000 [10:25<06:07, 10.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4838/12392 [00:00<00:00, 48372\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4920\u001b[A\n",
      "Simulating N-1 Contingencies:  61%|████▊   | 6068/10000 [10:25<06:15, 10.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4952/12392 [00:00<00:00, 49496\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4975\u001b[A\n",
      "Simulating N-1 Contingencies:  61%|████▊   | 6071/10000 [10:26<06:19, 10.35it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4693/12392 [00:00<00:00, 46926\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4857\u001b[A\n",
      "Simulating N-1 Contingencies:  61%|████▊   | 6073/10000 [10:26<07:56,  8.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4959/12392 [00:00<00:00, 49588\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4906\u001b[A\n",
      "Simulating N-1 Contingencies:  61%|████▊   | 6074/10000 [10:26<09:19,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   2%| | 266/12392 [00:00<00:06, 1868.9\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4779/12392 [00:00<00:00, 23538\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3081\u001b[A\n",
      "Simulating N-1 Contingencies:  61%|████▊   | 6076/10000 [10:27<10:46,  6.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4753/12392 [00:00<00:00, 47527\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4824\u001b[A\n",
      "Simulating N-1 Contingencies:  61%|████▊   | 6077/10000 [10:27<12:02,  5.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   8%| | 962/12392 [00:00<00:01, 6470.1\u001b[A\n",
      "Converting scenarios to PyG Data objects:  47%|▍| 5850/12392 [00:00<00:00, 27249\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3255\u001b[A\n",
      "Simulating N-1 Contingencies:  61%|████▊   | 6079/10000 [10:28<12:33,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4772/12392 [00:00<00:00, 47718\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4827\u001b[A\n",
      "Simulating N-1 Contingencies:  61%|████▊   | 6080/10000 [10:28<13:39,  4.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  13%|▏| 1658/12392 [00:00<00:01, 9955.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  53%|▌| 6614/12392 [00:00<00:00, 28241\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3236\u001b[A\n",
      "Simulating N-1 Contingencies:  61%|████▊   | 6082/10000 [10:28<13:41,  4.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4869/12392 [00:00<00:00, 48684\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4958\u001b[A\n",
      "Simulating N-1 Contingencies:  61%|████▊   | 6084/10000 [10:29<12:15,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  23%|▏| 2789/12392 [00:00<00:00, 14854\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3246\u001b[A\n",
      "Simulating N-1 Contingencies:  61%|████▊   | 6086/10000 [10:29<12:43,  5.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4858/12392 [00:00<00:00, 48571\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4925\u001b[A\n",
      "Simulating N-1 Contingencies:  61%|████▊   | 6087/10000 [10:29<13:43,  4.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  33%|▎| 4094/12392 [00:00<00:00, 19008\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3242\u001b[A\n",
      "Simulating N-1 Contingencies:  61%|████▊   | 6088/10000 [10:30<16:25,  3.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4829/12392 [00:00<00:00, 48280\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4862\u001b[A\n",
      "Simulating N-1 Contingencies:  61%|████▊   | 6091/10000 [10:30<11:46,  5.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4817/12392 [00:00<00:00, 48167\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3218\u001b[A\n",
      "Simulating N-1 Contingencies:  61%|████▊   | 6092/10000 [10:30<14:32,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4883/12392 [00:00<00:00, 48827\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4935\u001b[A\n",
      "Simulating N-1 Contingencies:  61%|████▉   | 6094/10000 [10:31<12:46,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4935/12392 [00:00<00:00, 49348\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3277\u001b[A\n",
      "Simulating N-1 Contingencies:  61%|████▉   | 6095/10000 [10:31<15:24,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4934/12392 [00:00<00:00, 49334\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4949\u001b[A\n",
      "Simulating N-1 Contingencies:  61%|████▉   | 6101/10000 [10:31<07:59,  8.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4955/12392 [00:00<00:00, 49543\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3266\u001b[A\n",
      "Simulating N-1 Contingencies:  61%|████▉   | 6108/10000 [10:32<06:09, 10.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 5013/12392 [00:00<00:00, 50121\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5026\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4976/12392 [00:00<00:00, 49752\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3273\u001b[A\n",
      "Simulating N-1 Contingencies:  61%|████▉   | 6110/10000 [10:33<08:52,  7.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4905/12392 [00:00<00:00, 49043\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4957\u001b[A\n",
      "Simulating N-1 Contingencies:  61%|████▉   | 6117/10000 [10:33<06:14, 10.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 5000/12392 [00:00<00:00, 49996\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3255\u001b[A\n",
      "Simulating N-1 Contingencies:  61%|████▉   | 6131/10000 [10:33<03:42, 17.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4945/12392 [00:00<00:00, 49444\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4998\u001b[A\n",
      "Simulating N-1 Contingencies:  61%|████▉   | 6135/10000 [10:34<03:58, 16.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4529/12392 [00:00<00:00, 45215\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3821\u001b[A\n",
      "Simulating N-1 Contingencies:  61%|████▉   | 6141/10000 [10:34<04:31, 14.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4885/12392 [00:00<00:00, 48840\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4713\u001b[A\n",
      "Simulating N-1 Contingencies:  61%|████▉   | 6143/10000 [10:35<05:24, 11.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4754/12392 [00:00<00:00, 47529\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4807\u001b[A\n",
      "Simulating N-1 Contingencies:  61%|████▉   | 6146/10000 [10:35<05:44, 11.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4896/12392 [00:00<00:00, 48950\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4945\u001b[A\n",
      "Simulating N-1 Contingencies:  61%|████▉   | 6148/10000 [10:35<07:19,  8.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4953/12392 [00:00<00:00, 49528\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5027\u001b[A\n",
      "Simulating N-1 Contingencies:  62%|████▉   | 6152/10000 [10:36<07:02,  9.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4921/12392 [00:00<00:00, 49202\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4974\u001b[A\n",
      "Simulating N-1 Contingencies:  62%|████▉   | 6154/10000 [10:36<07:35,  8.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4986/12392 [00:00<00:00, 49856\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3207\u001b[A\n",
      "Simulating N-1 Contingencies:  62%|████▉   | 6157/10000 [10:37<08:11,  7.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4975/12392 [00:00<00:00, 49748\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5021\u001b[A\n",
      "Simulating N-1 Contingencies:  62%|████▉   | 6161/10000 [10:37<06:52,  9.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4994/12392 [00:00<00:00, 49935\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5009\u001b[A\n",
      "Simulating N-1 Contingencies:  62%|████▉   | 6163/10000 [10:37<07:21,  8.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  16%|▏| 2006/12392 [00:00<00:00, 11912\u001b[A\n",
      "Converting scenarios to PyG Data objects:  56%|▌| 6966/12392 [00:00<00:00, 29209\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3284\u001b[A\n",
      "Simulating N-1 Contingencies:  62%|████▉   | 6164/10000 [10:38<09:53,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4960/12392 [00:00<00:00, 49594\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4985\u001b[A\n",
      "Simulating N-1 Contingencies:  62%|████▉   | 6167/10000 [10:38<08:34,  7.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  20%|▏| 2528/12392 [00:00<00:00, 13763\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3241\u001b[A\n",
      "Simulating N-1 Contingencies:  62%|████▉   | 6169/10000 [10:38<09:49,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4898/12392 [00:00<00:00, 48974\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4924\u001b[A\n",
      "Simulating N-1 Contingencies:  62%|████▉   | 6171/10000 [10:39<09:39,  6.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  25%|▏| 3048/12392 [00:00<00:00, 15492\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3197\u001b[A\n",
      "Simulating N-1 Contingencies:  62%|████▉   | 6174/10000 [10:39<09:33,  6.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4703/12392 [00:00<00:00, 46905\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4835\u001b[A\n",
      "Simulating N-1 Contingencies:  62%|████▉   | 6175/10000 [10:39<10:48,  5.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  34%|▎| 4179/12392 [00:00<00:00, 18670\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3175\u001b[A\n",
      "Simulating N-1 Contingencies:  62%|████▉   | 6178/10000 [10:40<10:14,  6.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4806/12392 [00:00<00:00, 48058\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4900\u001b[A\n",
      "Simulating N-1 Contingencies:  62%|████▉   | 6180/10000 [10:40<09:58,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4860/12392 [00:00<00:00, 48596\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3227\u001b[A\n",
      "Simulating N-1 Contingencies:  62%|████▉   | 6182/10000 [10:40<10:56,  5.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4945/12392 [00:00<00:00, 49447\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4841\u001b[A\n",
      "Simulating N-1 Contingencies:  62%|████▉   | 6183/10000 [10:41<12:06,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4935/12392 [00:00<00:00, 49342\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3213\u001b[A\n",
      "Simulating N-1 Contingencies:  62%|████▉   | 6192/10000 [10:41<06:17, 10.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4630/12392 [00:00<00:00, 46290\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4706\u001b[A\n",
      "Simulating N-1 Contingencies:  62%|████▉   | 6198/10000 [10:42<05:15, 12.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4744/12392 [00:00<00:00, 47434\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3191\u001b[A\n",
      "Simulating N-1 Contingencies:  62%|████▉   | 6200/10000 [10:42<06:34,  9.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4763/12392 [00:00<00:00, 47627\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4899\u001b[A\n",
      "Simulating N-1 Contingencies:  62%|████▉   | 6205/10000 [10:42<05:41, 11.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 5016/12392 [00:00<00:00, 50155\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3245\u001b[A\n",
      "Simulating N-1 Contingencies:  62%|████▉   | 6209/10000 [10:43<06:03, 10.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4951/12392 [00:00<00:00, 49508\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4980\u001b[A\n",
      "Simulating N-1 Contingencies:  62%|████▉   | 6211/10000 [10:43<06:34,  9.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4964/12392 [00:00<00:00, 49626\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3213\u001b[A\n",
      "Simulating N-1 Contingencies:  62%|████▉   | 6217/10000 [10:43<05:52, 10.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4915/12392 [00:00<00:00, 49143\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4967\u001b[A\n",
      "Simulating N-1 Contingencies:  62%|████▉   | 6219/10000 [10:44<06:24,  9.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4959/12392 [00:00<00:00, 49584\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4928\u001b[A\n",
      "Simulating N-1 Contingencies:  62%|████▉   | 6224/10000 [10:44<05:53, 10.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4965/12392 [00:00<00:00, 49645\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4866\u001b[A\n",
      "Simulating N-1 Contingencies:  62%|████▉   | 6227/10000 [10:45<06:02, 10.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4687/12392 [00:00<00:00, 46865\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3146\u001b[A\n",
      "Simulating N-1 Contingencies:  62%|████▉   | 6233/10000 [10:45<05:34, 11.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4950/12392 [00:00<00:00, 49497\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4972\u001b[A\n",
      "Simulating N-1 Contingencies:  62%|████▉   | 6235/10000 [10:45<06:11, 10.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4638/12392 [00:00<00:00, 46378\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4821\u001b[A\n",
      "Simulating N-1 Contingencies:  62%|████▉   | 6238/10000 [10:46<06:15, 10.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  25%|▏| 3050/12392 [00:00<00:00, 16148\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3302\u001b[A\n",
      "Simulating N-1 Contingencies:  62%|████▉   | 6240/10000 [10:46<07:39,  8.19it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4921/12392 [00:00<00:00, 49206\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4968\u001b[A\n",
      "Simulating N-1 Contingencies:  62%|████▉   | 6247/10000 [10:46<05:19, 11.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  18%|▏| 2265/12392 [00:00<00:00, 13235\u001b[A\n",
      "Converting scenarios to PyG Data objects:  58%|▌| 7203/12392 [00:00<00:00, 29679\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3292\u001b[A\n",
      "Simulating N-1 Contingencies:  63%|█████   | 6253/10000 [10:47<05:07, 12.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4934/12392 [00:00<00:00, 49332\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4968\u001b[A\n",
      "Simulating N-1 Contingencies:  63%|█████   | 6256/10000 [10:47<05:20, 11.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  16%|▏| 2004/12392 [00:00<00:00, 12104\u001b[A\n",
      "Converting scenarios to PyG Data objects:  56%|▌| 6976/12392 [00:00<00:00, 29527\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3319\u001b[A\n",
      "Simulating N-1 Contingencies:  63%|█████   | 6261/10000 [10:48<05:24, 11.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 5005/12392 [00:00<00:00, 50046\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5034\u001b[A\n",
      "Simulating N-1 Contingencies:  63%|█████   | 6264/10000 [10:48<05:34, 11.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  17%|▏| 2093/12392 [00:00<00:00, 12525\u001b[A\n",
      "Converting scenarios to PyG Data objects:  58%|▌| 7131/12392 [00:00<00:00, 29970\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3325\u001b[A\n",
      "Simulating N-1 Contingencies:  63%|█████   | 6266/10000 [10:48<06:50,  9.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4904/12392 [00:00<00:00, 49029\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4981\u001b[A\n",
      "Simulating N-1 Contingencies:  63%|█████   | 6273/10000 [10:49<05:03, 12.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   9%| | 1134/12392 [00:00<00:01, 7636.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  49%|▍| 6114/12392 [00:00<00:00, 28309\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3309\u001b[A\n",
      "Simulating N-1 Contingencies:  63%|█████   | 6281/10000 [10:49<04:28, 13.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  41%|▍| 5025/12392 [00:00<00:00, 50247\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5028\u001b[A\n",
      "Simulating N-1 Contingencies:  63%|█████   | 6284/10000 [10:49<04:46, 12.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  17%|▏| 2093/12392 [00:00<00:00, 12475\u001b[A\n",
      "Converting scenarios to PyG Data objects:  57%|▌| 7101/12392 [00:00<00:00, 29768\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3319\u001b[A\n",
      "Simulating N-1 Contingencies:  63%|█████   | 6287/10000 [10:50<05:36, 11.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4949/12392 [00:00<00:00, 49480\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4987\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  27%|▎| 3398/12392 [00:00<00:00, 17228\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3161\u001b[A\n",
      "Simulating N-1 Contingencies:  63%|█████   | 6289/10000 [10:51<08:14,  7.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4609/12392 [00:00<00:00, 46080\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4860\u001b[A\n",
      "Simulating N-1 Contingencies:  63%|█████   | 6303/10000 [10:51<03:45, 16.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  22%|▏| 2701/12392 [00:00<00:00, 14818\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3307\u001b[A\n",
      "Simulating N-1 Contingencies:  63%|█████   | 6308/10000 [10:51<04:14, 14.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4980/12392 [00:00<00:00, 49789\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4991\u001b[A\n",
      "Simulating N-1 Contingencies:  63%|█████   | 6311/10000 [10:52<04:35, 13.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  31%|▎| 3833/12392 [00:00<00:00, 18918\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3320\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4982/12392 [00:00<00:00, 49811\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5013\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4944/12392 [00:00<00:00, 49429\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3158\u001b[A\n",
      "Simulating N-1 Contingencies:  63%|█████   | 6314/10000 [10:53<08:25,  7.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4949/12392 [00:00<00:00, 49488\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4953\u001b[A\n",
      "Simulating N-1 Contingencies:  63%|█████   | 6321/10000 [10:53<06:09,  9.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  41%|▍| 5027/12392 [00:00<00:00, 50261\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3193\u001b[A\n",
      "Simulating N-1 Contingencies:  63%|█████   | 6323/10000 [10:54<07:10,  8.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4781/12392 [00:00<00:00, 47802\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4806\u001b[A\n",
      "Simulating N-1 Contingencies:  63%|█████   | 6328/10000 [10:54<06:07,  9.98it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:  63%|█████   | 6336/10000 [10:54<03:47, 16.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4673/12392 [00:00<00:00, 46723\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3082\u001b[A\n",
      "Simulating N-1 Contingencies:  63%|█████   | 6340/10000 [10:54<04:34, 13.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4788/12392 [00:00<00:00, 47877\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4832\u001b[A\n",
      "Simulating N-1 Contingencies:  63%|█████   | 6343/10000 [10:55<04:55, 12.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4733/12392 [00:00<00:00, 47322\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3143\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4830/12392 [00:00<00:00, 48290\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4925\u001b[A\n",
      "Simulating N-1 Contingencies:  63%|█████   | 6346/10000 [10:55<07:03,  8.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4990/12392 [00:00<00:00, 49888\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3230\u001b[A\n",
      "Simulating N-1 Contingencies:  63%|█████   | 6348/10000 [10:56<08:04,  7.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4762/12392 [00:00<00:00, 47617\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4903\u001b[A\n",
      "Simulating N-1 Contingencies:  64%|█████   | 6350/10000 [10:56<08:14,  7.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4739/12392 [00:00<00:00, 47382\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3001\u001b[A\n",
      "Simulating N-1 Contingencies:  64%|█████   | 6352/10000 [10:57<09:27,  6.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4677/12392 [00:00<00:00, 46760\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4727\u001b[A\n",
      "Simulating N-1 Contingencies:  64%|█████   | 6356/10000 [10:57<07:42,  7.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4852/12392 [00:00<00:00, 48510\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4945\u001b[A\n",
      "Simulating N-1 Contingencies:  64%|█████   | 6358/10000 [10:57<07:55,  7.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  23%|▏| 2876/12392 [00:00<00:00, 14556\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3177\u001b[A\n",
      "Simulating N-1 Contingencies:  64%|█████   | 6360/10000 [10:58<09:07,  6.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4611/12392 [00:00<00:00, 46104\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4773\u001b[A\n",
      "Simulating N-1 Contingencies:  64%|█████   | 6363/10000 [10:58<08:08,  7.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  36%|▎| 4441/12392 [00:00<00:00, 19671\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3215\u001b[A\n",
      "Simulating N-1 Contingencies:  64%|█████   | 6365/10000 [10:58<09:16,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4869/12392 [00:00<00:00, 48681\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4864\u001b[A\n",
      "Simulating N-1 Contingencies:  64%|█████   | 6367/10000 [10:59<09:10,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4898/12392 [00:00<00:00, 48971\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3232\u001b[A\n",
      "Simulating N-1 Contingencies:  64%|█████   | 6373/10000 [10:59<06:51,  8.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4828/12392 [00:00<00:00, 48271\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4931\u001b[A\n",
      "Simulating N-1 Contingencies:  64%|█████   | 6374/10000 [10:59<07:57,  7.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4920/12392 [00:00<00:00, 49196\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3242\u001b[A\n",
      "Simulating N-1 Contingencies:  64%|█████   | 6379/10000 [11:00<06:52,  8.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4910/12392 [00:00<00:00, 49097\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4957\u001b[A\n",
      "Simulating N-1 Contingencies:  64%|█████   | 6384/10000 [11:00<05:42, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4935/12392 [00:00<00:00, 49344\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3271\u001b[A\n",
      "Simulating N-1 Contingencies:  64%|█████   | 6387/10000 [11:01<06:25,  9.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 5000/12392 [00:00<00:00, 49991\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5030\u001b[A\n",
      "Simulating N-1 Contingencies:  64%|█████   | 6395/10000 [11:01<04:35, 13.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 5002/12392 [00:00<00:00, 50015\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3240\u001b[A\n",
      "Simulating N-1 Contingencies:  64%|█████   | 6399/10000 [11:01<05:06, 11.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4874/12392 [00:00<00:00, 48698\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4927\u001b[A\n",
      "Simulating N-1 Contingencies:  64%|█████   | 6401/10000 [11:02<05:39, 10.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4800/12392 [00:00<00:00, 47995\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3196\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4920/12392 [00:00<00:00, 49195\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4970\u001b[A\n",
      "Simulating N-1 Contingencies:  64%|█████   | 6403/10000 [11:02<08:22,  7.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4938/12392 [00:00<00:00, 49376\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4993\u001b[A\n",
      "Simulating N-1 Contingencies:  64%|█████▏  | 6408/10000 [11:03<06:35,  9.09it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  15%|▏| 1830/12392 [00:00<00:00, 11145\u001b[A\n",
      "Converting scenarios to PyG Data objects:  54%|▌| 6732/12392 [00:00<00:00, 28763\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3273\u001b[A\n",
      "Simulating N-1 Contingencies:  64%|█████▏  | 6415/10000 [11:03<05:28, 10.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4987/12392 [00:00<00:00, 49864\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5004\u001b[A\n",
      "Simulating N-1 Contingencies:  64%|█████▏  | 6419/10000 [11:04<05:14, 11.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  23%|▏| 2789/12392 [00:00<00:00, 15345\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3299\u001b[A\n",
      "Simulating N-1 Contingencies:  64%|█████▏  | 6421/10000 [11:04<06:21,  9.38it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:  64%|█████▏  | 6430/10000 [11:04<03:30, 16.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4996/12392 [00:00<00:00, 49955\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5033\u001b[A\n",
      "Simulating N-1 Contingencies:  64%|█████▏  | 6435/10000 [11:04<03:34, 16.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  18%|▏| 2267/12392 [00:00<00:00, 13246\u001b[A\n",
      "Converting scenarios to PyG Data objects:  58%|▌| 7218/12392 [00:00<00:00, 29742\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3295\u001b[A\n",
      "Simulating N-1 Contingencies:  64%|█████▏  | 6438/10000 [11:05<04:31, 13.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4938/12392 [00:00<00:00, 49375\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4979\u001b[A\n",
      "Simulating N-1 Contingencies:  64%|█████▏  | 6441/10000 [11:05<04:49, 12.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  18%|▏| 2178/12392 [00:00<00:00, 12856\u001b[A\n",
      "Converting scenarios to PyG Data objects:  58%|▌| 7173/12392 [00:00<00:00, 29824\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3314\u001b[A\n",
      "Simulating N-1 Contingencies:  64%|█████▏  | 6444/10000 [11:06<05:40, 10.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  41%|▍| 5026/12392 [00:00<00:00, 50251\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4986\u001b[A\n",
      "Simulating N-1 Contingencies:  64%|█████▏  | 6448/10000 [11:06<05:19, 11.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  15%|▏| 1917/12392 [00:00<00:00, 11249\u001b[A\n",
      "Converting scenarios to PyG Data objects:  55%|▌| 6815/12392 [00:00<00:00, 28454\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3235\u001b[A\n",
      "Simulating N-1 Contingencies:  65%|█████▏  | 6452/10000 [11:06<05:43, 10.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4850/12392 [00:00<00:00, 48497\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4933\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  26%|▎| 3224/12392 [00:00<00:00, 16633\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3251\u001b[A\n",
      "Simulating N-1 Contingencies:  65%|█████▏  | 6454/10000 [11:07<08:19,  7.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4924/12392 [00:00<00:00, 49232\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4933\u001b[A\n",
      "Simulating N-1 Contingencies:  65%|█████▏  | 6456/10000 [11:07<08:21,  7.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  34%|▎| 4179/12392 [00:00<00:00, 19658\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3281\u001b[A\n",
      "Simulating N-1 Contingencies:  65%|█████▏  | 6469/10000 [11:08<03:53, 15.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4965/12392 [00:00<00:00, 49634\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5008\u001b[A\n",
      "/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:  65%|█████▏  | 6473/10000 [11:08<04:02, 14.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  30%|▎| 3659/12392 [00:00<00:00, 18055\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3203\u001b[A\n",
      "Simulating N-1 Contingencies:  65%|█████▏  | 6477/10000 [11:09<04:43, 12.43it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4728/12392 [00:00<00:00, 47273\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4894\u001b[A\n",
      "Simulating N-1 Contingencies:  65%|█████▏  | 6482/10000 [11:09<04:26, 13.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  28%|▎| 3485/12392 [00:00<00:00, 17202\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3246\u001b[A\n",
      "Simulating N-1 Contingencies:  65%|█████▏  | 6490/10000 [11:09<04:04, 14.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4915/12392 [00:00<00:00, 49143\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4994\u001b[A\n",
      "Simulating N-1 Contingencies:  65%|█████▏  | 6493/10000 [11:10<04:23, 13.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  36%|▎| 4442/12392 [00:00<00:00, 20445\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3293\u001b[A\n",
      "Simulating N-1 Contingencies:  65%|█████▏  | 6496/10000 [11:10<05:12, 11.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4985/12392 [00:00<00:00, 49841\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5027\u001b[A\n",
      "Simulating N-1 Contingencies:  65%|█████▏  | 6498/10000 [11:10<05:42, 10.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4744/12392 [00:00<00:00, 47432\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3208\u001b[A\n",
      "Simulating N-1 Contingencies:  65%|█████▏  | 6500/10000 [11:11<06:59,  8.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4933/12392 [00:00<00:00, 49323\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4993\u001b[A\n",
      "Simulating N-1 Contingencies:  65%|█████▏  | 6502/10000 [11:11<07:15,  8.02it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4992/12392 [00:00<00:00, 49913\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3296\u001b[A\n",
      "Simulating N-1 Contingencies:  65%|█████▏  | 6509/10000 [11:12<05:32, 10.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4948/12392 [00:00<00:00, 49475\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4984\u001b[A\n",
      "Simulating N-1 Contingencies:  65%|█████▏  | 6518/10000 [11:12<03:59, 14.54it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4973/12392 [00:00<00:00, 49720\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3287\u001b[A\n",
      "Simulating N-1 Contingencies:  65%|█████▏  | 6520/10000 [11:12<05:03, 11.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4982/12392 [00:00<00:00, 49813\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5035\u001b[A\n",
      "Simulating N-1 Contingencies:  65%|█████▏  | 6528/10000 [11:13<03:58, 14.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4965/12392 [00:00<00:00, 49642\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3260\u001b[A\n",
      "Simulating N-1 Contingencies:  65%|█████▏  | 6530/10000 [11:13<05:03, 11.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4786/12392 [00:00<00:00, 47847\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4831\u001b[A\n",
      "Simulating N-1 Contingencies:  65%|█████▏  | 6532/10000 [11:13<05:36, 10.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4773/12392 [00:00<00:00, 47719\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3205\u001b[A\n",
      "Simulating N-1 Contingencies:  65%|█████▏  | 6534/10000 [11:14<06:51,  8.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4962/12392 [00:00<00:00, 49539\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5018\u001b[A\n",
      "Simulating N-1 Contingencies:  65%|█████▏  | 6535/10000 [11:14<07:54,  7.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4964/12392 [00:00<00:00, 49603\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5012\u001b[A\n",
      "Simulating N-1 Contingencies:  65%|█████▏  | 6543/10000 [11:15<04:51, 11.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4889/12392 [00:00<00:00, 48881\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4944\u001b[A\n",
      "Simulating N-1 Contingencies:  65%|█████▏  | 6545/10000 [11:15<05:32, 10.39it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4897/12392 [00:00<00:00, 48966\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3165\u001b[A\n",
      "Simulating N-1 Contingencies:  66%|█████▏  | 6550/10000 [11:15<05:27, 10.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4933/12392 [00:00<00:00, 49320\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4801\u001b[A\n",
      "Simulating N-1 Contingencies:  66%|█████▏  | 6552/10000 [11:16<06:02,  9.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 5009/12392 [00:00<00:00, 50084\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5018\u001b[A\n",
      "Simulating N-1 Contingencies:  66%|█████▏  | 6554/10000 [11:16<06:29,  8.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  23%|▏| 2876/12392 [00:00<00:00, 15597\u001b[A\n",
      "Converting scenarios to PyG Data objects:  59%|▌| 7266/12392 [00:00<00:00, 27951\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3132\u001b[A\n",
      "Simulating N-1 Contingencies:  66%|█████▏  | 6556/10000 [11:16<07:54,  7.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4674/12392 [00:00<00:00, 46734\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4801\u001b[A\n",
      "Simulating N-1 Contingencies:  66%|█████▏  | 6561/10000 [11:17<06:03,  9.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  26%|▎| 3224/12392 [00:00<00:00, 16106\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3221\u001b[A\n",
      "Simulating N-1 Contingencies:  66%|█████▎  | 6563/10000 [11:17<07:18,  7.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4876/12392 [00:00<00:00, 48759\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4938\u001b[A\n",
      "Simulating N-1 Contingencies:  66%|█████▎  | 6564/10000 [11:17<08:23,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  32%|▎| 4007/12392 [00:00<00:00, 18815\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3187\u001b[A\n",
      "Simulating N-1 Contingencies:  66%|█████▎  | 6571/10000 [11:18<05:53,  9.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4623/12392 [00:00<00:00, 46223\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4858\u001b[A\n",
      "Simulating N-1 Contingencies:  66%|█████▎  | 6572/10000 [11:18<06:56,  8.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4768/12392 [00:00<00:00, 47677\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3202\u001b[A\n",
      "Simulating N-1 Contingencies:  66%|█████▎  | 6574/10000 [11:19<08:06,  7.04it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4958/12392 [00:00<00:00, 49576\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4923\u001b[A\n",
      "Simulating N-1 Contingencies:  66%|█████▎  | 6578/10000 [11:19<06:40,  8.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4736/12392 [00:00<00:00, 47351\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3168\u001b[A\n",
      "Simulating N-1 Contingencies:  66%|█████▎  | 6579/10000 [11:19<08:47,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4787/12392 [00:00<00:00, 47702\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4839\u001b[A\n",
      "Simulating N-1 Contingencies:  66%|█████▎  | 6580/10000 [11:20<09:52,  5.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4687/12392 [00:00<00:00, 46864\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3129\u001b[A\n",
      "Simulating N-1 Contingencies:  66%|█████▎  | 6582/10000 [11:20<10:37,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4801/12392 [00:00<00:00, 48002\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4849\u001b[A\n",
      "Simulating N-1 Contingencies:  66%|█████▎  | 6586/10000 [11:20<07:50,  7.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4804/12392 [00:00<00:00, 48029\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4876\u001b[A\n",
      "Simulating N-1 Contingencies:  66%|█████▎  | 6590/10000 [11:21<07:17,  7.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4823/12392 [00:00<00:00, 48227\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4872\u001b[A\n",
      "Simulating N-1 Contingencies:  66%|█████▎  | 6595/10000 [11:21<05:31, 10.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4837/12392 [00:00<00:00, 48367\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3168\u001b[A\n",
      "Simulating N-1 Contingencies:  66%|█████▎  | 6597/10000 [11:22<06:59,  8.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4896/12392 [00:00<00:00, 48949\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4904\u001b[A\n",
      "Simulating N-1 Contingencies:  66%|█████▎  | 6600/10000 [11:22<06:34,  8.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4897/12392 [00:00<00:00, 48964\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4923\u001b[A\n",
      "Simulating N-1 Contingencies:  66%|█████▎  | 6608/10000 [11:22<04:21, 12.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  20%|▏| 2441/12392 [00:00<00:00, 13746\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3294\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  41%|▍| 5033/12392 [00:00<00:00, 50324\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 5039\u001b[A\n",
      "Simulating N-1 Contingencies:  66%|█████▎  | 6610/10000 [11:23<06:45,  8.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  24%|▏| 2961/12392 [00:00<00:00, 15485\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3248\u001b[A\n",
      "Simulating N-1 Contingencies:  66%|█████▎  | 6614/10000 [11:23<06:34,  8.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4932/12392 [00:00<00:00, 49314\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4985\u001b[A\n",
      "Simulating N-1 Contingencies:  66%|█████▎  | 6623/10000 [11:24<04:24, 12.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  27%|▎| 3398/12392 [00:00<00:00, 16566\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3175\u001b[A\n",
      "Simulating N-1 Contingencies:  66%|█████▎  | 6626/10000 [11:24<05:08, 10.92it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4769/12392 [00:00<00:00, 47684\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4854\u001b[A\n",
      "Simulating N-1 Contingencies:  66%|█████▎  | 6632/10000 [11:25<04:28, 12.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  30%|▎| 3746/12392 [00:00<00:00, 17756\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3213\u001b[A\n",
      "Simulating N-1 Contingencies:  66%|█████▎  | 6634/10000 [11:25<05:33, 10.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4777/12392 [00:00<00:00, 47762\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4868\u001b[A\n",
      "Simulating N-1 Contingencies:  66%|█████▎  | 6636/10000 [11:25<06:00,  9.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  35%|▎| 4351/12392 [00:00<00:00, 43505\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3050\u001b[A\n",
      "Simulating N-1 Contingencies:  66%|█████▎  | 6637/10000 [11:26<07:59,  7.01it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4786/12392 [00:00<00:00, 47852\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4862\u001b[A\n",
      "Simulating N-1 Contingencies:  66%|█████▎  | 6640/10000 [11:26<07:17,  7.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4851/12392 [00:00<00:00, 48506\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 2611\u001b[A\n",
      "Simulating N-1 Contingencies:  66%|█████▎  | 6643/10000 [11:27<08:08,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4602/12392 [00:00<00:00, 46015\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4734\u001b[A\n",
      "Simulating N-1 Contingencies:  66%|█████▎  | 6647/10000 [11:27<06:55,  8.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4727/12392 [00:00<00:00, 47266\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3078\u001b[A\n",
      "Simulating N-1 Contingencies:  67%|█████▎  | 6653/10000 [11:27<05:53,  9.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4787/12392 [00:00<00:00, 47866\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4778\u001b[A\n",
      "Simulating N-1 Contingencies:  67%|█████▎  | 6654/10000 [11:28<06:53,  8.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4770/12392 [00:00<00:00, 47690\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3072\u001b[A\n",
      "Simulating N-1 Contingencies:  67%|█████▎  | 6659/10000 [11:28<06:16,  8.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4741/12392 [00:00<00:00, 47407\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4805\u001b[A\n",
      "Simulating N-1 Contingencies:  67%|█████▎  | 6674/10000 [11:29<03:03, 18.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4702/12392 [00:00<00:00, 47004\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3036\u001b[A\n",
      "Simulating N-1 Contingencies:  67%|█████▎  | 6678/10000 [11:29<03:57, 14.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4732/12392 [00:00<00:00, 47316\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4796\u001b[A\n",
      "Simulating N-1 Contingencies:  67%|█████▎  | 6681/10000 [11:29<04:18, 12.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4785/12392 [00:00<00:00, 47841\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3036\u001b[A\n",
      "Simulating N-1 Contingencies:  67%|█████▎  | 6684/10000 [11:30<05:14, 10.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4852/12392 [00:00<00:00, 48513\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4831\u001b[A\n",
      "Simulating N-1 Contingencies:  67%|█████▎  | 6686/10000 [11:30<05:45,  9.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4821/12392 [00:00<00:00, 48201\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4751\u001b[A\n",
      "Simulating N-1 Contingencies:  67%|█████▎  | 6688/10000 [11:31<06:20,  8.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   9%| | 1134/12392 [00:00<00:01, 6686.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  47%|▍| 5850/12392 [00:00<00:00, 25190\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3057\u001b[A\n",
      "Simulating N-1 Contingencies:  67%|█████▎  | 6694/10000 [11:31<05:31,  9.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4689/12392 [00:00<00:00, 46880\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4744\u001b[A\n",
      "Simulating N-1 Contingencies:  67%|█████▎  | 6696/10000 [11:31<06:01,  9.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  18%|▏| 2265/12392 [00:00<00:00, 12451\u001b[A\n",
      "Converting scenarios to PyG Data objects:  57%|▌| 7062/12392 [00:00<00:00, 28073\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3110\u001b[A\n",
      "Simulating N-1 Contingencies:  67%|█████▎  | 6698/10000 [11:32<07:15,  7.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4758/12392 [00:00<00:00, 47568\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4743\u001b[A\n",
      "Simulating N-1 Contingencies:  67%|█████▎  | 6699/10000 [11:32<08:21,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  18%|▏| 2178/12392 [00:00<00:00, 11208\u001b[A\n",
      "Converting scenarios to PyG Data objects:  56%|▌| 6970/12392 [00:00<00:00, 26762\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3038\u001b[A\n",
      "Simulating N-1 Contingencies:  67%|█████▎  | 6712/10000 [11:33<03:41, 14.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4785/12392 [00:00<00:00, 47840\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4749\u001b[A\n",
      "Simulating N-1 Contingencies:  67%|█████▎  | 6715/10000 [11:33<04:07, 13.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  13%|▏| 1569/12392 [00:00<00:01, 8698.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  48%|▍| 5942/12392 [00:00<00:00, 24178\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 2952\u001b[A\n",
      "Simulating N-1 Contingencies:  67%|█████▎  | 6718/10000 [11:33<05:12, 10.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4699/12392 [00:00<00:00, 46988\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4724\u001b[A\n",
      "Simulating N-1 Contingencies:  67%|█████▍  | 6720/10000 [11:34<05:46,  9.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  15%|▏| 1917/12392 [00:00<00:00, 10989\u001b[A\n",
      "Converting scenarios to PyG Data objects:  54%|▌| 6706/12392 [00:00<00:00, 27602\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3161\u001b[A\n",
      "Simulating N-1 Contingencies:  67%|█████▍  | 6723/10000 [11:34<06:26,  8.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4648/12392 [00:00<00:00, 46470\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4729\u001b[A\n",
      "Simulating N-1 Contingencies:  67%|█████▍  | 6726/10000 [11:35<06:14,  8.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  18%|▏| 2265/12392 [00:00<00:00, 12516\u001b[A\n",
      "Converting scenarios to PyG Data objects:  57%|▌| 7094/12392 [00:00<00:00, 28296\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3173\u001b[A\n",
      "Simulating N-1 Contingencies:  67%|█████▍  | 6730/10000 [11:35<06:14,  8.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4694/12392 [00:00<00:00, 46931\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4732\u001b[A\n",
      "Simulating N-1 Contingencies:  67%|█████▍  | 6735/10000 [11:35<05:15, 10.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  21%|▏| 2613/12392 [00:00<00:00, 13295\u001b[A\n",
      "Converting scenarios to PyG Data objects:  60%|▌| 7430/12392 [00:00<00:00, 27972\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3093\u001b[A\n",
      "Simulating N-1 Contingencies:  67%|█████▍  | 6737/10000 [11:36<06:29,  8.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4809/12392 [00:00<00:00, 48086\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4751\u001b[A\n",
      "Simulating N-1 Contingencies:  67%|█████▍  | 6740/10000 [11:36<06:16,  8.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  24%|▏| 2961/12392 [00:00<00:00, 14681\u001b[A\n",
      "Converting scenarios to PyG Data objects:  62%|▌| 7718/12392 [00:00<00:00, 28317\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 2974\u001b[A\n",
      "Simulating N-1 Contingencies:  67%|█████▍  | 6744/10000 [11:37<06:22,  8.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4697/12392 [00:00<00:00, 46965\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4781\u001b[A\n",
      "Simulating N-1 Contingencies:  67%|█████▍  | 6745/10000 [11:37<07:23,  7.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4703/12392 [00:00<00:00, 20041\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3156\u001b[A\n",
      "Simulating N-1 Contingencies:  67%|█████▍  | 6747/10000 [11:37<08:25,  6.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4742/12392 [00:00<00:00, 47413\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4779\u001b[A\n",
      "Simulating N-1 Contingencies:  67%|█████▍  | 6748/10000 [11:38<09:27,  5.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4792/12392 [00:00<00:00, 47876\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3123\u001b[A\n",
      "Simulating N-1 Contingencies:  68%|█████▍  | 6756/10000 [11:38<05:42,  9.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  36%|▎| 4482/12392 [00:00<00:00, 44811\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4652\u001b[A\n",
      "Simulating N-1 Contingencies:  68%|█████▍  | 6764/10000 [11:38<04:15, 12.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4677/12392 [00:00<00:00, 46765\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3140\u001b[A\n",
      "Simulating N-1 Contingencies:  68%|█████▍  | 6769/10000 [11:39<04:30, 11.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4700/12392 [00:00<00:00, 46992\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4711\u001b[A\n",
      "Simulating N-1 Contingencies:  68%|█████▍  | 6772/10000 [11:39<04:44, 11.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4660/12392 [00:00<00:00, 46591\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3130\u001b[A\n",
      "Simulating N-1 Contingencies:  68%|█████▍  | 6776/10000 [11:40<05:09, 10.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4767/12392 [00:00<00:00, 47661\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4859\u001b[A\n",
      "Simulating N-1 Contingencies:  68%|█████▍  | 6780/10000 [11:40<04:54, 10.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4876/12392 [00:00<00:00, 48751\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3175\u001b[A\n",
      "Simulating N-1 Contingencies:  68%|█████▍  | 6782/10000 [11:40<06:01,  8.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  35%|▎| 4330/12392 [00:00<00:00, 43293\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4559\u001b[A\n",
      "Simulating N-1 Contingencies:  68%|█████▍  | 6783/10000 [11:41<07:05,  7.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4788/12392 [00:00<00:00, 47868\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4836\u001b[A\n",
      "Simulating N-1 Contingencies:  68%|█████▍  | 6788/10000 [11:41<06:23,  8.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4759/12392 [00:00<00:00, 47584\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4804\u001b[A\n",
      "Simulating N-1 Contingencies:  68%|█████▍  | 6789/10000 [11:42<07:40,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4802/12392 [00:00<00:00, 48015\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4775\u001b[A\n",
      "Simulating N-1 Contingencies:  68%|█████▍  | 6790/10000 [11:42<09:00,  5.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   4%| | 528/12392 [00:00<00:03, 3553.9\u001b[A\n",
      "Converting scenarios to PyG Data objects:  41%|▍| 5108/12392 [00:00<00:00, 24260\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3106\u001b[A\n",
      "Simulating N-1 Contingencies:  68%|█████▍  | 6799/10000 [11:42<04:04, 13.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4776/12392 [00:00<00:00, 47753\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4823\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4574/12392 [00:00<00:00, 45577\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4613\u001b[A\n",
      "Simulating N-1 Contingencies:  68%|█████▍  | 6802/10000 [11:43<06:26,  8.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4782/12392 [00:00<00:00, 47816\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4832\u001b[A\n",
      "Simulating N-1 Contingencies:  68%|█████▍  | 6804/10000 [11:43<06:44,  7.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  10%| | 1223/12392 [00:00<00:01, 6414.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  49%|▍| 6045/12392 [00:00<00:00, 24319\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 2939\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4691/12392 [00:00<00:00, 46901\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4777\u001b[A\n",
      "Simulating N-1 Contingencies:  68%|█████▍  | 6806/10000 [11:44<09:38,  5.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   8%| | 960/12392 [00:00<00:01, 6194.1\u001b[A\n",
      "Converting scenarios to PyG Data objects:  46%|▍| 5713/12392 [00:00<00:00, 26018\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3145\u001b[A\n",
      "Simulating N-1 Contingencies:  68%|█████▍  | 6813/10000 [11:45<06:31,  8.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4788/12392 [00:00<00:00, 47875\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4831\u001b[A\n",
      "Simulating N-1 Contingencies:  68%|█████▍  | 6815/10000 [11:45<06:46,  7.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  13%|▏| 1658/12392 [00:00<00:01, 9432.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  52%|▌| 6488/12392 [00:00<00:00, 26856\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3102\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4749/12392 [00:00<00:00, 47485\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4717\u001b[A\n",
      "Simulating N-1 Contingencies:  68%|█████▍  | 6817/10000 [11:46<09:14,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  24%|▏| 2963/12392 [00:00<00:00, 15483\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3229\u001b[A\n",
      "Simulating N-1 Contingencies:  68%|█████▍  | 6818/10000 [11:46<10:49,  4.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4777/12392 [00:00<00:00, 47763\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4826\u001b[A\n",
      "Simulating N-1 Contingencies:  68%|█████▍  | 6832/10000 [11:47<03:45, 14.08it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:  68%|█████▍  | 6840/10000 [11:47<02:28, 21.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4766/12392 [00:00<00:00, 47649\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4738\u001b[A\n",
      "Simulating N-1 Contingencies:  68%|█████▍  | 6846/10000 [11:47<03:00, 17.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4709/12392 [00:00<00:00, 47085\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4786\u001b[A\n",
      "Simulating N-1 Contingencies:  68%|█████▍  | 6850/10000 [11:48<03:40, 14.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4692/12392 [00:00<00:00, 46907\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4773\u001b[A\n",
      "Simulating N-1 Contingencies:  69%|█████▍  | 6858/10000 [11:48<03:10, 16.45it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4763/12392 [00:00<00:00, 47624\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3138\u001b[A\n",
      "Simulating N-1 Contingencies:  69%|█████▍  | 6874/10000 [11:49<02:22, 22.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4862/12392 [00:00<00:00, 48612\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4854\u001b[A\n",
      "Simulating N-1 Contingencies:  69%|█████▌  | 6882/10000 [11:49<02:22, 21.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4751/12392 [00:00<00:00, 47504\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3151\u001b[A\n",
      "Simulating N-1 Contingencies:  69%|█████▌  | 6889/10000 [11:49<02:45, 18.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4712/12392 [00:00<00:00, 47102\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4789\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4786/12392 [00:00<00:00, 47856\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4826\u001b[A\n",
      "Simulating N-1 Contingencies:  69%|█████▌  | 6892/10000 [11:50<03:51, 13.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   9%| | 1134/12392 [00:00<00:01, 7248.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  47%|▍| 5831/12392 [00:00<00:00, 26204\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3128\u001b[A\n",
      "Simulating N-1 Contingencies:  69%|█████▌  | 6900/10000 [11:51<03:39, 14.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4844/12392 [00:00<00:00, 48432\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4637\u001b[A\n",
      "Simulating N-1 Contingencies:  69%|█████▌  | 6903/10000 [11:51<03:57, 13.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  18%|▏| 2267/12392 [00:00<00:00, 12562\u001b[A\n",
      "Converting scenarios to PyG Data objects:  58%|▌| 7157/12392 [00:00<00:00, 28616\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3189\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4783/12392 [00:00<00:00, 47821\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4864\u001b[A\n",
      "Simulating N-1 Contingencies:  69%|█████▌  | 6905/10000 [11:52<05:50,  8.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  24%|▏| 2963/12392 [00:00<00:00, 15359\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3215\u001b[A\n",
      "Simulating N-1 Contingencies:  69%|█████▌  | 6907/10000 [11:52<06:40,  7.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4790/12392 [00:00<00:00, 47881\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4853\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  34%|▎| 4268/12392 [00:00<00:00, 19435\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3214\u001b[A\n",
      "Simulating N-1 Contingencies:  69%|█████▌  | 6909/10000 [11:53<08:45,  5.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4830/12392 [00:00<00:00, 48294\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4855\u001b[A\n",
      "Simulating N-1 Contingencies:  69%|█████▌  | 6911/10000 [11:53<08:31,  6.04it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4767/12392 [00:00<00:00, 47667\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3172\u001b[A\n",
      "Simulating N-1 Contingencies:  69%|█████▌  | 6914/10000 [11:53<08:14,  6.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4777/12392 [00:00<00:00, 47765\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4799\u001b[A\n",
      "Simulating N-1 Contingencies:  69%|█████▌  | 6915/10000 [11:54<09:04,  5.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4773/12392 [00:00<00:00, 47723\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3185\u001b[A\n",
      "Simulating N-1 Contingencies:  69%|█████▌  | 6917/10000 [11:54<09:35,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4822/12392 [00:00<00:00, 48210\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4808\u001b[A\n",
      "Simulating N-1 Contingencies:  69%|█████▌  | 6918/10000 [11:54<10:25,  4.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4754/12392 [00:00<00:00, 47533\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3130\u001b[A\n",
      "Simulating N-1 Contingencies:  69%|█████▌  | 6927/10000 [11:55<04:26, 11.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4754/12392 [00:00<00:00, 47537\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4810\u001b[A\n",
      "Simulating N-1 Contingencies:  69%|█████▌  | 6935/10000 [11:55<03:24, 14.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4810/12392 [00:00<00:00, 48095\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3143\u001b[A\n",
      "Simulating N-1 Contingencies:  69%|█████▌  | 6938/10000 [11:56<04:17, 11.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4778/12392 [00:00<00:00, 47774\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4829\u001b[A\n",
      "Simulating N-1 Contingencies:  69%|█████▌  | 6940/10000 [11:56<04:50, 10.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4703/12392 [00:00<00:00, 47026\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4793\u001b[A\n",
      "Simulating N-1 Contingencies:  69%|█████▌  | 6942/10000 [11:56<05:21,  9.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   8%| | 962/12392 [00:00<00:01, 6264.6\u001b[A\n",
      "Converting scenarios to PyG Data objects:  47%|▍| 5803/12392 [00:00<00:00, 26575\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3183\u001b[A\n",
      "Simulating N-1 Contingencies:  69%|█████▌  | 6944/10000 [11:57<06:33,  7.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4703/12392 [00:00<00:00, 46845\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4763\u001b[A\n",
      "Simulating N-1 Contingencies:  69%|█████▌  | 6946/10000 [11:57<06:48,  7.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  17%|▏| 2091/12392 [00:00<00:00, 11926\u001b[A\n",
      "Converting scenarios to PyG Data objects:  56%|▌| 6924/12392 [00:00<00:00, 28269\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3188\u001b[A\n",
      "Simulating N-1 Contingencies:  69%|█████▌  | 6948/10000 [11:57<07:50,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4714/12392 [00:00<00:00, 47133\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4762\u001b[A\n",
      "Simulating N-1 Contingencies:  70%|█████▌  | 6960/10000 [11:58<03:13, 15.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  15%|▏| 1919/12392 [00:00<00:00, 11104\u001b[A\n",
      "Converting scenarios to PyG Data objects:  55%|▌| 6762/12392 [00:00<00:00, 27995\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3183\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4711/12392 [00:00<00:00, 47107\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4805\u001b[A\n",
      "Simulating N-1 Contingencies:  70%|█████▌  | 6963/10000 [11:59<05:12,  9.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  21%|▏| 2615/12392 [00:00<00:00, 13991\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3207\u001b[A\n",
      "Simulating N-1 Contingencies:  70%|█████▌  | 6966/10000 [11:59<05:44,  8.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4766/12392 [00:00<00:00, 47654\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4813\u001b[A\n",
      "Simulating N-1 Contingencies:  70%|█████▌  | 6970/10000 [11:59<05:12,  9.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  27%|▎| 3398/12392 [00:00<00:00, 16557\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3179\u001b[A\n",
      "Simulating N-1 Contingencies:  70%|█████▌  | 6972/10000 [12:00<06:15,  8.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4696/12392 [00:00<00:00, 46956\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4784\u001b[A\n",
      "Simulating N-1 Contingencies:  70%|█████▌  | 6976/10000 [12:00<05:30,  9.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  29%|▎| 3572/12392 [00:00<00:00, 17216\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3188\u001b[A\n",
      "Simulating N-1 Contingencies:  70%|█████▌  | 6981/10000 [12:01<05:11,  9.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4817/12392 [00:00<00:00, 48163\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4824\u001b[A\n",
      "Simulating N-1 Contingencies:  70%|█████▌  | 6984/10000 [12:01<05:11,  9.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  33%|▎| 4093/12392 [00:00<00:00, 18982\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3078\u001b[A\n",
      "Simulating N-1 Contingencies:  70%|█████▌  | 6986/10000 [12:01<06:19,  7.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4838/12392 [00:00<00:00, 48370\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4863\u001b[A\n",
      "Simulating N-1 Contingencies:  70%|█████▌  | 6987/10000 [12:02<07:15,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4719/12392 [00:00<00:00, 47181\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3166\u001b[A\n",
      "Simulating N-1 Contingencies:  70%|█████▌  | 6991/10000 [12:02<06:38,  7.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4803/12392 [00:00<00:00, 48022\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4834\u001b[A\n",
      "Simulating N-1 Contingencies:  70%|█████▌  | 6994/10000 [12:02<06:11,  8.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4755/12392 [00:00<00:00, 47543\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3166\u001b[A\n",
      "Simulating N-1 Contingencies:  70%|█████▌  | 7000/10000 [12:03<05:10,  9.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4801/12392 [00:00<00:00, 48007\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4848\u001b[A\n",
      "Simulating N-1 Contingencies:  70%|█████▌  | 7006/10000 [12:03<04:15, 11.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4759/12392 [00:00<00:00, 47580\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3145\u001b[A\n",
      "Simulating N-1 Contingencies:  70%|█████▌  | 7011/10000 [12:04<04:23, 11.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4617/12392 [00:00<00:00, 46159\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4745\u001b[A\n",
      "Simulating N-1 Contingencies:  70%|█████▌  | 7015/10000 [12:04<04:18, 11.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4789/12392 [00:00<00:00, 47885\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3161\u001b[A\n",
      "/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:  70%|█████▌  | 7017/10000 [12:04<05:20,  9.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4788/12392 [00:00<00:00, 47872\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4808\u001b[A\n",
      "Simulating N-1 Contingencies:  70%|█████▌  | 7019/10000 [12:05<05:43,  8.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4756/12392 [00:00<00:00, 47553\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4835\u001b[A\n",
      "Simulating N-1 Contingencies:  70%|█████▌  | 7021/10000 [12:05<06:46,  7.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4790/12392 [00:00<00:00, 47898\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4823\u001b[A\n",
      "Simulating N-1 Contingencies:  70%|█████▌  | 7024/10000 [12:06<06:07,  8.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4724/12392 [00:00<00:00, 47226\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3144\u001b[A\n",
      "Simulating N-1 Contingencies:  70%|█████▋  | 7033/10000 [12:06<03:26, 14.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4815/12392 [00:00<00:00, 48145\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4862\u001b[A\n",
      "Simulating N-1 Contingencies:  70%|█████▋  | 7036/10000 [12:06<03:50, 12.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4824/12392 [00:00<00:00, 48235\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4852\u001b[A\n",
      "Simulating N-1 Contingencies:  70%|█████▋  | 7041/10000 [12:07<03:38, 13.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  15%|▏| 1832/12392 [00:00<00:00, 10721\u001b[A\n",
      "Converting scenarios to PyG Data objects:  54%|▌| 6702/12392 [00:00<00:00, 28013\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3180\u001b[A\n",
      "Simulating N-1 Contingencies:  70%|█████▋  | 7044/10000 [12:07<04:31, 10.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4799/12392 [00:00<00:00, 47984\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4823\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  20%|▏| 2528/12392 [00:00<00:00, 12956\u001b[A\n",
      "Converting scenarios to PyG Data objects:  59%|▌| 7304/12392 [00:00<00:00, 27666\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3070\u001b[A\n",
      "Simulating N-1 Contingencies:  70%|█████▋  | 7046/10000 [12:08<06:59,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4809/12392 [00:00<00:00, 48073\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4840\u001b[A\n",
      "Simulating N-1 Contingencies:  71%|█████▋  | 7061/10000 [12:08<02:59, 16.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  10%| | 1222/12392 [00:00<00:01, 7716.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  47%|▍| 5801/12392 [00:00<00:00, 25771\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3103\u001b[A\n",
      "Simulating N-1 Contingencies:  71%|█████▋  | 7066/10000 [12:09<03:27, 14.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4647/12392 [00:00<00:00, 46462\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4770\u001b[A\n",
      "Simulating N-1 Contingencies:  71%|█████▋  | 7071/10000 [12:09<03:24, 14.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   1%| | 177/12392 [00:00<00:09, 1284.8\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4774/12392 [00:00<00:00, 24032\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3141\u001b[A\n",
      "Simulating N-1 Contingencies:  71%|█████▋  | 7077/10000 [12:10<03:35, 13.59it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4736/12392 [00:00<00:00, 47350\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4814\u001b[A\n",
      "Simulating N-1 Contingencies:  71%|█████▋  | 7081/10000 [12:10<03:40, 13.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4823/12392 [00:00<00:00, 48218\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4832\u001b[A\n",
      "Simulating N-1 Contingencies:  71%|█████▋  | 7083/10000 [12:10<04:38, 10.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4745/12392 [00:00<00:00, 47443\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4795\u001b[A\n",
      "Simulating N-1 Contingencies:  71%|█████▋  | 7086/10000 [12:11<04:44, 10.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   5%| | 613/12392 [00:00<00:02, 4199.4\u001b[A\n",
      "Converting scenarios to PyG Data objects:  43%|▍| 5340/12392 [00:00<00:00, 25499\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3166\u001b[A\n",
      "Simulating N-1 Contingencies:  71%|█████▋  | 7088/10000 [12:11<05:47,  8.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4841/12392 [00:00<00:00, 48402\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4828\u001b[A\n",
      "Simulating N-1 Contingencies:  71%|█████▋  | 7091/10000 [12:11<05:34,  8.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   6%| | 698/12392 [00:00<00:02, 4653.0\u001b[A\n",
      "Converting scenarios to PyG Data objects:  44%|▍| 5441/12392 [00:00<00:00, 25516\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3151\u001b[A\n",
      "Simulating N-1 Contingencies:  71%|█████▋  | 7092/10000 [12:12<07:20,  6.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4702/12392 [00:00<00:00, 47017\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4791\u001b[A\n",
      "Simulating N-1 Contingencies:  71%|█████▋  | 7094/10000 [12:12<07:18,  6.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  11%| | 1397/12392 [00:00<00:01, 8632.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  50%|▍| 6154/12392 [00:00<00:00, 26888\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3157\u001b[A\n",
      "Simulating N-1 Contingencies:  71%|█████▋  | 7095/10000 [12:13<09:18,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4724/12392 [00:00<00:00, 47232\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4805\u001b[A\n",
      "Simulating N-1 Contingencies:  71%|█████▋  | 7097/10000 [12:13<08:40,  5.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  17%|▏| 2093/12392 [00:00<00:00, 11748\u001b[A\n",
      "Converting scenarios to PyG Data objects:  55%|▌| 6872/12392 [00:00<00:00, 27786\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3157\u001b[A\n",
      "Simulating N-1 Contingencies:  71%|█████▋  | 7098/10000 [12:13<10:45,  4.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4782/12392 [00:00<00:00, 47815\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4809\u001b[A\n",
      "Simulating N-1 Contingencies:  71%|█████▋  | 7099/10000 [12:14<11:21,  4.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  23%|▏| 2789/12392 [00:00<00:00, 14654\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3203\u001b[A\n",
      "Simulating N-1 Contingencies:  71%|█████▋  | 7101/10000 [12:14<10:59,  4.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4758/12392 [00:00<00:00, 47576\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4785\u001b[A\n",
      "Simulating N-1 Contingencies:  71%|█████▋  | 7108/10000 [12:14<05:28,  8.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  24%|▏| 2962/12392 [00:00<00:00, 15024\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3127\u001b[A\n",
      "Simulating N-1 Contingencies:  71%|█████▋  | 7118/10000 [12:15<03:18, 14.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4770/12392 [00:00<00:00, 47694\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4813\u001b[A\n",
      "Simulating N-1 Contingencies:  71%|█████▋  | 7121/10000 [12:15<03:41, 13.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  27%|▎| 3397/12392 [00:00<00:00, 16785\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3185\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4746/12392 [00:00<00:00, 47453\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4770\u001b[A\n",
      "Simulating N-1 Contingencies:  71%|█████▋  | 7124/10000 [12:16<05:34,  8.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  32%|▎| 3918/12392 [00:00<00:00, 18267\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3185\u001b[A\n",
      "Simulating N-1 Contingencies:  71%|█████▋  | 7127/10000 [12:16<05:57,  8.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4813/12392 [00:00<00:00, 48125\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4844\u001b[A\n",
      "Simulating N-1 Contingencies:  71%|█████▋  | 7129/10000 [12:17<06:11,  7.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4790/12392 [00:00<00:00, 47875\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3187\u001b[A\n",
      "Simulating N-1 Contingencies:  71%|█████▋  | 7133/10000 [12:17<05:54,  8.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4831/12392 [00:00<00:00, 48300\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4865\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4825/12392 [00:00<00:00, 48246\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3196\u001b[A\n",
      "Simulating N-1 Contingencies:  71%|█████▋  | 7135/10000 [12:18<08:05,  5.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4701/12392 [00:00<00:00, 46915\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4529\u001b[A\n",
      "Simulating N-1 Contingencies:  71%|█████▋  | 7136/10000 [12:18<08:53,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4722/12392 [00:00<00:00, 47214\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3137\u001b[A\n",
      "Simulating N-1 Contingencies:  71%|█████▋  | 7142/10000 [12:19<06:15,  7.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4836/12392 [00:00<00:00, 48353\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4869\u001b[A\n",
      "Simulating N-1 Contingencies:  71%|█████▋  | 7144/10000 [12:19<06:24,  7.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4750/12392 [00:00<00:00, 47490\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3140\u001b[A\n",
      "Simulating N-1 Contingencies:  71%|█████▋  | 7147/10000 [12:19<06:36,  7.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4792/12392 [00:00<00:00, 47917\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4830\u001b[A\n",
      "Simulating N-1 Contingencies:  71%|█████▋  | 7149/10000 [12:20<06:42,  7.08it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4806/12392 [00:00<00:00, 48054\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4832\u001b[A\n",
      "Simulating N-1 Contingencies:  72%|█████▋  | 7154/10000 [12:20<05:09,  9.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  23%|▏| 2789/12392 [00:00<00:00, 14716\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3194\u001b[A\n",
      "Simulating N-1 Contingencies:  72%|█████▋  | 7155/10000 [12:20<06:46,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4779/12392 [00:00<00:00, 47786\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4789\u001b[A\n",
      "Simulating N-1 Contingencies:  72%|█████▋  | 7165/10000 [12:21<03:13, 14.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  18%|▏| 2265/12392 [00:00<00:00, 12631\u001b[A\n",
      "Converting scenarios to PyG Data objects:  57%|▌| 7114/12392 [00:00<00:00, 28529\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3194\u001b[A\n",
      "Simulating N-1 Contingencies:  72%|█████▋  | 7172/10000 [12:21<03:15, 14.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4644/12392 [00:00<00:00, 46430\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4756\u001b[A\n",
      "Simulating N-1 Contingencies:  72%|█████▋  | 7184/10000 [12:22<02:13, 21.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   8%| | 1049/12392 [00:00<00:01, 6792.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  47%|▍| 5870/12392 [00:00<00:00, 26691\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3185\u001b[A\n",
      "Simulating N-1 Contingencies:  72%|█████▊  | 7188/10000 [12:22<02:56, 15.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4746/12392 [00:00<00:00, 47449\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4796\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   8%| | 962/12392 [00:00<00:01, 6241.3\u001b[A\n",
      "Converting scenarios to PyG Data objects:  46%|▍| 5709/12392 [00:00<00:00, 26070\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3151\u001b[A\n",
      "Simulating N-1 Contingencies:  72%|█████▊  | 7191/10000 [12:23<04:34, 10.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4753/12392 [00:00<00:00, 47523\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4803\u001b[A\n",
      "Simulating N-1 Contingencies:  72%|█████▊  | 7197/10000 [12:23<03:53, 11.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   9%| | 1134/12392 [00:00<00:01, 7295.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  48%|▍| 5907/12392 [00:00<00:00, 26658\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3175\u001b[A\n",
      "Simulating N-1 Contingencies:  72%|█████▊  | 7200/10000 [12:24<04:30, 10.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4711/12392 [00:00<00:00, 47101\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4784\u001b[A\n",
      "Simulating N-1 Contingencies:  72%|█████▊  | 7202/10000 [12:24<04:55,  9.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  13%|▏| 1656/12392 [00:00<00:01, 9842.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  52%|▌| 6432/12392 [00:00<00:00, 27251\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3161\u001b[A\n",
      "Simulating N-1 Contingencies:  72%|█████▊  | 7205/10000 [12:24<05:26,  8.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4773/12392 [00:00<00:00, 47725\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4829\u001b[A\n",
      "Simulating N-1 Contingencies:  72%|█████▊  | 7207/10000 [12:25<05:44,  8.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  18%|▏| 2178/12392 [00:00<00:00, 12195\u001b[A\n",
      "Converting scenarios to PyG Data objects:  56%|▌| 6980/12392 [00:00<00:00, 28115\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3083\u001b[A\n",
      "Simulating N-1 Contingencies:  72%|█████▊  | 7210/10000 [12:25<06:07,  7.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4774/12392 [00:00<00:00, 47729\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4843\u001b[A\n",
      "Simulating N-1 Contingencies:  72%|█████▊  | 7214/10000 [12:26<05:15,  8.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  17%|▏| 2093/12392 [00:00<00:00, 11978\u001b[A\n",
      "Converting scenarios to PyG Data objects:  57%|▌| 7003/12392 [00:00<00:00, 28673\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3222\u001b[A\n",
      "Simulating N-1 Contingencies:  72%|█████▊  | 7216/10000 [12:26<06:12,  7.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4832/12392 [00:00<00:00, 48315\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4824\u001b[A\n",
      "Simulating N-1 Contingencies:  72%|█████▊  | 7220/10000 [12:26<05:17,  8.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  21%|▏| 2615/12392 [00:00<00:00, 13932\u001b[A\n",
      "Converting scenarios to PyG Data objects:  60%|▌| 7449/12392 [00:00<00:00, 28799\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3178\u001b[A\n",
      "Simulating N-1 Contingencies:  72%|█████▊  | 7221/10000 [12:27<06:55,  6.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4626/12392 [00:00<00:00, 46253\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4743\u001b[A\n",
      "Simulating N-1 Contingencies:  72%|█████▊  | 7222/10000 [12:27<07:51,  5.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  32%|▎| 3920/12392 [00:00<00:00, 18231\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3177\u001b[A\n",
      "Simulating N-1 Contingencies:  72%|█████▊  | 7223/10000 [12:27<09:47,  4.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4752/12392 [00:00<00:00, 47514\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4801\u001b[A\n",
      "Simulating N-1 Contingencies:  72%|█████▊  | 7224/10000 [12:28<10:26,  4.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4791/12392 [00:00<00:00, 47901\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3014\u001b[A\n",
      "Simulating N-1 Contingencies:  72%|█████▊  | 7226/10000 [12:28<10:26,  4.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4802/12392 [00:00<00:00, 48017\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4817\u001b[A\n",
      "Simulating N-1 Contingencies:  72%|█████▊  | 7240/10000 [12:29<02:58, 15.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4686/12392 [00:00<00:00, 46851\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3143\u001b[A\n",
      "Simulating N-1 Contingencies:  72%|█████▊  | 7243/10000 [12:29<03:50, 11.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4830/12392 [00:00<00:00, 48288\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4888\u001b[A\n",
      "Simulating N-1 Contingencies:  72%|█████▊  | 7246/10000 [12:29<04:02, 11.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4736/12392 [00:00<00:00, 47351\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3162\u001b[A\n",
      "Simulating N-1 Contingencies:  73%|█████▊  | 7252/10000 [12:30<03:52, 11.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4749/12392 [00:00<00:00, 47483\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4792\u001b[A\n",
      "Simulating N-1 Contingencies:  73%|█████▊  | 7254/10000 [12:30<04:21, 10.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4762/12392 [00:00<00:00, 47609\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3159\u001b[A\n",
      "Simulating N-1 Contingencies:  73%|█████▊  | 7256/10000 [12:31<05:25,  8.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4774/12392 [00:00<00:00, 47736\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4802\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4694/12392 [00:00<00:00, 46929\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3132\u001b[A\n",
      "Simulating N-1 Contingencies:  73%|█████▊  | 7258/10000 [12:31<07:41,  5.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4730/12392 [00:00<00:00, 47292\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4785\u001b[A\n",
      "Simulating N-1 Contingencies:  73%|█████▊  | 7264/10000 [12:32<05:17,  8.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4784/12392 [00:00<00:00, 47836\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4824\u001b[A\n",
      "Simulating N-1 Contingencies:  73%|█████▊  | 7269/10000 [12:32<04:28, 10.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4723/12392 [00:00<00:00, 47225\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4780\u001b[A\n",
      "Simulating N-1 Contingencies:  73%|█████▊  | 7271/10000 [12:32<05:22,  8.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4762/12392 [00:00<00:00, 47615\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3135\u001b[A\n",
      "Simulating N-1 Contingencies:  73%|█████▊  | 7276/10000 [12:33<04:57,  9.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4801/12392 [00:00<00:00, 48005\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4817\u001b[A\n",
      "Simulating N-1 Contingencies:  73%|█████▊  | 7286/10000 [12:33<02:54, 15.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4808/12392 [00:00<00:00, 48076\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4836\u001b[A\n",
      "Simulating N-1 Contingencies:  73%|█████▊  | 7290/10000 [12:34<03:05, 14.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   8%| | 1048/12392 [00:00<00:01, 6037.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  47%|▍| 5788/12392 [00:00<00:00, 24707\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3013\u001b[A\n",
      "Simulating N-1 Contingencies:  73%|█████▊  | 7293/10000 [12:34<03:57, 11.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4748/12392 [00:00<00:00, 47473\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4797\u001b[A\n",
      "Simulating N-1 Contingencies:  73%|█████▊  | 7303/10000 [12:35<02:57, 15.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4802/12392 [00:00<00:00, 48009\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4821\u001b[A\n",
      "Simulating N-1 Contingencies:  73%|█████▊  | 7306/10000 [12:35<03:19, 13.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4854/12392 [00:00<00:00, 48535\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3182\u001b[A\n",
      "Simulating N-1 Contingencies:  73%|█████▊  | 7309/10000 [12:35<04:05, 10.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4759/12392 [00:00<00:00, 47580\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4807\u001b[A\n",
      "Simulating N-1 Contingencies:  73%|█████▊  | 7311/10000 [12:36<04:34,  9.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4790/12392 [00:00<00:00, 47875\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4797\u001b[A\n",
      "Simulating N-1 Contingencies:  73%|█████▊  | 7313/10000 [12:36<05:00,  8.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  24%|▏| 2963/12392 [00:00<00:00, 15074\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3173\u001b[A\n",
      "Simulating N-1 Contingencies:  73%|█████▊  | 7315/10000 [12:36<06:04,  7.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4765/12392 [00:00<00:00, 47645\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4825\u001b[A\n",
      "Simulating N-1 Contingencies:  73%|█████▊  | 7317/10000 [12:37<06:12,  7.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  32%|▎| 3920/12392 [00:00<00:00, 18282\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3201\u001b[A\n",
      "Simulating N-1 Contingencies:  73%|█████▊  | 7321/10000 [12:37<05:44,  7.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4840/12392 [00:00<00:00, 48389\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4826\u001b[A\n",
      "Simulating N-1 Contingencies:  73%|█████▊  | 7327/10000 [12:37<04:15, 10.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  33%|▎| 4092/12392 [00:00<00:00, 18907\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3214\u001b[A\n",
      "Simulating N-1 Contingencies:  73%|█████▊  | 7338/10000 [12:38<02:44, 16.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4806/12392 [00:00<00:00, 48051\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4828\u001b[A\n",
      "Simulating N-1 Contingencies:  73%|█████▊  | 7341/10000 [12:38<03:07, 14.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  32%|▎| 3920/12392 [00:00<00:00, 18496\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3222\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4815/12392 [00:00<00:00, 48140\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4845\u001b[A\n",
      "Simulating N-1 Contingencies:  73%|█████▉  | 7344/10000 [12:39<04:47,  9.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4716/12392 [00:00<00:00, 47150\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3173\u001b[A\n",
      "Simulating N-1 Contingencies:  73%|█████▉  | 7346/10000 [12:39<05:37,  7.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4791/12392 [00:00<00:00, 47905\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4848\u001b[A\n",
      "Simulating N-1 Contingencies:  73%|█████▉  | 7348/10000 [12:40<05:49,  7.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4798/12392 [00:00<00:00, 47973\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3132\u001b[A\n",
      "Simulating N-1 Contingencies:  74%|█████▉  | 7350/10000 [12:40<06:39,  6.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4796/12392 [00:00<00:00, 47951\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4833\u001b[A\n",
      "Simulating N-1 Contingencies:  74%|█████▉  | 7352/10000 [12:40<06:37,  6.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  36%|▎| 4453/12392 [00:00<00:00, 44524\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3028\u001b[A\n",
      "Simulating N-1 Contingencies:  74%|█████▉  | 7353/10000 [12:41<08:30,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4739/12392 [00:00<00:00, 47383\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4822\u001b[A\n",
      "Simulating N-1 Contingencies:  74%|█████▉  | 7355/10000 [12:41<07:55,  5.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4707/12392 [00:00<00:00, 47066\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4803\u001b[A\n",
      "Simulating N-1 Contingencies:  74%|█████▉  | 7358/10000 [12:42<07:20,  6.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4693/12392 [00:00<00:00, 46923\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4466\u001b[A\n",
      "Simulating N-1 Contingencies:  74%|█████▉  | 7364/10000 [12:42<04:33,  9.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4758/12392 [00:00<00:00, 47573\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3105\u001b[A\n",
      "Simulating N-1 Contingencies:  74%|█████▉  | 7372/10000 [12:43<03:39, 12.00it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:  74%|█████▉  | 7380/10000 [12:43<02:19, 18.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4835/12392 [00:00<00:00, 48346\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4845\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4735/12392 [00:00<00:00, 47336\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4815\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   4%| | 527/12392 [00:00<00:03, 3641.5\u001b[A\n",
      "Converting scenarios to PyG Data objects:  43%|▍| 5304/12392 [00:00<00:00, 25561\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3047\u001b[A\n",
      "Simulating N-1 Contingencies:  74%|█████▉  | 7384/10000 [12:44<04:21,  9.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4803/12392 [00:00<00:00, 48020\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4825\u001b[A\n",
      "Simulating N-1 Contingencies:  74%|█████▉  | 7387/10000 [12:44<04:23,  9.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   2%| | 264/12392 [00:00<00:06, 1893.4\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4880/12392 [00:00<00:00, 24294\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3134\u001b[A\n",
      "Simulating N-1 Contingencies:  74%|█████▉  | 7392/10000 [12:44<04:17, 10.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4784/12392 [00:00<00:00, 47833\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4805\u001b[A\n",
      "Simulating N-1 Contingencies:  74%|█████▉  | 7397/10000 [12:45<04:04, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  34%|▎| 4239/12392 [00:00<00:00, 42381\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4515\u001b[A\n",
      "Simulating N-1 Contingencies:  74%|█████▉  | 7399/10000 [12:45<04:36,  9.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4818/12392 [00:00<00:00, 48168\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4779\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   7%| | 875/12392 [00:00<00:02, 5693.8\u001b[A\n",
      "Converting scenarios to PyG Data objects:  46%|▍| 5671/12392 [00:00<00:00, 26052\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3148\u001b[A\n",
      "Simulating N-1 Contingencies:  74%|█████▉  | 7401/10000 [12:46<06:54,  6.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4785/12392 [00:00<00:00, 47843\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4815\u001b[A\n",
      "Simulating N-1 Contingencies:  74%|█████▉  | 7403/10000 [12:46<06:47,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   4%| | 438/12392 [00:00<00:03, 3067.3\u001b[A\n",
      "Converting scenarios to PyG Data objects:  42%|▍| 5241/12392 [00:00<00:00, 25552\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3176\u001b[A\n",
      "Simulating N-1 Contingencies:  74%|█████▉  | 7411/10000 [12:47<04:27,  9.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4742/12392 [00:00<00:00, 47417\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4783\u001b[A\n",
      "Simulating N-1 Contingencies:  74%|█████▉  | 7418/10000 [12:47<03:50, 11.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4781/12392 [00:00<00:00, 47803\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4831\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4794/12392 [00:00<00:00, 47935\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4827\u001b[A\n",
      "Simulating N-1 Contingencies:  74%|█████▉  | 7420/10000 [12:48<05:25,  7.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   4%| | 438/12392 [00:00<00:03, 3093.4\u001b[A\n",
      "Converting scenarios to PyG Data objects:  42%|▍| 5206/12392 [00:00<00:00, 25485\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3185\u001b[A\n",
      "Simulating N-1 Contingencies:  74%|█████▉  | 7421/10000 [12:48<06:53,  6.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4793/12392 [00:00<00:00, 47919\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4836\u001b[A\n",
      "Simulating N-1 Contingencies:  74%|█████▉  | 7426/10000 [12:49<05:13,  8.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4715/12392 [00:00<00:00, 47134\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4817\u001b[A\n",
      "Simulating N-1 Contingencies:  74%|█████▉  | 7430/10000 [12:49<04:30,  9.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4796/12392 [00:00<00:00, 47949\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4860\u001b[A\n",
      "Simulating N-1 Contingencies:  74%|█████▉  | 7432/10000 [12:49<04:54,  8.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   2%| | 264/12392 [00:00<00:06, 1858.0\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 5015/12392 [00:00<00:00, 24743\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3148\u001b[A\n",
      "Simulating N-1 Contingencies:  74%|█████▉  | 7433/10000 [12:50<06:42,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4786/12392 [00:00<00:00, 47851\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4799\u001b[A\n",
      "Simulating N-1 Contingencies:  74%|█████▉  | 7434/10000 [12:50<07:36,  5.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   4%| | 525/12392 [00:00<00:03, 3575.8\u001b[A\n",
      "Converting scenarios to PyG Data objects:  43%|▍| 5346/12392 [00:00<00:00, 25586\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3153\u001b[A\n",
      "Simulating N-1 Contingencies:  74%|█████▉  | 7435/10000 [12:50<09:33,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4781/12392 [00:00<00:00, 47801\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4826\u001b[A\n",
      "Simulating N-1 Contingencies:  74%|█████▉  | 7437/10000 [12:51<08:25,  5.07it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:  74%|█████▉  | 7445/10000 [12:51<03:10, 13.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4772/12392 [00:00<00:00, 47710\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4820\u001b[A\n",
      "Simulating N-1 Contingencies:  74%|█████▉  | 7448/10000 [12:51<03:58, 10.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4662/12392 [00:00<00:00, 46611\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4791\u001b[A\n",
      "Simulating N-1 Contingencies:  75%|█████▉  | 7452/10000 [12:52<03:47, 11.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4811/12392 [00:00<00:00, 48103\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4849\u001b[A\n",
      "Simulating N-1 Contingencies:  75%|█████▉  | 7454/10000 [12:52<04:47,  8.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4791/12392 [00:00<00:00, 47899\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4815\u001b[A\n",
      "Simulating N-1 Contingencies:  75%|█████▉  | 7458/10000 [12:52<04:41,  9.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4788/12392 [00:00<00:00, 47671\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4827\u001b[A\n",
      "Simulating N-1 Contingencies:  75%|█████▉  | 7461/10000 [12:53<04:35,  9.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4789/12392 [00:00<00:00, 47887\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4830\u001b[A\n",
      "Simulating N-1 Contingencies:  75%|█████▉  | 7464/10000 [12:53<04:31,  9.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4840/12392 [00:00<00:00, 48396\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4860\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4810/12392 [00:00<00:00, 48098\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4623\u001b[A\n",
      "Simulating N-1 Contingencies:  75%|█████▉  | 7469/10000 [12:54<05:25,  7.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4792/12392 [00:00<00:00, 47915\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4849\u001b[A\n",
      "Simulating N-1 Contingencies:  75%|█████▉  | 7472/10000 [12:54<05:03,  8.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4692/12392 [00:00<00:00, 46912\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3134\u001b[A\n",
      "Simulating N-1 Contingencies:  75%|█████▉  | 7475/10000 [12:55<05:27,  7.71it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4792/12392 [00:00<00:00, 47909\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4841\u001b[A\n",
      "Simulating N-1 Contingencies:  75%|█████▉  | 7482/10000 [12:55<03:45, 11.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4844/12392 [00:00<00:00, 48435\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4840\u001b[A\n",
      "Simulating N-1 Contingencies:  75%|█████▉  | 7492/10000 [12:56<02:22, 17.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   8%| | 1047/12392 [00:00<00:01, 6746.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  47%|▍| 5819/12392 [00:00<00:00, 26384\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3173\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4635/12392 [00:00<00:00, 46345\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4778\u001b[A\n",
      "Simulating N-1 Contingencies:  75%|█████▉  | 7496/10000 [12:56<03:44, 11.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   8%| | 960/12392 [00:00<00:01, 6170.6\u001b[A\n",
      "Converting scenarios to PyG Data objects:  46%|▍| 5725/12392 [00:00<00:00, 26023\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3143\u001b[A\n",
      "Simulating N-1 Contingencies:  75%|██████  | 7500/10000 [12:57<04:01, 10.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4773/12392 [00:00<00:00, 47722\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4814\u001b[A\n",
      "Simulating N-1 Contingencies:  75%|██████  | 7507/10000 [12:57<03:15, 12.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   6%| | 699/12392 [00:00<00:02, 4638.6\u001b[A\n",
      "Converting scenarios to PyG Data objects:  44%|▍| 5402/12392 [00:00<00:00, 25266\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3137\u001b[A\n",
      "Simulating N-1 Contingencies:  75%|██████  | 7509/10000 [12:58<04:04, 10.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4775/12392 [00:00<00:00, 47747\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4815\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  11%| | 1397/12392 [00:00<00:01, 8676.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  50%|▌| 6252/12392 [00:00<00:00, 27421\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3200\u001b[A\n",
      "Simulating N-1 Contingencies:  75%|██████  | 7511/10000 [12:58<05:49,  7.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4824/12392 [00:00<00:00, 48233\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4844\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  22%|▏| 2701/12392 [00:00<00:00, 14263\u001b[A\n",
      "Converting scenarios to PyG Data objects:  61%|▌| 7524/12392 [00:00<00:00, 28867\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3161\u001b[A\n",
      "Simulating N-1 Contingencies:  75%|██████  | 7513/10000 [12:59<07:31,  5.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4798/12392 [00:00<00:00, 47971\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4839\u001b[A\n",
      "Simulating N-1 Contingencies:  75%|██████  | 7515/10000 [12:59<07:12,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  31%|▎| 3833/12392 [00:00<00:00, 18210\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3216\u001b[A\n",
      "Simulating N-1 Contingencies:  75%|██████  | 7517/10000 [13:00<07:35,  5.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4774/12392 [00:00<00:00, 47737\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4819\u001b[A\n",
      "Simulating N-1 Contingencies:  75%|██████  | 7520/10000 [13:00<06:28,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4789/12392 [00:00<00:00, 47882\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3141\u001b[A\n",
      "Simulating N-1 Contingencies:  75%|██████  | 7522/10000 [13:00<07:04,  5.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4742/12392 [00:00<00:00, 47412\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4781\u001b[A\n",
      "Simulating N-1 Contingencies:  75%|██████  | 7524/10000 [13:01<06:50,  6.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4720/12392 [00:00<00:00, 47196\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3167\u001b[A\n",
      "Simulating N-1 Contingencies:  75%|██████  | 7528/10000 [13:01<05:56,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4818/12392 [00:00<00:00, 48171\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4811\u001b[A\n",
      "Simulating N-1 Contingencies:  75%|██████  | 7545/10000 [13:02<01:50, 22.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4791/12392 [00:00<00:00, 47902\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3195\u001b[A\n",
      "Simulating N-1 Contingencies:  76%|██████  | 7550/10000 [13:02<02:24, 16.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4747/12392 [00:00<00:00, 47466\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4795\u001b[A\n",
      "/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:  76%|██████  | 7554/10000 [13:02<02:38, 15.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4789/12392 [00:00<00:00, 47880\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3163\u001b[A\n",
      "Simulating N-1 Contingencies:  76%|██████  | 7557/10000 [13:03<03:20, 12.16it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4794/12392 [00:00<00:00, 47935\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4832\u001b[A\n",
      "Simulating N-1 Contingencies:  76%|██████  | 7561/10000 [13:03<03:19, 12.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4795/12392 [00:00<00:00, 47946\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3173\u001b[A\n",
      "Simulating N-1 Contingencies:  76%|██████  | 7564/10000 [13:04<03:57, 10.27it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4752/12392 [00:00<00:00, 47511\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4785\u001b[A\n",
      "Simulating N-1 Contingencies:  76%|██████  | 7572/10000 [13:04<02:58, 13.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  34%|▎| 4157/12392 [00:00<00:00, 41567\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3048\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4798/12392 [00:00<00:00, 47974\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4823\u001b[A\n",
      "Simulating N-1 Contingencies:  76%|██████  | 7574/10000 [13:05<04:38,  8.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4744/12392 [00:00<00:00, 47428\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4795\u001b[A\n",
      "Simulating N-1 Contingencies:  76%|██████  | 7577/10000 [13:05<04:31,  8.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4810/12392 [00:00<00:00, 48094\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4848\u001b[A\n",
      "Simulating N-1 Contingencies:  76%|██████  | 7579/10000 [13:05<05:15,  7.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4786/12392 [00:00<00:00, 47856\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4839\u001b[A\n",
      "Simulating N-1 Contingencies:  76%|██████  | 7583/10000 [13:06<04:33,  8.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   1%| | 89/12392 [00:00<00:18, 649.32i\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4844/12392 [00:00<00:00, 24584\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3155\u001b[A\n",
      "Simulating N-1 Contingencies:  76%|██████  | 7585/10000 [13:06<05:22,  7.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4823/12392 [00:00<00:00, 48221\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4833\u001b[A\n",
      "Simulating N-1 Contingencies:  76%|██████  | 7586/10000 [13:06<06:07,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4747/12392 [00:00<00:00, 47466\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4803\u001b[A\n",
      "Simulating N-1 Contingencies:  76%|██████  | 7589/10000 [13:07<06:01,  6.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4786/12392 [00:00<00:00, 47856\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4841\u001b[A\n",
      "Simulating N-1 Contingencies:  76%|██████  | 7595/10000 [13:07<04:31,  8.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4741/12392 [00:00<00:00, 47404\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4806\u001b[A\n",
      "Simulating N-1 Contingencies:  76%|██████  | 7601/10000 [13:08<03:26, 11.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4711/12392 [00:00<00:00, 47100\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3136\u001b[A\n",
      "Simulating N-1 Contingencies:  76%|██████  | 7605/10000 [13:08<03:48, 10.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4758/12392 [00:00<00:00, 47574\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4792\u001b[A\n",
      "Simulating N-1 Contingencies:  76%|██████  | 7608/10000 [13:09<03:53, 10.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4772/12392 [00:00<00:00, 47711\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4835\u001b[A\n",
      "Simulating N-1 Contingencies:  76%|██████  | 7610/10000 [13:09<04:16,  9.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   8%| | 1049/12392 [00:00<00:01, 6820.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  46%|▍| 5705/12392 [00:00<00:00, 25956\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3163\u001b[A\n",
      "Simulating N-1 Contingencies:  76%|██████  | 7611/10000 [13:09<05:47,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4758/12392 [00:00<00:00, 47574\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4830\u001b[A\n",
      "Simulating N-1 Contingencies:  76%|██████  | 7614/10000 [13:10<05:13,  7.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  11%| | 1395/12392 [00:00<00:01, 8579.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  50%|▌| 6245/12392 [00:00<00:00, 27246\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3189\u001b[A\n",
      "Simulating N-1 Contingencies:  76%|██████  | 7618/10000 [13:10<04:56,  8.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4776/12392 [00:00<00:00, 47749\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4826\u001b[A\n",
      "Simulating N-1 Contingencies:  76%|██████  | 7619/10000 [13:10<05:43,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  22%|▏| 2702/12392 [00:00<00:00, 14286\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3192\u001b[A\n",
      "Simulating N-1 Contingencies:  76%|██████  | 7620/10000 [13:11<07:20,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4846/12392 [00:00<00:00, 48452\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4857\u001b[A\n",
      "Simulating N-1 Contingencies:  76%|██████  | 7621/10000 [13:11<08:00,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  36%|▎| 4442/12392 [00:00<00:00, 19778\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3196\u001b[A\n",
      "Simulating N-1 Contingencies:  76%|██████  | 7623/10000 [13:11<08:10,  4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4649/12392 [00:00<00:00, 46485\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4788\u001b[A\n",
      "Simulating N-1 Contingencies:  76%|██████  | 7625/10000 [13:12<07:26,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4792/12392 [00:00<00:00, 47914\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 2965\u001b[A\n",
      "Simulating N-1 Contingencies:  76%|██████  | 7628/10000 [13:12<06:56,  5.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4713/12392 [00:00<00:00, 47121\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4779\u001b[A\n",
      "Simulating N-1 Contingencies:  76%|██████  | 7634/10000 [13:13<04:26,  8.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4809/12392 [00:00<00:00, 48082\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3186\u001b[A\n",
      "Simulating N-1 Contingencies:  76%|██████  | 7641/10000 [13:13<03:38, 10.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4735/12392 [00:00<00:00, 47341\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4793\u001b[A\n",
      "Simulating N-1 Contingencies:  76%|██████  | 7645/10000 [13:13<03:30, 11.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4772/12392 [00:00<00:00, 47712\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3192\u001b[A\n",
      "Simulating N-1 Contingencies:  76%|██████  | 7647/10000 [13:14<04:19,  9.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4718/12392 [00:00<00:00, 47176\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4797\u001b[A\n",
      "Simulating N-1 Contingencies:  76%|██████  | 7648/10000 [13:14<05:03,  7.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4772/12392 [00:00<00:00, 47713\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3143\u001b[A\n",
      "Simulating N-1 Contingencies:  77%|██████  | 7651/10000 [13:15<05:18,  7.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4817/12392 [00:00<00:00, 48166\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4836\u001b[A\n",
      "Simulating N-1 Contingencies:  77%|██████  | 7652/10000 [13:15<06:03,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4801/12392 [00:00<00:00, 48007\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4834\u001b[A\n",
      "Simulating N-1 Contingencies:  77%|██████  | 7654/10000 [13:15<05:58,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  27%|▎| 3398/12392 [00:00<00:00, 16673\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3210\u001b[A\n",
      "Simulating N-1 Contingencies:  77%|██████  | 7656/10000 [13:16<06:37,  5.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4865/12392 [00:00<00:00, 48638\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4894\u001b[A\n",
      "Simulating N-1 Contingencies:  77%|██████▏ | 7657/10000 [13:16<07:20,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  33%|▎| 4094/12392 [00:00<00:00, 18807\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3193\u001b[A\n",
      "Simulating N-1 Contingencies:  77%|██████▏ | 7667/10000 [13:16<03:01, 12.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4738/12392 [00:00<00:00, 47376\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4810\u001b[A\n",
      "Simulating N-1 Contingencies:  77%|██████▏ | 7670/10000 [13:17<03:16, 11.88it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  30%|▎| 3746/12392 [00:00<00:00, 17581\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3165\u001b[A\n",
      "Simulating N-1 Contingencies:  77%|██████▏ | 7674/10000 [13:17<03:39, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4774/12392 [00:00<00:00, 47736\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4797\u001b[A\n",
      "Simulating N-1 Contingencies:  77%|██████▏ | 7681/10000 [13:17<02:53, 13.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4529/12392 [00:00<00:00, 19958\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3195\u001b[A\n",
      "Simulating N-1 Contingencies:  77%|██████▏ | 7683/10000 [13:18<03:44, 10.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4831/12392 [00:00<00:00, 48308\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4850\u001b[A\n",
      "Simulating N-1 Contingencies:  77%|██████▏ | 7685/10000 [13:18<04:05,  9.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4791/12392 [00:00<00:00, 47906\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3153\u001b[A\n",
      "Simulating N-1 Contingencies:  77%|██████▏ | 7687/10000 [13:19<04:58,  7.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  31%|▎| 3901/12392 [00:00<00:00, 39002\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4492\u001b[A\n",
      "Simulating N-1 Contingencies:  77%|██████▏ | 7695/10000 [13:19<03:17, 11.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4798/12392 [00:00<00:00, 47971\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3164\u001b[A\n",
      "Simulating N-1 Contingencies:  77%|██████▏ | 7700/10000 [13:20<03:23, 11.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4746/12392 [00:00<00:00, 47454\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4819\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4733/12392 [00:00<00:00, 47327\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3152\u001b[A\n",
      "Simulating N-1 Contingencies:  77%|██████▏ | 7702/10000 [13:20<04:58,  7.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4704/12392 [00:00<00:00, 47038\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4787\u001b[A\n",
      "Simulating N-1 Contingencies:  77%|██████▏ | 7712/10000 [13:21<02:44, 13.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4785/12392 [00:00<00:00, 47845\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3154\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4761/12392 [00:00<00:00, 47606\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4824\u001b[A\n",
      "Simulating N-1 Contingencies:  77%|██████▏ | 7715/10000 [13:21<04:06,  9.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4782/12392 [00:00<00:00, 47812\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3130\u001b[A\n",
      "Simulating N-1 Contingencies:  77%|██████▏ | 7718/10000 [13:22<04:28,  8.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4589/12392 [00:00<00:00, 45886\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4719\u001b[A\n",
      "Simulating N-1 Contingencies:  77%|██████▏ | 7721/10000 [13:22<04:21,  8.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4745/12392 [00:00<00:00, 47443\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4793\u001b[A\n",
      "Simulating N-1 Contingencies:  77%|██████▏ | 7723/10000 [13:22<04:36,  8.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  15%|▏| 1830/12392 [00:00<00:00, 10672\u001b[A\n",
      "Converting scenarios to PyG Data objects:  53%|▌| 6597/12392 [00:00<00:00, 27485\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3161\u001b[A\n",
      "Simulating N-1 Contingencies:  77%|██████▏ | 7727/10000 [13:23<04:30,  8.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4754/12392 [00:00<00:00, 47534\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4791\u001b[A\n",
      "Simulating N-1 Contingencies:  77%|██████▏ | 7729/10000 [13:23<04:44,  7.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  18%|▏| 2178/12392 [00:00<00:00, 12492\u001b[A\n",
      "Converting scenarios to PyG Data objects:  56%|▌| 6994/12392 [00:00<00:00, 28554\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3197\u001b[A\n",
      "Simulating N-1 Contingencies:  77%|██████▏ | 7734/10000 [13:24<04:13,  8.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4777/12392 [00:00<00:00, 47762\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4817\u001b[A\n",
      "Simulating N-1 Contingencies:  77%|██████▏ | 7736/10000 [13:24<04:29,  8.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  23%|▏| 2876/12392 [00:00<00:00, 14812\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3174\u001b[A\n",
      "Simulating N-1 Contingencies:  77%|██████▏ | 7737/10000 [13:24<05:51,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4791/12392 [00:00<00:00, 47904\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4837\u001b[A\n",
      "Simulating N-1 Contingencies:  77%|██████▏ | 7739/10000 [13:25<05:47,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4616/12392 [00:00<00:00, 20432\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3215\u001b[A\n",
      "Simulating N-1 Contingencies:  77%|██████▏ | 7740/10000 [13:25<07:17,  5.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4781/12392 [00:00<00:00, 47798\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4839\u001b[A\n",
      "Simulating N-1 Contingencies:  77%|██████▏ | 7742/10000 [13:25<06:46,  5.56it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:  78%|██████▏ | 7750/10000 [13:25<02:46, 13.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  34%|▎| 4267/12392 [00:00<00:00, 19186\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3055\u001b[A\n",
      "Simulating N-1 Contingencies:  78%|██████▏ | 7755/10000 [13:26<03:04, 12.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4790/12392 [00:00<00:00, 47890\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4853\u001b[A\n",
      "Simulating N-1 Contingencies:  78%|██████▏ | 7759/10000 [13:26<03:03, 12.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4767/12392 [00:00<00:00, 47659\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3147\u001b[A\n",
      "Simulating N-1 Contingencies:  78%|██████▏ | 7761/10000 [13:27<03:55,  9.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4788/12392 [00:00<00:00, 47709\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4816\u001b[A\n",
      "Simulating N-1 Contingencies:  78%|██████▏ | 7763/10000 [13:27<04:14,  8.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4784/12392 [00:00<00:00, 47830\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3155\u001b[A\n",
      "Simulating N-1 Contingencies:  78%|██████▏ | 7768/10000 [13:27<03:56,  9.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4749/12392 [00:00<00:00, 47485\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4810\u001b[A\n",
      "Simulating N-1 Contingencies:  78%|██████▏ | 7776/10000 [13:28<02:51, 12.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4706/12392 [00:00<00:00, 47055\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3151\u001b[A\n",
      "Simulating N-1 Contingencies:  78%|██████▏ | 7778/10000 [13:28<03:37, 10.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4789/12392 [00:00<00:00, 47879\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4842\u001b[A\n",
      "Simulating N-1 Contingencies:  78%|██████▏ | 7780/10000 [13:29<03:57,  9.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4823/12392 [00:00<00:00, 48223\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3182\u001b[A\n",
      "Simulating N-1 Contingencies:  78%|██████▏ | 7787/10000 [13:29<03:19, 11.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4734/12392 [00:00<00:00, 47333\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4796\u001b[A\n",
      "Simulating N-1 Contingencies:  78%|██████▏ | 7798/10000 [13:29<02:04, 17.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4768/12392 [00:00<00:00, 47671\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3172\u001b[A\n",
      "Simulating N-1 Contingencies:  78%|██████▏ | 7802/10000 [13:30<02:35, 14.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4778/12392 [00:00<00:00, 47770\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4825\u001b[A\n",
      "Simulating N-1 Contingencies:  78%|██████▏ | 7805/10000 [13:30<02:49, 12.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4747/12392 [00:00<00:00, 47459\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3116\u001b[A\n",
      "Simulating N-1 Contingencies:  78%|██████▏ | 7807/10000 [13:31<03:41,  9.92it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4772/12392 [00:00<00:00, 47710\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4838\u001b[A\n",
      "Simulating N-1 Contingencies:  78%|██████▏ | 7812/10000 [13:31<03:13, 11.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4758/12392 [00:00<00:00, 47575\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4830\u001b[A\n",
      "Simulating N-1 Contingencies:  78%|██████▎ | 7823/10000 [13:32<02:16, 15.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4696/12392 [00:00<00:00, 46955\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4770\u001b[A\n",
      "Simulating N-1 Contingencies:  78%|██████▎ | 7825/10000 [13:32<02:43, 13.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4669/12392 [00:00<00:00, 46684\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3089\u001b[A\n",
      "Simulating N-1 Contingencies:  78%|██████▎ | 7828/10000 [13:32<03:23, 10.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4746/12392 [00:00<00:00, 47450\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4800\u001b[A\n",
      "Simulating N-1 Contingencies:  78%|██████▎ | 7830/10000 [13:33<03:45,  9.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4777/12392 [00:00<00:00, 47762\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4826\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  26%|▎| 3224/12392 [00:00<00:00, 15894\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3177\u001b[A\n",
      "Simulating N-1 Contingencies:  78%|██████▎ | 7832/10000 [13:33<05:36,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4794/12392 [00:00<00:00, 47937\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4811\u001b[A\n",
      "Simulating N-1 Contingencies:  78%|██████▎ | 7839/10000 [13:34<03:42,  9.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  31%|▎| 3831/12392 [00:00<00:00, 18138\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3172\u001b[A\n",
      "Simulating N-1 Contingencies:  78%|██████▎ | 7842/10000 [13:34<04:05,  8.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4809/12392 [00:00<00:00, 48085\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4855\u001b[A\n",
      "Simulating N-1 Contingencies:  78%|██████▎ | 7845/10000 [13:34<03:59,  9.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4616/12392 [00:00<00:00, 20233\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3196\u001b[A\n",
      "Simulating N-1 Contingencies:  78%|██████▎ | 7850/10000 [13:35<03:44,  9.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4746/12392 [00:00<00:00, 47453\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4793\u001b[A\n",
      "Simulating N-1 Contingencies:  79%|██████▎ | 7858/10000 [13:35<02:46, 12.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4798/12392 [00:00<00:00, 47970\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3157\u001b[A\n",
      "Simulating N-1 Contingencies:  79%|██████▎ | 7860/10000 [13:36<03:28, 10.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4664/12392 [00:00<00:00, 46636\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4737\u001b[A\n",
      "Simulating N-1 Contingencies:  79%|██████▎ | 7864/10000 [13:36<03:18, 10.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4719/12392 [00:00<00:00, 47181\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3162\u001b[A\n",
      "Simulating N-1 Contingencies:  79%|██████▎ | 7866/10000 [13:36<04:03,  8.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4813/12392 [00:00<00:00, 48122\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4848\u001b[A\n",
      "Simulating N-1 Contingencies:  79%|██████▎ | 7867/10000 [13:37<04:42,  7.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4809/12392 [00:00<00:00, 48088\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3178\u001b[A\n",
      "Simulating N-1 Contingencies:  79%|██████▎ | 7872/10000 [13:37<04:06,  8.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4690/12392 [00:00<00:00, 46892\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4796\u001b[A\n",
      "Simulating N-1 Contingencies:  79%|██████▎ | 7873/10000 [13:38<04:46,  7.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4771/12392 [00:00<00:00, 47702\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3147\u001b[A\n",
      "Simulating N-1 Contingencies:  79%|██████▎ | 7880/10000 [13:38<03:35,  9.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4798/12392 [00:00<00:00, 47970\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4851\u001b[A\n",
      "Simulating N-1 Contingencies:  79%|██████▎ | 7882/10000 [13:38<03:52,  9.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4794/12392 [00:00<00:00, 47932\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4842\u001b[A\n",
      "Simulating N-1 Contingencies:  79%|██████▎ | 7883/10000 [13:39<04:33,  7.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   2%| | 266/12392 [00:00<00:06, 1902.5\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4925/12392 [00:00<00:00, 24485\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3136\u001b[A\n",
      "Simulating N-1 Contingencies:  79%|██████▎ | 7885/10000 [13:39<05:18,  6.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4793/12392 [00:00<00:00, 47925\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4823\u001b[A\n",
      "Simulating N-1 Contingencies:  79%|██████▎ | 7888/10000 [13:39<04:44,  7.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   3%| | 351/12392 [00:00<00:04, 2462.2\u001b[A\n",
      "Converting scenarios to PyG Data objects:  41%|▍| 5071/12392 [00:00<00:00, 24853\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3150\u001b[A\n",
      "Simulating N-1 Contingencies:  79%|██████▎ | 7889/10000 [13:40<06:08,  5.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4846/12392 [00:00<00:00, 48457\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4876\u001b[A\n",
      "Simulating N-1 Contingencies:  79%|██████▎ | 7890/10000 [13:40<06:46,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4790/12392 [00:00<00:00, 47887\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4831\u001b[A\n",
      "Simulating N-1 Contingencies:  79%|██████▎ | 7892/10000 [13:40<07:00,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4766/12392 [00:00<00:00, 47652\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4842\u001b[A\n",
      "Simulating N-1 Contingencies:  79%|██████▎ | 7898/10000 [13:41<04:35,  7.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4733/12392 [00:00<00:00, 47326\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4794\u001b[A\n",
      "Simulating N-1 Contingencies:  79%|██████▎ | 7902/10000 [13:41<03:54,  8.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4766/12392 [00:00<00:00, 47651\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3122\u001b[A\n",
      "Simulating N-1 Contingencies:  79%|██████▎ | 7906/10000 [13:42<03:57,  8.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4704/12392 [00:00<00:00, 47029\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4748\u001b[A\n",
      "Simulating N-1 Contingencies:  79%|██████▎ | 7907/10000 [13:42<04:40,  7.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4801/12392 [00:00<00:00, 48001\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4827\u001b[A\n",
      "Simulating N-1 Contingencies:  79%|██████▎ | 7908/10000 [13:42<05:26,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  28%|▎| 3485/12392 [00:00<00:00, 16941\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3150\u001b[A\n",
      "Simulating N-1 Contingencies:  79%|██████▎ | 7909/10000 [13:43<07:02,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4751/12392 [00:00<00:00, 47506\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4813\u001b[A\n",
      "Simulating N-1 Contingencies:  79%|██████▎ | 7910/10000 [13:43<07:36,  4.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4749/12392 [00:00<00:00, 47487\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3138\u001b[A\n",
      "Simulating N-1 Contingencies:  79%|██████▎ | 7911/10000 [13:43<09:10,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4786/12392 [00:00<00:00, 47851\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4823\u001b[A\n",
      "Simulating N-1 Contingencies:  79%|██████▎ | 7916/10000 [13:44<04:58,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4805/12392 [00:00<00:00, 48045\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3192\u001b[A\n",
      "Simulating N-1 Contingencies:  79%|██████▎ | 7917/10000 [13:44<06:23,  5.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4786/12392 [00:00<00:00, 47856\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4832\u001b[A\n",
      "Simulating N-1 Contingencies:  79%|██████▎ | 7918/10000 [13:45<06:59,  4.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4834/12392 [00:00<00:00, 48330\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3177\u001b[A\n",
      "Simulating N-1 Contingencies:  79%|██████▎ | 7919/10000 [13:45<08:29,  4.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4747/12392 [00:00<00:00, 47465\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4793\u001b[A\n",
      "Simulating N-1 Contingencies:  79%|██████▎ | 7921/10000 [13:45<07:16,  4.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4789/12392 [00:00<00:00, 47879\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3131\u001b[A\n",
      "Simulating N-1 Contingencies:  79%|██████▎ | 7922/10000 [13:46<08:47,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4788/12392 [00:00<00:00, 47867\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4843\u001b[A\n",
      "Simulating N-1 Contingencies:  79%|██████▎ | 7928/10000 [13:46<04:26,  7.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4805/12392 [00:00<00:00, 48039\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4800\u001b[A\n",
      "Simulating N-1 Contingencies:  79%|██████▎ | 7934/10000 [13:46<03:18, 10.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4811/12392 [00:00<00:00, 48101\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4822\u001b[A\n",
      "Simulating N-1 Contingencies:  79%|██████▎ | 7936/10000 [13:47<03:41,  9.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4742/12392 [00:00<00:00, 47417\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4523\u001b[A\n",
      "Simulating N-1 Contingencies:  79%|██████▎ | 7939/10000 [13:47<03:42,  9.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4828/12392 [00:00<00:00, 48274\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4861\u001b[A\n",
      "Simulating N-1 Contingencies:  79%|██████▎ | 7941/10000 [13:48<04:32,  7.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4746/12392 [00:00<00:00, 47456\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4824\u001b[A\n",
      "Simulating N-1 Contingencies:  79%|██████▎ | 7944/10000 [13:48<04:42,  7.27it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:  80%|██████▎ | 7952/10000 [13:48<02:00, 17.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4763/12392 [00:00<00:00, 47623\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4818\u001b[A\n",
      "Simulating N-1 Contingencies:  80%|██████▎ | 7956/10000 [13:48<02:13, 15.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4762/12392 [00:00<00:00, 47617\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3139\u001b[A\n",
      "Simulating N-1 Contingencies:  80%|██████▎ | 7960/10000 [13:49<02:45, 12.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4715/12392 [00:00<00:00, 47145\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4770\u001b[A\n",
      "Simulating N-1 Contingencies:  80%|██████▎ | 7966/10000 [13:49<02:26, 13.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4817/12392 [00:00<00:00, 48164\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4833\u001b[A\n",
      "Simulating N-1 Contingencies:  80%|██████▎ | 7968/10000 [13:50<03:12, 10.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4598/12392 [00:00<00:00, 45975\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4740\u001b[A\n",
      "Simulating N-1 Contingencies:  80%|██████▍ | 7970/10000 [13:50<03:33,  9.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4787/12392 [00:00<00:00, 47841\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4813\u001b[A\n",
      "Simulating N-1 Contingencies:  80%|██████▍ | 7972/10000 [13:50<04:19,  7.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4693/12392 [00:00<00:00, 46922\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4797\u001b[A\n",
      "Simulating N-1 Contingencies:  80%|██████▍ | 7975/10000 [13:51<04:03,  8.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4755/12392 [00:00<00:00, 47547\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4782\u001b[A\n",
      "Simulating N-1 Contingencies:  80%|██████▍ | 7978/10000 [13:51<03:53,  8.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4551/12392 [00:00<00:00, 45506\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4735\u001b[A\n",
      "Simulating N-1 Contingencies:  80%|██████▍ | 7980/10000 [13:51<04:39,  7.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4773/12392 [00:00<00:00, 47719\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4803\u001b[A\n",
      "Simulating N-1 Contingencies:  80%|██████▍ | 7981/10000 [13:52<05:20,  6.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   8%| | 962/12392 [00:00<00:01, 6204.3\u001b[A\n",
      "Converting scenarios to PyG Data objects:  46%|▍| 5714/12392 [00:00<00:00, 26014\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3141\u001b[A\n",
      "Simulating N-1 Contingencies:  80%|██████▍ | 7982/10000 [13:52<06:48,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4743/12392 [00:00<00:00, 47426\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4821\u001b[A\n",
      "Simulating N-1 Contingencies:  80%|██████▍ | 7985/10000 [13:52<05:25,  6.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   7%| | 873/12392 [00:00<00:02, 5728.2\u001b[A\n",
      "Converting scenarios to PyG Data objects:  46%|▍| 5710/12392 [00:00<00:00, 26357\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3180\u001b[A\n",
      "Simulating N-1 Contingencies:  80%|██████▍ | 7988/10000 [13:53<05:14,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4785/12392 [00:00<00:00, 47846\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4824\u001b[A\n",
      "Simulating N-1 Contingencies:  80%|██████▍ | 7989/10000 [13:53<05:52,  5.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  11%| | 1395/12392 [00:00<00:01, 8522.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  50%|▍| 6135/12392 [00:00<00:00, 26640\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3156\u001b[A\n",
      "Simulating N-1 Contingencies:  80%|██████▍ | 7993/10000 [13:54<04:56,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4828/12392 [00:00<00:00, 48272\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4840\u001b[A\n",
      "Simulating N-1 Contingencies:  80%|██████▍ | 7994/10000 [13:54<05:34,  5.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  22%|▏| 2702/12392 [00:00<00:00, 14240\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3181\u001b[A\n",
      "Simulating N-1 Contingencies:  80%|██████▍ | 7995/10000 [13:54<06:58,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4767/12392 [00:00<00:00, 47662\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4846\u001b[A\n",
      "Simulating N-1 Contingencies:  80%|██████▍ | 8001/10000 [13:55<03:59,  8.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  22%|▏| 2700/12392 [00:00<00:00, 14432\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3211\u001b[A\n",
      "Simulating N-1 Contingencies:  80%|██████▍ | 8006/10000 [13:55<03:36,  9.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4832/12392 [00:00<00:00, 48310\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4830\u001b[A\n",
      "Simulating N-1 Contingencies:  80%|██████▍ | 8007/10000 [13:55<04:13,  7.86it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  23%|▏| 2876/12392 [00:00<00:00, 14849\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3184\u001b[A\n",
      "Simulating N-1 Contingencies:  80%|██████▍ | 8015/10000 [13:56<03:03, 10.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4776/12392 [00:00<00:00, 47749\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4801\u001b[A\n",
      "Simulating N-1 Contingencies:  80%|██████▍ | 8017/10000 [13:56<03:21,  9.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  36%|▎| 4442/12392 [00:00<00:00, 19696\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3192\u001b[A\n",
      "Simulating N-1 Contingencies:  80%|██████▍ | 8020/10000 [13:57<03:44,  8.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4764/12392 [00:00<00:00, 47634\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4821\u001b[A\n",
      "Simulating N-1 Contingencies:  80%|██████▍ | 8021/10000 [13:57<04:21,  7.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4783/12392 [00:00<00:00, 47823\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3180\u001b[A\n",
      "Simulating N-1 Contingencies:  80%|██████▍ | 8023/10000 [13:57<05:00,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4685/12392 [00:00<00:00, 46842\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4773\u001b[A\n",
      "Simulating N-1 Contingencies:  80%|██████▍ | 8025/10000 [13:58<04:59,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4760/12392 [00:00<00:00, 47593\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3158\u001b[A\n",
      "Simulating N-1 Contingencies:  80%|██████▍ | 8027/10000 [13:58<05:33,  5.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4733/12392 [00:00<00:00, 47326\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4801\u001b[A\n",
      "Simulating N-1 Contingencies:  80%|██████▍ | 8029/10000 [13:58<05:22,  6.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4790/12392 [00:00<00:00, 47737\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3186\u001b[A\n",
      "Simulating N-1 Contingencies:  80%|██████▍ | 8030/10000 [13:59<06:44,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4854/12392 [00:00<00:00, 48532\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4812\u001b[A\n",
      "Simulating N-1 Contingencies:  80%|██████▍ | 8032/10000 [13:59<06:08,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  33%|▎| 4103/12392 [00:00<00:00, 41019\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3030\u001b[A\n",
      "Simulating N-1 Contingencies:  80%|██████▍ | 8034/10000 [14:00<06:31,  5.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4816/12392 [00:00<00:00, 48150\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4831\u001b[A\n",
      "Simulating N-1 Contingencies:  80%|██████▍ | 8037/10000 [14:00<05:14,  6.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4790/12392 [00:00<00:00, 47890\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4845\u001b[A\n",
      "Simulating N-1 Contingencies:  80%|██████▍ | 8041/10000 [14:00<04:06,  7.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  21%|▏| 2613/12392 [00:00<00:00, 14041\u001b[A\n",
      "Converting scenarios to PyG Data objects:  60%|▌| 7450/12392 [00:00<00:00, 28947\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3180\u001b[A\n",
      "Simulating N-1 Contingencies:  80%|██████▍ | 8044/10000 [14:01<04:19,  7.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4757/12392 [00:00<00:00, 47567\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4799\u001b[A\n",
      "Simulating N-1 Contingencies:  81%|██████▍ | 8055/10000 [14:01<02:03, 15.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   8%| | 1048/12392 [00:00<00:01, 6688.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  46%|▍| 5654/12392 [00:00<00:00, 25463\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3127\u001b[A\n",
      "Simulating N-1 Contingencies:  81%|██████▍ | 8069/10000 [14:02<01:30, 21.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4665/12392 [00:00<00:00, 46641\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4781\u001b[A\n",
      "Simulating N-1 Contingencies:  81%|██████▍ | 8073/10000 [14:02<01:59, 16.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4786/12392 [00:00<00:00, 47851\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4817\u001b[A\n",
      "Simulating N-1 Contingencies:  81%|██████▍ | 8079/10000 [14:02<01:56, 16.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4801/12392 [00:00<00:00, 48003\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3120\u001b[A\n",
      "Simulating N-1 Contingencies:  81%|██████▍ | 8082/10000 [14:03<02:29, 12.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4678/12392 [00:00<00:00, 46769\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4791\u001b[A\n",
      "Simulating N-1 Contingencies:  81%|██████▍ | 8085/10000 [14:03<02:39, 11.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4779/12392 [00:00<00:00, 47784\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4831\u001b[A\n",
      "Simulating N-1 Contingencies:  81%|██████▍ | 8088/10000 [14:04<02:48, 11.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  16%|▏| 2006/12392 [00:00<00:00, 11602\u001b[A\n",
      "Converting scenarios to PyG Data objects:  55%|▌| 6847/12392 [00:00<00:00, 28254\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3190\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4780/12392 [00:00<00:00, 47791\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4833\u001b[A\n",
      "Simulating N-1 Contingencies:  81%|██████▍ | 8090/10000 [14:04<04:19,  7.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  27%|▎| 3311/12392 [00:00<00:00, 16535\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3197\u001b[A\n",
      "Simulating N-1 Contingencies:  81%|██████▍ | 8092/10000 [14:05<04:49,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4737/12392 [00:00<00:00, 47363\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4801\u001b[A\n",
      "Simulating N-1 Contingencies:  81%|██████▍ | 8098/10000 [14:05<03:25,  9.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  32%|▎| 3918/12392 [00:00<00:00, 18196\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3165\u001b[A\n",
      "Simulating N-1 Contingencies:  81%|██████▍ | 8101/10000 [14:05<03:44,  8.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4767/12392 [00:00<00:00, 47662\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4816\u001b[A\n",
      "Simulating N-1 Contingencies:  81%|██████▍ | 8103/10000 [14:06<03:56,  8.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4795/12392 [00:00<00:00, 47943\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3183\u001b[A\n",
      "Simulating N-1 Contingencies:  81%|██████▍ | 8105/10000 [14:06<04:32,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4832/12392 [00:00<00:00, 48310\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4867\u001b[A\n",
      "Simulating N-1 Contingencies:  81%|██████▍ | 8107/10000 [14:07<04:34,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4780/12392 [00:00<00:00, 47796\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3189\u001b[A\n",
      "Simulating N-1 Contingencies:  81%|██████▍ | 8109/10000 [14:07<05:07,  6.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4871/12392 [00:00<00:00, 48703\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4870\u001b[A\n",
      "Simulating N-1 Contingencies:  81%|██████▍ | 8111/10000 [14:07<04:59,  6.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4782/12392 [00:00<00:00, 47811\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3163\u001b[A\n",
      "Simulating N-1 Contingencies:  81%|██████▍ | 8112/10000 [14:08<06:17,  5.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4766/12392 [00:00<00:00, 47650\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4816\u001b[A\n",
      "Simulating N-1 Contingencies:  81%|██████▍ | 8119/10000 [14:08<03:24,  9.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4710/12392 [00:00<00:00, 47092\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3126\u001b[A\n",
      "Simulating N-1 Contingencies:  81%|██████▍ | 8120/10000 [14:08<04:30,  6.95it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4800/12392 [00:00<00:00, 47992\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4859\u001b[A\n",
      "Simulating N-1 Contingencies:  81%|██████▍ | 8122/10000 [14:09<04:32,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4811/12392 [00:00<00:00, 48098\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3133\u001b[A\n",
      "Simulating N-1 Contingencies:  81%|██████▌ | 8125/10000 [14:09<04:35,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4811/12392 [00:00<00:00, 48106\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4845\u001b[A\n",
      "Simulating N-1 Contingencies:  81%|██████▌ | 8131/10000 [14:10<03:12,  9.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4770/12392 [00:00<00:00, 47695\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4824\u001b[A\n",
      "Simulating N-1 Contingencies:  82%|██████▌ | 8152/10000 [14:10<01:26, 21.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4761/12392 [00:00<00:00, 47609\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4774\u001b[A\n",
      "Simulating N-1 Contingencies:  82%|██████▌ | 8164/10000 [14:11<01:09, 26.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4789/12392 [00:00<00:00, 47886\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3159\u001b[A\n",
      "Simulating N-1 Contingencies:  82%|██████▌ | 8169/10000 [14:11<01:36, 19.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4789/12392 [00:00<00:00, 47879\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4841\u001b[A\n",
      "Simulating N-1 Contingencies:  82%|██████▌ | 8174/10000 [14:11<01:43, 17.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4770/12392 [00:00<00:00, 47696\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4798\u001b[A\n",
      "Simulating N-1 Contingencies:  82%|██████▌ | 8183/10000 [14:12<01:43, 17.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4800/12392 [00:00<00:00, 47997\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4837\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4706/12392 [00:00<00:00, 47051\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4749\u001b[A\n",
      "Simulating N-1 Contingencies:  82%|██████▌ | 8188/10000 [14:13<02:32, 11.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4796/12392 [00:00<00:00, 47949\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4841\u001b[A\n",
      "Simulating N-1 Contingencies:  82%|██████▌ | 8190/10000 [14:13<02:54, 10.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4768/12392 [00:00<00:00, 47671\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4814\u001b[A\n",
      "Simulating N-1 Contingencies:  82%|██████▌ | 8195/10000 [14:13<02:50, 10.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4787/12392 [00:00<00:00, 47866\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4807\u001b[A\n",
      "Simulating N-1 Contingencies:  82%|██████▌ | 8197/10000 [14:14<03:13,  9.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4787/12392 [00:00<00:00, 47867\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4829\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   3%| | 351/12392 [00:00<00:04, 2499.6\u001b[A\n",
      "Converting scenarios to PyG Data objects:  42%|▍| 5146/12392 [00:00<00:00, 25418\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3179\u001b[A\n",
      "Simulating N-1 Contingencies:  82%|██████▌ | 8199/10000 [14:14<05:03,  5.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4827/12392 [00:00<00:00, 48263\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4823\u001b[A\n",
      "Simulating N-1 Contingencies:  82%|██████▌ | 8201/10000 [14:15<04:53,  6.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   4%| | 440/12392 [00:00<00:03, 3077.0\u001b[A\n",
      "Converting scenarios to PyG Data objects:  41%|▍| 5094/12392 [00:00<00:00, 24796\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3155\u001b[A\n",
      "Simulating N-1 Contingencies:  82%|██████▌ | 8203/10000 [14:15<05:20,  5.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4760/12392 [00:00<00:00, 47593\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4834\u001b[A\n",
      "Simulating N-1 Contingencies:  82%|██████▌ | 8207/10000 [14:16<04:02,  7.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  36%|▎| 4500/12392 [00:00<00:00, 44990\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4691\u001b[A\n",
      "Simulating N-1 Contingencies:  82%|██████▌ | 8216/10000 [14:16<02:16, 13.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4719/12392 [00:00<00:00, 47184\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3144\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4774/12392 [00:00<00:00, 47732\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4822\u001b[A\n",
      "Simulating N-1 Contingencies:  82%|██████▌ | 8219/10000 [14:17<03:27,  8.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4776/12392 [00:00<00:00, 47756\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4794\u001b[A\n",
      "/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:  82%|██████▌ | 8222/10000 [14:17<03:21,  8.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  17%|▏| 2091/12392 [00:00<00:00, 11685\u001b[A\n",
      "Converting scenarios to PyG Data objects:  56%|▌| 6954/12392 [00:00<00:00, 28084\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3165\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4789/12392 [00:00<00:00, 47886\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4844\u001b[A\n",
      "Simulating N-1 Contingencies:  82%|██████▌ | 8224/10000 [14:18<04:44,  6.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  27%|▎| 3398/12392 [00:00<00:00, 16601\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3189\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4820/12392 [00:00<00:00, 48195\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4802\u001b[A\n",
      "Simulating N-1 Contingencies:  82%|██████▌ | 8226/10000 [14:18<05:58,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  32%|▎| 3920/12392 [00:00<00:00, 18099\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3055\u001b[A\n",
      "Simulating N-1 Contingencies:  82%|██████▌ | 8230/10000 [14:19<05:00,  5.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4723/12392 [00:00<00:00, 47225\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4795\u001b[A\n",
      "Simulating N-1 Contingencies:  82%|██████▌ | 8231/10000 [14:19<05:24,  5.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4835/12392 [00:00<00:00, 48346\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3154\u001b[A\n",
      "Simulating N-1 Contingencies:  82%|██████▌ | 8235/10000 [14:20<04:34,  6.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4756/12392 [00:00<00:00, 47556\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4811\u001b[A\n",
      "Simulating N-1 Contingencies:  82%|██████▌ | 8239/10000 [14:20<03:45,  7.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4755/12392 [00:00<00:00, 47543\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3188\u001b[A\n",
      "Simulating N-1 Contingencies:  82%|██████▌ | 8242/10000 [14:20<03:54,  7.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4793/12392 [00:00<00:00, 47926\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4854\u001b[A\n",
      "Simulating N-1 Contingencies:  82%|██████▌ | 8243/10000 [14:21<04:25,  6.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4861/12392 [00:00<00:00, 48604\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3206\u001b[A\n",
      "Simulating N-1 Contingencies:  82%|██████▌ | 8246/10000 [14:21<04:22,  6.67it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4691/12392 [00:00<00:00, 46904\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4730\u001b[A\n",
      "Simulating N-1 Contingencies:  82%|██████▌ | 8248/10000 [14:22<04:23,  6.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4799/12392 [00:00<00:00, 47985\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3152\u001b[A\n",
      "Simulating N-1 Contingencies:  83%|██████▌ | 8251/10000 [14:22<04:22,  6.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4796/12392 [00:00<00:00, 47954\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4797\u001b[A\n",
      "Simulating N-1 Contingencies:  83%|██████▌ | 8253/10000 [14:22<04:21,  6.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4822/12392 [00:00<00:00, 48218\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4840\u001b[A\n",
      "Simulating N-1 Contingencies:  83%|██████▌ | 8263/10000 [14:23<01:57, 14.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   4%| | 438/12392 [00:00<00:03, 3011.8\u001b[A\n",
      "Converting scenarios to PyG Data objects:  42%|▍| 5221/12392 [00:00<00:00, 25220\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3144\u001b[A\n",
      "Simulating N-1 Contingencies:  83%|██████▌ | 8267/10000 [14:23<02:21, 12.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4742/12392 [00:00<00:00, 47412\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4796\u001b[A\n",
      "Simulating N-1 Contingencies:  83%|██████▌ | 8270/10000 [14:23<02:31, 11.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   4%| | 525/12392 [00:00<00:03, 3531.4\u001b[A\n",
      "Converting scenarios to PyG Data objects:  42%|▍| 5265/12392 [00:00<00:00, 25026\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3118\u001b[A\n",
      "Simulating N-1 Contingencies:  83%|██████▌ | 8272/10000 [14:24<03:13,  8.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4756/12392 [00:00<00:00, 47557\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4813\u001b[A\n",
      "Simulating N-1 Contingencies:  83%|██████▌ | 8274/10000 [14:24<03:27,  8.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   8%| | 1049/12392 [00:00<00:01, 6778.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  47%|▍| 5815/12392 [00:00<00:00, 26400\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3173\u001b[A\n",
      "Simulating N-1 Contingencies:  83%|██████▌ | 8276/10000 [14:25<04:05,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4790/12392 [00:00<00:00, 47775\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4867\u001b[A\n",
      "Simulating N-1 Contingencies:  83%|██████▌ | 8277/10000 [14:25<04:39,  6.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  19%|▏| 2354/12392 [00:00<00:00, 12959\u001b[A\n",
      "Converting scenarios to PyG Data objects:  58%|▌| 7158/12392 [00:00<00:00, 28333\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3165\u001b[A\n",
      "Simulating N-1 Contingencies:  83%|██████▌ | 8278/10000 [14:25<05:53,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4804/12392 [00:00<00:00, 48032\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4826\u001b[A\n",
      "Simulating N-1 Contingencies:  83%|██████▋ | 8282/10000 [14:26<04:08,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  27%|▎| 3311/12392 [00:00<00:00, 15863\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3127\u001b[A\n",
      "Simulating N-1 Contingencies:  83%|██████▋ | 8284/10000 [14:26<04:41,  6.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4833/12392 [00:00<00:00, 48325\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4856\u001b[A\n",
      "Simulating N-1 Contingencies:  83%|██████▋ | 8288/10000 [14:26<03:39,  7.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  28%|▎| 3485/12392 [00:00<00:00, 16929\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3187\u001b[A\n",
      "Simulating N-1 Contingencies:  83%|██████▋ | 8293/10000 [14:27<03:13,  8.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4780/12392 [00:00<00:00, 47789\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4823\u001b[A\n",
      "Simulating N-1 Contingencies:  83%|██████▋ | 8296/10000 [14:27<03:08,  9.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  25%|▏| 3050/12392 [00:00<00:00, 15490\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3160\u001b[A\n",
      "Simulating N-1 Contingencies:  83%|██████▋ | 8303/10000 [14:28<02:36, 10.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4809/12392 [00:00<00:00, 48086\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4593\u001b[A\n",
      "Simulating N-1 Contingencies:  83%|██████▋ | 8306/10000 [14:28<02:42, 10.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  34%|▎| 4181/12392 [00:00<00:00, 18934\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3174\u001b[A\n",
      "Simulating N-1 Contingencies:  83%|██████▋ | 8308/10000 [14:28<03:17,  8.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4761/12392 [00:00<00:00, 47608\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4818\u001b[A\n",
      "Simulating N-1 Contingencies:  83%|██████▋ | 8310/10000 [14:29<03:28,  8.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4849/12392 [00:00<00:00, 48484\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3133\u001b[A\n",
      "Simulating N-1 Contingencies:  83%|██████▋ | 8311/10000 [14:29<04:31,  6.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4759/12392 [00:00<00:00, 47580\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4832\u001b[A\n",
      "Simulating N-1 Contingencies:  83%|██████▋ | 8315/10000 [14:29<03:34,  7.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4820/12392 [00:00<00:00, 48194\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3172\u001b[A\n",
      "Simulating N-1 Contingencies:  83%|██████▋ | 8321/10000 [14:30<02:56,  9.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4788/12392 [00:00<00:00, 47876\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4812\u001b[A\n",
      "Simulating N-1 Contingencies:  83%|██████▋ | 8324/10000 [14:30<02:55,  9.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4745/12392 [00:00<00:00, 47445\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3158\u001b[A\n",
      "Simulating N-1 Contingencies:  83%|██████▋ | 8330/10000 [14:31<02:38, 10.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4742/12392 [00:00<00:00, 47412\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4817\u001b[A\n",
      "Simulating N-1 Contingencies:  83%|██████▋ | 8335/10000 [14:31<02:22, 11.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4777/12392 [00:00<00:00, 47762\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3165\u001b[A\n",
      "Simulating N-1 Contingencies:  83%|██████▋ | 8338/10000 [14:32<02:45, 10.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4761/12392 [00:00<00:00, 47604\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4831\u001b[A\n",
      "Simulating N-1 Contingencies:  83%|██████▋ | 8342/10000 [14:32<02:35, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4679/12392 [00:00<00:00, 46779\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3109\u001b[A\n",
      "Simulating N-1 Contingencies:  83%|██████▋ | 8344/10000 [14:32<03:12,  8.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4800/12392 [00:00<00:00, 47992\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4833\u001b[A\n",
      "Simulating N-1 Contingencies:  84%|██████▋ | 8357/10000 [14:33<01:35, 17.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4791/12392 [00:00<00:00, 47906\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4820\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   3%| | 351/12392 [00:00<00:04, 2489.4\u001b[A\n",
      "Converting scenarios to PyG Data objects:  42%|▍| 5165/12392 [00:00<00:00, 25462\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3183\u001b[A\n",
      "Simulating N-1 Contingencies:  84%|██████▋ | 8361/10000 [14:33<02:25, 11.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4762/12392 [00:00<00:00, 47613\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4768\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4549/12392 [00:00<00:00, 45485\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4761\u001b[A\n",
      "Simulating N-1 Contingencies:  84%|██████▋ | 8364/10000 [14:34<03:17,  8.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4747/12392 [00:00<00:00, 47467\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4806\u001b[A\n",
      "Simulating N-1 Contingencies:  84%|██████▋ | 8366/10000 [14:34<03:25,  7.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4745/12392 [00:00<00:00, 47441\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4803\u001b[A\n",
      "Simulating N-1 Contingencies:  84%|██████▋ | 8368/10000 [14:35<03:52,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4766/12392 [00:00<00:00, 47651\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3109\u001b[A\n",
      "Simulating N-1 Contingencies:  84%|██████▋ | 8372/10000 [14:35<03:37,  7.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4754/12392 [00:00<00:00, 47532\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4809\u001b[A\n",
      "Simulating N-1 Contingencies:  84%|██████▋ | 8374/10000 [14:36<03:42,  7.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4778/12392 [00:00<00:00, 47775\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4799\u001b[A\n",
      "Simulating N-1 Contingencies:  84%|██████▋ | 8376/10000 [14:36<03:46,  7.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  20%|▏| 2528/12392 [00:00<00:00, 13464\u001b[A\n",
      "Converting scenarios to PyG Data objects:  59%|▌| 7373/12392 [00:00<00:00, 28578\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3151\u001b[A\n",
      "Simulating N-1 Contingencies:  84%|██████▋ | 8384/10000 [14:36<02:36, 10.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4761/12392 [00:00<00:00, 47600\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4803\u001b[A\n",
      "Simulating N-1 Contingencies:  84%|██████▋ | 8388/10000 [14:37<02:29, 10.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  25%|▏| 3050/12392 [00:00<00:00, 15461\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3181\u001b[A\n",
      "Simulating N-1 Contingencies:  84%|██████▋ | 8390/10000 [14:37<03:02,  8.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4747/12392 [00:00<00:00, 47460\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4826\u001b[A\n",
      "Simulating N-1 Contingencies:  84%|██████▋ | 8392/10000 [14:38<03:13,  8.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  34%|▎| 4181/12392 [00:00<00:00, 18525\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3126\u001b[A\n",
      "Simulating N-1 Contingencies:  84%|██████▋ | 8393/10000 [14:38<04:13,  6.34it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4683/12392 [00:00<00:00, 46826\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4794\u001b[A\n",
      "Simulating N-1 Contingencies:  84%|██████▋ | 8396/10000 [14:38<03:43,  7.16it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4841/12392 [00:00<00:00, 48402\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3008\u001b[A\n",
      "Simulating N-1 Contingencies:  84%|██████▋ | 8399/10000 [14:39<03:52,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4788/12392 [00:00<00:00, 47873\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4841\u001b[A\n",
      "Simulating N-1 Contingencies:  84%|██████▋ | 8401/10000 [14:39<03:53,  6.86it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4801/12392 [00:00<00:00, 48001\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3174\u001b[A\n",
      "Simulating N-1 Contingencies:  84%|██████▋ | 8404/10000 [14:39<03:54,  6.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4764/12392 [00:00<00:00, 47630\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4788\u001b[A\n",
      "Simulating N-1 Contingencies:  84%|██████▋ | 8406/10000 [14:40<03:55,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4768/12392 [00:00<00:00, 47670\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3141\u001b[A\n",
      "Simulating N-1 Contingencies:  84%|██████▋ | 8407/10000 [14:40<04:59,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4788/12392 [00:00<00:00, 47877\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4774\u001b[A\n",
      "Simulating N-1 Contingencies:  84%|██████▋ | 8413/10000 [14:41<03:05,  8.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  35%|▎| 4390/12392 [00:00<00:00, 43896\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3049\u001b[A\n",
      "Simulating N-1 Contingencies:  84%|██████▋ | 8417/10000 [14:41<03:06,  8.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4770/12392 [00:00<00:00, 47690\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4817\u001b[A\n",
      "Simulating N-1 Contingencies:  84%|██████▋ | 8421/10000 [14:41<02:46,  9.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4731/12392 [00:00<00:00, 47300\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3132\u001b[A\n",
      "Simulating N-1 Contingencies:  84%|██████▋ | 8429/10000 [14:42<02:14, 11.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4557/12392 [00:00<00:00, 45567\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4718\u001b[A\n",
      "Simulating N-1 Contingencies:  84%|██████▋ | 8431/10000 [14:42<02:29, 10.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4814/12392 [00:00<00:00, 48129\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4880\u001b[A\n",
      "Simulating N-1 Contingencies:  84%|██████▋ | 8436/10000 [14:43<02:13, 11.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  12%| | 1484/12392 [00:00<00:01, 9043.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  52%|▌| 6392/12392 [00:00<00:00, 27674\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3204\u001b[A\n",
      "Simulating N-1 Contingencies:  84%|██████▊ | 8438/10000 [14:43<02:46,  9.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4864/12392 [00:00<00:00, 48637\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4916\u001b[A\n",
      "Simulating N-1 Contingencies:  84%|██████▊ | 8444/10000 [14:43<02:14, 11.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  13%|▏| 1656/12392 [00:00<00:01, 9917.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  52%|▌| 6464/12392 [00:00<00:00, 27512\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3173\u001b[A\n",
      "Simulating N-1 Contingencies:  84%|██████▊ | 8447/10000 [14:44<02:35,  9.98it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4761/12392 [00:00<00:00, 47603\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4807\u001b[A\n",
      "Simulating N-1 Contingencies:  85%|██████▊ | 8454/10000 [14:44<02:02, 12.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   8%| | 1047/12392 [00:00<00:01, 6840.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  47%|▍| 5825/12392 [00:00<00:00, 26601\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3189\u001b[A\n",
      "Simulating N-1 Contingencies:  85%|██████▊ | 8459/10000 [14:45<02:09, 11.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4754/12392 [00:00<00:00, 47532\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4826\u001b[A\n",
      "Simulating N-1 Contingencies:  85%|██████▊ | 8461/10000 [14:45<02:23, 10.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  14%|▏| 1745/12392 [00:00<00:01, 10321\u001b[A\n",
      "Converting scenarios to PyG Data objects:  52%|▌| 6489/12392 [00:00<00:00, 27320\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3104\u001b[A\n",
      "Simulating N-1 Contingencies:  85%|██████▊ | 8463/10000 [14:45<02:58,  8.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4681/12392 [00:00<00:00, 46808\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4785\u001b[A\n",
      "Simulating N-1 Contingencies:  85%|██████▊ | 8470/10000 [14:46<02:11, 11.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  19%|▏| 2352/12392 [00:00<00:00, 12814\u001b[A\n",
      "Converting scenarios to PyG Data objects:  57%|▌| 7084/12392 [00:00<00:00, 27914\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3138\u001b[A\n",
      "Simulating N-1 Contingencies:  85%|██████▊ | 8472/10000 [14:46<02:44,  9.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4783/12392 [00:00<00:00, 47823\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4820\u001b[A\n",
      "Simulating N-1 Contingencies:  85%|██████▊ | 8473/10000 [14:46<03:12,  7.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  27%|▎| 3311/12392 [00:00<00:00, 16327\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3175\u001b[A\n",
      "Simulating N-1 Contingencies:  85%|██████▊ | 8478/10000 [14:47<02:50,  8.90it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4803/12392 [00:00<00:00, 48023\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4804\u001b[A\n",
      "Simulating N-1 Contingencies:  85%|██████▊ | 8486/10000 [14:47<02:01, 12.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  30%|▎| 3746/12392 [00:00<00:00, 17813\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3192\u001b[A\n",
      "Simulating N-1 Contingencies:  85%|██████▊ | 8490/10000 [14:48<02:14, 11.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4894/12392 [00:00<00:00, 48929\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4935\u001b[A\n",
      "Simulating N-1 Contingencies:  85%|██████▊ | 8493/10000 [14:48<02:18, 10.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4798/12392 [00:00<00:00, 47969\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3160\u001b[A\n",
      "Simulating N-1 Contingencies:  85%|██████▊ | 8495/10000 [14:48<02:50,  8.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4783/12392 [00:00<00:00, 47819\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4829\u001b[A\n",
      "Simulating N-1 Contingencies:  85%|██████▊ | 8496/10000 [14:49<03:18,  7.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4772/12392 [00:00<00:00, 47714\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3170\u001b[A\n",
      "Simulating N-1 Contingencies:  85%|██████▊ | 8498/10000 [14:49<03:47,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4676/12392 [00:00<00:00, 46752\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4778\u001b[A\n",
      "Simulating N-1 Contingencies:  85%|██████▊ | 8499/10000 [14:49<04:17,  5.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4760/12392 [00:00<00:00, 47590\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3013\u001b[A\n",
      "Simulating N-1 Contingencies:  85%|██████▊ | 8501/10000 [14:50<04:41,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4640/12392 [00:00<00:00, 46389\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4787\u001b[A\n",
      "Simulating N-1 Contingencies:  85%|██████▊ | 8502/10000 [14:50<05:06,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4778/12392 [00:00<00:00, 47770\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3116\u001b[A\n",
      "Simulating N-1 Contingencies:  85%|██████▊ | 8506/10000 [14:51<04:00,  6.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4773/12392 [00:00<00:00, 47719\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4810\u001b[A\n",
      "Simulating N-1 Contingencies:  85%|██████▊ | 8507/10000 [14:51<04:27,  5.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4807/12392 [00:00<00:00, 48063\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4840\u001b[A\n",
      "Simulating N-1 Contingencies:  85%|██████▊ | 8511/10000 [14:51<03:19,  7.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  15%|▏| 1917/12392 [00:00<00:00, 10969\u001b[A\n",
      "Converting scenarios to PyG Data objects:  54%|▌| 6711/12392 [00:00<00:00, 27596\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3155\u001b[A\n",
      "Simulating N-1 Contingencies:  85%|██████▊ | 8514/10000 [14:52<03:26,  7.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4763/12392 [00:00<00:00, 47623\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4816\u001b[A\n",
      "Simulating N-1 Contingencies:  85%|██████▊ | 8515/10000 [14:52<03:55,  6.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  25%|▏| 3048/12392 [00:00<00:00, 15484\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3185\u001b[A\n",
      "Simulating N-1 Contingencies:  85%|██████▊ | 8518/10000 [14:52<03:49,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4790/12392 [00:00<00:00, 47882\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4821\u001b[A\n",
      "Simulating N-1 Contingencies:  85%|██████▊ | 8519/10000 [14:53<04:18,  5.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4616/12392 [00:00<00:00, 20012\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3180\u001b[A\n",
      "Simulating N-1 Contingencies:  85%|██████▊ | 8523/10000 [14:53<03:36,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4863/12392 [00:00<00:00, 48624\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4858\u001b[A\n",
      "Simulating N-1 Contingencies:  85%|██████▊ | 8524/10000 [14:53<04:04,  6.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  36%|▎| 4465/12392 [00:00<00:00, 44641\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3122\u001b[A\n",
      "Simulating N-1 Contingencies:  85%|██████▊ | 8534/10000 [14:54<01:52, 13.03it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4795/12392 [00:00<00:00, 47943\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4712\u001b[A\n",
      "Simulating N-1 Contingencies:  85%|██████▊ | 8539/10000 [14:54<01:47, 13.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4808/12392 [00:00<00:00, 48071\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3094\u001b[A\n",
      "Simulating N-1 Contingencies:  85%|██████▊ | 8542/10000 [14:55<02:14, 10.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4833/12392 [00:00<00:00, 48320\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4896\u001b[A\n",
      "Simulating N-1 Contingencies:  85%|██████▊ | 8544/10000 [14:55<02:28,  9.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4805/12392 [00:00<00:00, 48038\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3165\u001b[A\n",
      "Simulating N-1 Contingencies:  85%|██████▊ | 8547/10000 [14:56<02:47,  8.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4876/12392 [00:00<00:00, 48750\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4854\u001b[A\n",
      "Simulating N-1 Contingencies:  85%|██████▊ | 8549/10000 [14:56<02:56,  8.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4725/12392 [00:00<00:00, 47246\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3136\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4739/12392 [00:00<00:00, 47383\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4814\u001b[A\n",
      "Simulating N-1 Contingencies:  86%|██████▊ | 8551/10000 [14:57<04:14,  5.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4786/12392 [00:00<00:00, 47856\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4823\u001b[A\n",
      "Simulating N-1 Contingencies:  86%|██████▊ | 8552/10000 [14:57<04:36,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4724/12392 [00:00<00:00, 47233\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4805\u001b[A\n",
      "Simulating N-1 Contingencies:  86%|██████▊ | 8554/10000 [14:57<04:45,  5.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4752/12392 [00:00<00:00, 47510\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4829\u001b[A\n",
      "Simulating N-1 Contingencies:  86%|██████▊ | 8558/10000 [14:58<03:49,  6.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4759/12392 [00:00<00:00, 47583\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4818\u001b[A\n",
      "Simulating N-1 Contingencies:  86%|██████▊ | 8561/10000 [14:58<03:16,  7.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4790/12392 [00:00<00:00, 47682\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3144\u001b[A\n",
      "Simulating N-1 Contingencies:  86%|██████▊ | 8567/10000 [14:58<02:33,  9.32it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:  86%|██████▊ | 8575/10000 [14:59<01:25, 16.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4790/12392 [00:00<00:00, 47777\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4830\u001b[A\n",
      "Simulating N-1 Contingencies:  86%|██████▊ | 8578/10000 [14:59<01:38, 14.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4755/12392 [00:00<00:00, 47545\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4829\u001b[A\n",
      "Simulating N-1 Contingencies:  86%|██████▊ | 8581/10000 [14:59<01:49, 12.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   8%| | 960/12392 [00:00<00:01, 6192.5\u001b[A\n",
      "Converting scenarios to PyG Data objects:  46%|▍| 5742/12392 [00:00<00:00, 26153\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3155\u001b[A\n",
      "Simulating N-1 Contingencies:  86%|██████▊ | 8583/10000 [15:00<02:25,  9.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4739/12392 [00:00<00:00, 47385\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4829\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  18%|▏| 2267/12392 [00:00<00:00, 12462\u001b[A\n",
      "Converting scenarios to PyG Data objects:  56%|▌| 6958/12392 [00:00<00:00, 27613\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3117\u001b[A\n",
      "Simulating N-1 Contingencies:  86%|██████▊ | 8585/10000 [15:00<03:38,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4813/12392 [00:00<00:00, 48120\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4864\u001b[A\n",
      "Simulating N-1 Contingencies:  86%|██████▊ | 8587/10000 [15:01<03:36,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  21%|▏| 2615/12392 [00:00<00:00, 13948\u001b[A\n",
      "Converting scenarios to PyG Data objects:  60%|▌| 7453/12392 [00:00<00:00, 28837\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3183\u001b[A\n",
      "Simulating N-1 Contingencies:  86%|██████▊ | 8592/10000 [15:01<02:57,  7.91it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:  86%|██████▉ | 8600/10000 [15:01<01:37, 14.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4790/12392 [00:00<00:00, 47890\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4830\u001b[A\n",
      "Simulating N-1 Contingencies:  86%|██████▉ | 8603/10000 [15:02<01:46, 13.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  16%|▏| 2006/12392 [00:00<00:00, 11526\u001b[A\n",
      "Converting scenarios to PyG Data objects:  55%|▌| 6844/12392 [00:00<00:00, 28138\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3184\u001b[A\n",
      "Simulating N-1 Contingencies:  86%|██████▉ | 8606/10000 [15:02<02:10, 10.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  32%|▎| 3980/12392 [00:00<00:00, 39793\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4508\u001b[A\n",
      "Simulating N-1 Contingencies:  86%|██████▉ | 8611/10000 [15:02<01:58, 11.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  14%|▏| 1742/12392 [00:00<00:01, 10614\u001b[A\n",
      "Converting scenarios to PyG Data objects:  53%|▌| 6535/12392 [00:00<00:00, 27977\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3217\u001b[A\n",
      "Simulating N-1 Contingencies:  86%|██████▉ | 8613/10000 [15:03<02:28,  9.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4691/12392 [00:00<00:00, 46900\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4769\u001b[A\n",
      "Simulating N-1 Contingencies:  86%|██████▉ | 8615/10000 [15:03<02:40,  8.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  22%|▏| 2700/12392 [00:00<00:00, 14055\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3171\u001b[A\n",
      "Simulating N-1 Contingencies:  86%|██████▉ | 8618/10000 [15:04<02:53,  7.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4791/12392 [00:00<00:00, 47905\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4831\u001b[A\n",
      "Simulating N-1 Contingencies:  86%|██████▉ | 8619/10000 [15:04<03:19,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  25%|▏| 3050/12392 [00:00<00:00, 15393\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3136\u001b[A\n",
      "Simulating N-1 Contingencies:  86%|██████▉ | 8625/10000 [15:04<02:34,  8.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4693/12392 [00:00<00:00, 46913\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4772\u001b[A\n",
      "Simulating N-1 Contingencies:  86%|██████▉ | 8628/10000 [15:05<02:31,  9.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  26%|▎| 3224/12392 [00:00<00:00, 16044\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3173\u001b[A\n",
      "Simulating N-1 Contingencies:  86%|██████▉ | 8634/10000 [15:05<02:12, 10.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4798/12392 [00:00<00:00, 47971\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4814\u001b[A\n",
      "Simulating N-1 Contingencies:  86%|██████▉ | 8639/10000 [15:05<01:58, 11.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  34%|▎| 4181/12392 [00:00<00:00, 18881\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3166\u001b[A\n",
      "Simulating N-1 Contingencies:  86%|██████▉ | 8641/10000 [15:06<02:27,  9.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4763/12392 [00:00<00:00, 47622\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4806\u001b[A\n",
      "Simulating N-1 Contingencies:  86%|██████▉ | 8644/10000 [15:06<02:25,  9.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4780/12392 [00:00<00:00, 47788\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3146\u001b[A\n",
      "Simulating N-1 Contingencies:  86%|██████▉ | 8646/10000 [15:07<02:54,  7.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4742/12392 [00:00<00:00, 47416\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4803\u001b[A\n",
      "Simulating N-1 Contingencies:  87%|██████▉ | 8654/10000 [15:07<01:55, 11.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4797/12392 [00:00<00:00, 47959\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3174\u001b[A\n",
      "Simulating N-1 Contingencies:  87%|██████▉ | 8656/10000 [15:07<02:22,  9.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4720/12392 [00:00<00:00, 47191\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4799\u001b[A\n",
      "Simulating N-1 Contingencies:  87%|██████▉ | 8657/10000 [15:08<02:47,  8.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4836/12392 [00:00<00:00, 48352\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3158\u001b[A\n",
      "Simulating N-1 Contingencies:  87%|██████▉ | 8659/10000 [15:08<03:14,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4790/12392 [00:00<00:00, 47758\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4821\u001b[A\n",
      "Simulating N-1 Contingencies:  87%|██████▉ | 8662/10000 [15:08<02:56,  7.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4754/12392 [00:00<00:00, 47534\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3103\u001b[A\n",
      "Simulating N-1 Contingencies:  87%|██████▉ | 8664/10000 [15:09<03:24,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4747/12392 [00:00<00:00, 47460\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4802\u001b[A\n",
      "Simulating N-1 Contingencies:  87%|██████▉ | 8670/10000 [15:09<02:19,  9.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4753/12392 [00:00<00:00, 47525\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4792\u001b[A\n",
      "Simulating N-1 Contingencies:  87%|██████▉ | 8673/10000 [15:10<02:35,  8.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4827/12392 [00:00<00:00, 48266\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4825\u001b[A\n",
      "Simulating N-1 Contingencies:  87%|██████▉ | 8675/10000 [15:10<02:46,  7.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4796/12392 [00:00<00:00, 47956\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4830\u001b[A\n",
      "Simulating N-1 Contingencies:  87%|██████▉ | 8679/10000 [15:10<02:40,  8.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4755/12392 [00:00<00:00, 47546\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4802\u001b[A\n",
      "Simulating N-1 Contingencies:  87%|██████▉ | 8682/10000 [15:11<02:31,  8.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4770/12392 [00:00<00:00, 47695\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4802\u001b[A\n",
      "Simulating N-1 Contingencies:  87%|██████▉ | 8685/10000 [15:11<02:47,  7.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4815/12392 [00:00<00:00, 48145\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4829\u001b[A\n",
      "Simulating N-1 Contingencies:  87%|██████▉ | 8687/10000 [15:11<02:55,  7.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4720/12392 [00:00<00:00, 47191\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4793\u001b[A\n",
      "Simulating N-1 Contingencies:  87%|██████▉ | 8691/10000 [15:12<02:45,  7.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4694/12392 [00:00<00:00, 46934\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4476\u001b[A\n",
      "Simulating N-1 Contingencies:  87%|██████▉ | 8700/10000 [15:12<01:17, 16.69it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4694/12392 [00:00<00:00, 46934\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3132\u001b[A\n",
      "Simulating N-1 Contingencies:  87%|██████▉ | 8703/10000 [15:13<01:48, 11.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4807/12392 [00:00<00:00, 48059\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4852\u001b[A\n",
      "Simulating N-1 Contingencies:  87%|██████▉ | 8714/10000 [15:13<01:04, 19.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4699/12392 [00:00<00:00, 46984\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4779\u001b[A\n",
      "Simulating N-1 Contingencies:  87%|██████▉ | 8721/10000 [15:14<01:04, 19.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4786/12392 [00:00<00:00, 47854\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4847\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4698/12392 [00:00<00:00, 46979\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4755\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  10%| | 1223/12392 [00:00<00:01, 7616.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  49%|▍| 6094/12392 [00:00<00:00, 26959\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3171\u001b[A\n",
      "Simulating N-1 Contingencies:  87%|██████▉ | 8725/10000 [15:15<02:15,  9.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4655/12392 [00:00<00:00, 46540\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4736\u001b[A\n",
      "Simulating N-1 Contingencies:  87%|██████▉ | 8728/10000 [15:15<02:15,  9.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  14%|▏| 1743/12392 [00:00<00:01, 10301\u001b[A\n",
      "Converting scenarios to PyG Data objects:  52%|▌| 6407/12392 [00:00<00:00, 26936\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3137\u001b[A\n",
      "Simulating N-1 Contingencies:  87%|██████▉ | 8730/10000 [15:15<02:38,  8.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4817/12392 [00:00<00:00, 48167\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4836\u001b[A\n",
      "Simulating N-1 Contingencies:  87%|██████▉ | 8737/10000 [15:16<01:55, 10.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  20%|▏| 2528/12392 [00:00<00:00, 13523\u001b[A\n",
      "Converting scenarios to PyG Data objects:  59%|▌| 7340/12392 [00:00<00:00, 28508\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3162\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4705/12392 [00:00<00:00, 47044\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4790\u001b[A\n",
      "Simulating N-1 Contingencies:  87%|██████▉ | 8739/10000 [15:17<02:46,  7.56it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  23%|▏| 2876/12392 [00:00<00:00, 14932\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3163\u001b[A\n",
      "Simulating N-1 Contingencies:  87%|██████▉ | 8745/10000 [15:17<02:20,  8.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4789/12392 [00:00<00:00, 47886\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4827\u001b[A\n",
      "Simulating N-1 Contingencies:  88%|███████ | 8755/10000 [15:17<01:24, 14.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  15%|▏| 1917/12392 [00:00<00:00, 10967\u001b[A\n",
      "Converting scenarios to PyG Data objects:  54%|▌| 6735/12392 [00:00<00:00, 27701\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3156\u001b[A\n",
      "Simulating N-1 Contingencies:  88%|███████ | 8761/10000 [15:18<01:29, 13.84it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4749/12392 [00:00<00:00, 47487\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4788\u001b[A\n",
      "Simulating N-1 Contingencies:  88%|███████ | 8766/10000 [15:18<01:27, 14.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  17%|▏| 2091/12392 [00:00<00:00, 11788\u001b[A\n",
      "Converting scenarios to PyG Data objects:  54%|▌| 6697/12392 [00:00<00:00, 27074\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3130\u001b[A\n",
      "Simulating N-1 Contingencies:  88%|███████ | 8778/10000 [15:19<01:05, 18.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4789/12392 [00:00<00:00, 47887\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4834\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  13%|▏| 1658/12392 [00:00<00:01, 9722.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  52%|▌| 6455/12392 [00:00<00:00, 27155\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3153\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4790/12392 [00:00<00:00, 47882\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4836\u001b[A\n",
      "Simulating N-1 Contingencies:  88%|███████ | 8782/10000 [15:20<01:59, 10.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  22%|▏| 2787/12392 [00:00<00:00, 14519\u001b[A\n",
      "Converting scenarios to PyG Data objects:  62%|▌| 7650/12392 [00:00<00:00, 29072\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3040\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4777/12392 [00:00<00:00, 47764\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4815\u001b[A\n",
      "Simulating N-1 Contingencies:  88%|███████ | 8785/10000 [15:21<02:34,  7.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  32%|▎| 3918/12392 [00:00<00:00, 18223\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3188\u001b[A\n",
      "Simulating N-1 Contingencies:  88%|███████ | 8788/10000 [15:21<02:39,  7.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4790/12392 [00:00<00:00, 47890\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4825\u001b[A\n",
      "Simulating N-1 Contingencies:  88%|███████ | 8790/10000 [15:21<02:42,  7.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4780/12392 [00:00<00:00, 47790\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3162\u001b[A\n",
      "Simulating N-1 Contingencies:  88%|███████ | 8792/10000 [15:22<03:02,  6.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4802/12392 [00:00<00:00, 48011\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4811\u001b[A\n",
      "Simulating N-1 Contingencies:  88%|███████ | 8794/10000 [15:22<03:01,  6.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4743/12392 [00:00<00:00, 47423\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3144\u001b[A\n",
      "Simulating N-1 Contingencies:  88%|███████ | 8796/10000 [15:22<03:20,  6.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4806/12392 [00:00<00:00, 48043\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4829\u001b[A\n",
      "Simulating N-1 Contingencies:  88%|███████ | 8798/10000 [15:23<03:14,  6.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4729/12392 [00:00<00:00, 47283\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3162\u001b[A\n",
      "Simulating N-1 Contingencies:  88%|███████ | 8800/10000 [15:23<03:31,  5.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4724/12392 [00:00<00:00, 47231\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4775\u001b[A\n",
      "Simulating N-1 Contingencies:  88%|███████ | 8821/10000 [15:24<00:50, 23.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4808/12392 [00:00<00:00, 48072\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3118\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4658/12392 [00:00<00:00, 46577\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4758\u001b[A\n",
      "Simulating N-1 Contingencies:  88%|███████ | 8826/10000 [15:24<01:25, 13.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  31%|▎| 3797/12392 [00:00<00:00, 37967\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 2997\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4790/12392 [00:00<00:00, 47898\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4814\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4717/12392 [00:00<00:00, 47164\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4778\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  16%|▏| 2006/12392 [00:00<00:00, 11452\u001b[A\n",
      "Converting scenarios to PyG Data objects:  55%|▌| 6823/12392 [00:00<00:00, 27945\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3164\u001b[A\n",
      "Simulating N-1 Contingencies:  88%|███████ | 8830/10000 [15:26<02:44,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4739/12392 [00:00<00:00, 47379\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4772\u001b[A\n",
      "Simulating N-1 Contingencies:  88%|███████ | 8833/10000 [15:26<02:35,  7.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  17%|▏| 2093/12392 [00:00<00:00, 11514\u001b[A\n",
      "Converting scenarios to PyG Data objects:  55%|▌| 6847/12392 [00:00<00:00, 27365\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3105\u001b[A\n",
      "Simulating N-1 Contingencies:  88%|███████ | 8835/10000 [15:27<02:51,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4746/12392 [00:00<00:00, 47456\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4767\u001b[A\n",
      "Simulating N-1 Contingencies:  88%|███████ | 8838/10000 [15:27<02:38,  7.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  21%|▏| 2615/12392 [00:00<00:00, 13946\u001b[A\n",
      "Converting scenarios to PyG Data objects:  60%|▌| 7389/12392 [00:00<00:00, 28557\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3157\u001b[A\n",
      "Simulating N-1 Contingencies:  88%|███████ | 8840/10000 [15:27<02:56,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4759/12392 [00:00<00:00, 47580\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4812\u001b[A\n",
      "Simulating N-1 Contingencies:  88%|███████ | 8846/10000 [15:28<02:05,  9.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  16%|▏| 2004/12392 [00:00<00:00, 11348\u001b[A\n",
      "Converting scenarios to PyG Data objects:  55%|▌| 6817/12392 [00:00<00:00, 27795\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3152\u001b[A\n",
      "Simulating N-1 Contingencies:  89%|███████ | 8851/10000 [15:28<01:59,  9.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4736/12392 [00:00<00:00, 47357\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4794\u001b[A\n",
      "Simulating N-1 Contingencies:  89%|███████ | 8856/10000 [15:29<01:45, 10.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  18%|▏| 2178/12392 [00:00<00:00, 12270\u001b[A\n",
      "Converting scenarios to PyG Data objects:  56%|▌| 6985/12392 [00:00<00:00, 28232\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3170\u001b[A\n",
      "Simulating N-1 Contingencies:  89%|███████ | 8860/10000 [15:29<01:51, 10.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4705/12392 [00:00<00:00, 47041\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4770\u001b[A\n",
      "Simulating N-1 Contingencies:  89%|███████ | 8863/10000 [15:29<01:53, 10.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  30%|▎| 3746/12392 [00:00<00:00, 17723\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3172\u001b[A\n",
      "Simulating N-1 Contingencies:  89%|███████ | 8865/10000 [15:30<02:16,  8.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4699/12392 [00:00<00:00, 46984\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4800\u001b[A\n",
      "Simulating N-1 Contingencies:  89%|███████ | 8869/10000 [15:30<02:01,  9.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  32%|▎| 3920/12392 [00:00<00:00, 17215\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3081\u001b[A\n",
      "Simulating N-1 Contingencies:  89%|███████ | 8882/10000 [15:31<01:08, 16.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4788/12392 [00:00<00:00, 47873\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4837\u001b[A\n",
      "Simulating N-1 Contingencies:  89%|███████ | 8885/10000 [15:31<01:17, 14.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  34%|▎| 4181/12392 [00:00<00:00, 19167\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3076\u001b[A\n",
      "Simulating N-1 Contingencies:  89%|███████ | 8888/10000 [15:31<01:37, 11.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4758/12392 [00:00<00:00, 47574\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4795\u001b[A\n",
      "Simulating N-1 Contingencies:  89%|███████ | 8891/10000 [15:32<01:42, 10.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4773/12392 [00:00<00:00, 47719\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3170\u001b[A\n",
      "Simulating N-1 Contingencies:  89%|███████ | 8893/10000 [15:32<02:07,  8.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4697/12392 [00:00<00:00, 46963\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4824\u001b[A\n",
      "Simulating N-1 Contingencies:  89%|███████ | 8896/10000 [15:33<02:03,  8.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4748/12392 [00:00<00:00, 47470\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3151\u001b[A\n",
      "Simulating N-1 Contingencies:  89%|███████ | 8904/10000 [15:33<01:35, 11.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4729/12392 [00:00<00:00, 47285\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4816\u001b[A\n",
      "Simulating N-1 Contingencies:  89%|███████▏| 8910/10000 [15:33<01:23, 13.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4767/12392 [00:00<00:00, 47666\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3152\u001b[A\n",
      "Simulating N-1 Contingencies:  89%|███████▏| 8912/10000 [15:34<01:45, 10.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4779/12392 [00:00<00:00, 47786\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4850\u001b[A\n",
      "Simulating N-1 Contingencies:  89%|███████▏| 8918/10000 [15:34<01:28, 12.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4788/12392 [00:00<00:00, 47870\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3128\u001b[A\n",
      "Simulating N-1 Contingencies:  89%|███████▏| 8924/10000 [15:35<01:28, 12.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4807/12392 [00:00<00:00, 48062\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4824\u001b[A\n",
      "Simulating N-1 Contingencies:  89%|███████▏| 8926/10000 [15:35<01:38, 10.93it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4784/12392 [00:00<00:00, 47836\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3124\u001b[A\n",
      "Simulating N-1 Contingencies:  89%|███████▏| 8930/10000 [15:35<01:45, 10.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4823/12392 [00:00<00:00, 48223\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4854\u001b[A\n",
      "Simulating N-1 Contingencies:  89%|███████▏| 8932/10000 [15:36<01:54,  9.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4796/12392 [00:00<00:00, 47957\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4821\u001b[A\n",
      "Simulating N-1 Contingencies:  89%|███████▏| 8938/10000 [15:36<01:31, 11.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  12%| | 1482/12392 [00:00<00:01, 8883.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  51%|▌| 6282/12392 [00:00<00:00, 26925\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3140\u001b[A\n",
      "Simulating N-1 Contingencies:  89%|███████▏| 8945/10000 [15:37<01:24, 12.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4726/12392 [00:00<00:00, 47248\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4827\u001b[A\n",
      "Simulating N-1 Contingencies:  89%|███████▏| 8947/10000 [15:37<01:34, 11.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  13%|▏| 1571/12392 [00:00<00:01, 9577.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  52%|▌| 6384/12392 [00:00<00:00, 27522\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3190\u001b[A\n",
      "Simulating N-1 Contingencies:  89%|███████▏| 8949/10000 [15:37<01:57,  8.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4773/12392 [00:00<00:00, 47728\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4823\u001b[A\n",
      "Simulating N-1 Contingencies:  90%|███████▏| 8952/10000 [15:38<01:54,  9.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  15%|▏| 1917/12392 [00:00<00:00, 11035\u001b[A\n",
      "Converting scenarios to PyG Data objects:  54%|▌| 6646/12392 [00:00<00:00, 27395\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3146\u001b[A\n",
      "Simulating N-1 Contingencies:  90%|███████▏| 8956/10000 [15:38<01:56,  8.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4782/12392 [00:00<00:00, 47812\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4835\u001b[A\n",
      "Simulating N-1 Contingencies:  90%|███████▏| 8959/10000 [15:38<01:53,  9.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  20%|▏| 2528/12392 [00:00<00:00, 13566\u001b[A\n",
      "Converting scenarios to PyG Data objects:  60%|▌| 7377/12392 [00:00<00:00, 28718\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3177\u001b[A\n",
      "Simulating N-1 Contingencies:  90%|███████▏| 8966/10000 [15:39<01:34, 10.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4794/12392 [00:00<00:00, 47934\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4841\u001b[A\n",
      "Simulating N-1 Contingencies:  90%|███████▏| 8968/10000 [15:39<01:43,  9.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  20%|▏| 2439/12392 [00:00<00:00, 13141\u001b[A\n",
      "Converting scenarios to PyG Data objects:  59%|▌| 7274/12392 [00:00<00:00, 28452\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3156\u001b[A\n",
      "Simulating N-1 Contingencies:  90%|███████▏| 8972/10000 [15:40<01:48,  9.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4815/12392 [00:00<00:00, 48142\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4841\u001b[A\n",
      "Simulating N-1 Contingencies:  90%|███████▏| 8973/10000 [15:40<02:06,  8.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  25%|▎| 3137/12392 [00:00<00:00, 15764\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3205\u001b[A\n",
      "Simulating N-1 Contingencies:  90%|███████▏| 8975/10000 [15:40<02:27,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4743/12392 [00:00<00:00, 47425\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4784\u001b[A\n",
      "Simulating N-1 Contingencies:  90%|███████▏| 8980/10000 [15:41<01:51,  9.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  28%|▎| 3485/12392 [00:00<00:00, 16929\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3187\u001b[A\n",
      "Simulating N-1 Contingencies:  90%|███████▏| 8982/10000 [15:41<02:13,  7.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4733/12392 [00:00<00:00, 47320\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4811\u001b[A\n",
      "Simulating N-1 Contingencies:  90%|███████▏| 8983/10000 [15:41<02:33,  6.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4616/12392 [00:00<00:00, 20200\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3049\u001b[A\n",
      "Simulating N-1 Contingencies:  90%|███████▏| 8986/10000 [15:42<02:33,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4763/12392 [00:00<00:00, 47624\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4780\u001b[A\n",
      "Simulating N-1 Contingencies:  90%|███████▏| 8989/10000 [15:42<02:17,  7.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4756/12392 [00:00<00:00, 47553\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3165\u001b[A\n",
      "Simulating N-1 Contingencies:  90%|███████▏| 8992/10000 [15:43<02:21,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4779/12392 [00:00<00:00, 47785\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4826\u001b[A\n",
      "Simulating N-1 Contingencies:  90%|███████▏| 8996/10000 [15:43<01:58,  8.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4824/12392 [00:00<00:00, 48232\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3181\u001b[A\n",
      "Simulating N-1 Contingencies:  90%|███████▏| 8998/10000 [15:43<02:18,  7.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4851/12392 [00:00<00:00, 48506\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4872\u001b[A\n",
      "Simulating N-1 Contingencies:  90%|███████▏| 9000/10000 [15:44<02:20,  7.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4775/12392 [00:00<00:00, 47744\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3184\u001b[A\n",
      "Simulating N-1 Contingencies:  90%|███████▏| 9007/10000 [15:44<01:42,  9.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4766/12392 [00:00<00:00, 47644\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4811\u001b[A\n",
      "Simulating N-1 Contingencies:  90%|███████▏| 9012/10000 [15:44<01:29, 11.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4807/12392 [00:00<00:00, 48064\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3137\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4803/12392 [00:00<00:00, 48026\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4849\u001b[A\n",
      "Simulating N-1 Contingencies:  90%|███████▏| 9014/10000 [15:45<02:12,  7.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4714/12392 [00:00<00:00, 47135\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3125\u001b[A\n",
      "Simulating N-1 Contingencies:  90%|███████▏| 9019/10000 [15:46<01:57,  8.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4746/12392 [00:00<00:00, 47455\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4810\u001b[A\n",
      "Simulating N-1 Contingencies:  90%|███████▏| 9025/10000 [15:46<01:33, 10.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 6595\u001b[A\n",
      "Simulating N-1 Contingencies:  90%|███████▏| 9028/10000 [15:46<01:29, 10.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   7%| | 873/12392 [00:00<00:02, 5648.9\u001b[A\n",
      "Converting scenarios to PyG Data objects:  45%|▍| 5561/12392 [00:00<00:00, 25452\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3131\u001b[A\n",
      "Simulating N-1 Contingencies:  90%|███████▏| 9031/10000 [15:47<01:42,  9.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4881/12392 [00:00<00:00, 48798\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4919\u001b[A\n",
      "Simulating N-1 Contingencies:  90%|███████▏| 9033/10000 [15:47<01:49,  8.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   8%| | 959/12392 [00:00<00:01, 6274.4\u001b[A\n",
      "Converting scenarios to PyG Data objects:  46%|▍| 5749/12392 [00:00<00:00, 26382\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3189\u001b[A\n",
      "Simulating N-1 Contingencies:  90%|███████▏| 9035/10000 [15:47<02:09,  7.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4827/12392 [00:00<00:00, 48265\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4879\u001b[A\n",
      "Simulating N-1 Contingencies:  90%|███████▏| 9036/10000 [15:48<02:28,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  18%|▏| 2267/12392 [00:00<00:00, 12541\u001b[A\n",
      "Converting scenarios to PyG Data objects:  58%|▌| 7159/12392 [00:00<00:00, 28598\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3188\u001b[A\n",
      "Simulating N-1 Contingencies:  90%|███████▏| 9045/10000 [15:48<01:15, 12.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4845/12392 [00:00<00:00, 48439\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4887\u001b[A\n",
      "Simulating N-1 Contingencies:  90%|███████▏| 9048/10000 [15:49<01:20, 11.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  12%| | 1482/12392 [00:00<00:01, 9044.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  51%|▌| 6340/12392 [00:00<00:00, 27458\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3178\u001b[A\n",
      "Simulating N-1 Contingencies:  91%|███████▏| 9051/10000 [15:49<01:36,  9.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4757/12392 [00:00<00:00, 47560\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4789\u001b[A\n",
      "Simulating N-1 Contingencies:  91%|███████▏| 9054/10000 [15:49<01:36,  9.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  13%|▏| 1571/12392 [00:00<00:01, 9388.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  52%|▌| 6395/12392 [00:00<00:00, 27278\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3166\u001b[A\n",
      "Simulating N-1 Contingencies:  91%|███████▏| 9056/10000 [15:50<01:59,  7.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4759/12392 [00:00<00:00, 47581\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4807\u001b[A\n",
      "Simulating N-1 Contingencies:  91%|███████▏| 9059/10000 [15:50<01:52,  8.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  17%|▏| 2093/12392 [00:00<00:00, 11925\u001b[A\n",
      "Converting scenarios to PyG Data objects:  56%|▌| 6904/12392 [00:00<00:00, 28160\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 2967\u001b[A\n",
      "Simulating N-1 Contingencies:  91%|███████▏| 9061/10000 [15:50<02:15,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4806/12392 [00:00<00:00, 48055\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4821\u001b[A\n",
      "Simulating N-1 Contingencies:  91%|███████▎| 9066/10000 [15:51<01:42,  9.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  11%| | 1310/12392 [00:00<00:01, 8014.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  49%|▍| 6104/12392 [00:00<00:00, 26633\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3133\u001b[A\n",
      "Simulating N-1 Contingencies:  91%|███████▎| 9074/10000 [15:51<01:20, 11.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4766/12392 [00:00<00:00, 47652\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4839\u001b[A\n",
      "Simulating N-1 Contingencies:  91%|███████▎| 9079/10000 [15:52<01:14, 12.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  18%|▏| 2267/12392 [00:00<00:00, 12371\u001b[A\n",
      "Converting scenarios to PyG Data objects:  57%|▌| 7026/12392 [00:00<00:00, 27797\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3134\u001b[A\n",
      "Simulating N-1 Contingencies:  91%|███████▎| 9081/10000 [15:52<01:33,  9.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4726/12392 [00:00<00:00, 47252\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4784\u001b[A\n",
      "Simulating N-1 Contingencies:  91%|███████▎| 9089/10000 [15:53<01:09, 13.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  15%|▏| 1832/12392 [00:00<00:00, 10723\u001b[A\n",
      "Converting scenarios to PyG Data objects:  53%|▌| 6553/12392 [00:00<00:00, 27337\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3147\u001b[A\n",
      "Simulating N-1 Contingencies:  91%|███████▎| 9091/10000 [15:53<01:27, 10.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4754/12392 [00:00<00:00, 47531\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4818\u001b[A\n",
      "Simulating N-1 Contingencies:  91%|███████▎| 9093/10000 [15:53<01:35,  9.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  24%|▏| 2963/12392 [00:00<00:00, 15411\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3173\u001b[A\n",
      "Simulating N-1 Contingencies:  91%|███████▎| 9094/10000 [15:54<02:05,  7.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4749/12392 [00:00<00:00, 47479\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4818\u001b[A\n",
      "Simulating N-1 Contingencies:  91%|███████▎| 9102/10000 [15:54<01:19, 11.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  25%|▎| 3137/12392 [00:00<00:00, 15750\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3180\u001b[A\n",
      "Simulating N-1 Contingencies:  91%|███████▎| 9104/10000 [15:54<01:37,  9.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4796/12392 [00:00<00:00, 47953\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4851\u001b[A\n",
      "Simulating N-1 Contingencies:  91%|███████▎| 9108/10000 [15:55<01:29,  9.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  33%|▎| 4094/12392 [00:00<00:00, 18734\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3195\u001b[A\n",
      "Simulating N-1 Contingencies:  91%|███████▎| 9110/10000 [15:55<01:48,  8.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4767/12392 [00:00<00:00, 47662\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4839\u001b[A\n",
      "Simulating N-1 Contingencies:  91%|███████▎| 9113/10000 [15:56<01:43,  8.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4716/12392 [00:00<00:00, 47152\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3164\u001b[A\n",
      "Simulating N-1 Contingencies:  91%|███████▎| 9116/10000 [15:56<01:50,  7.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4834/12392 [00:00<00:00, 48329\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4856\u001b[A\n",
      "Simulating N-1 Contingencies:  91%|███████▎| 9117/10000 [15:56<02:07,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4722/12392 [00:00<00:00, 47216\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3167\u001b[A\n",
      "Simulating N-1 Contingencies:  91%|███████▎| 9122/10000 [15:57<01:46,  8.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4675/12392 [00:00<00:00, 46747\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4756\u001b[A\n",
      "Simulating N-1 Contingencies:  91%|███████▎| 9124/10000 [15:57<01:51,  7.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4801/12392 [00:00<00:00, 48006\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3169\u001b[A\n",
      "Simulating N-1 Contingencies:  91%|███████▎| 9128/10000 [15:57<01:46,  8.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4784/12392 [00:00<00:00, 47830\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4819\u001b[A\n",
      "Simulating N-1 Contingencies:  91%|███████▎| 9130/10000 [15:58<01:51,  7.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4815/12392 [00:00<00:00, 48147\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3159\u001b[A\n",
      "Simulating N-1 Contingencies:  91%|███████▎| 9131/10000 [15:58<02:24,  6.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4773/12392 [00:00<00:00, 47719\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4817\u001b[A\n",
      "Simulating N-1 Contingencies:  91%|███████▎| 9132/10000 [15:58<02:40,  5.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4637/12392 [00:00<00:00, 46354\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4750\u001b[A\n",
      "Simulating N-1 Contingencies:  92%|███████▎| 9154/10000 [15:59<00:36, 23.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4722/12392 [00:00<00:00, 47215\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4815\u001b[A\n",
      "Simulating N-1 Contingencies:  92%|███████▎| 9163/10000 [16:00<00:35, 23.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4734/12392 [00:00<00:00, 47334\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3122\u001b[A\n",
      "Simulating N-1 Contingencies:  92%|███████▎| 9167/10000 [16:00<00:48, 17.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4755/12392 [00:00<00:00, 47547\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4831\u001b[A\n",
      "Simulating N-1 Contingencies:  92%|███████▎| 9171/10000 [16:00<00:53, 15.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4773/12392 [00:00<00:00, 47717\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4809\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   6%| | 699/12392 [00:00<00:02, 4728.9\u001b[A\n",
      "Converting scenarios to PyG Data objects:  45%|▍| 5535/12392 [00:00<00:00, 26170\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3185\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4741/12392 [00:00<00:00, 47400\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4795\u001b[A\n",
      "Simulating N-1 Contingencies:  92%|███████▎| 9174/10000 [16:01<01:37,  8.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  15%|▏| 1830/12392 [00:00<00:01, 10503\u001b[A\n",
      "Converting scenarios to PyG Data objects:  54%|▌| 6700/12392 [00:00<00:00, 27709\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3162\u001b[A\n",
      "Simulating N-1 Contingencies:  92%|███████▎| 9177/10000 [16:02<01:42,  8.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4730/12392 [00:00<00:00, 47289\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4799\u001b[A\n",
      "Simulating N-1 Contingencies:  92%|███████▎| 9179/10000 [16:02<01:46,  7.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  19%|▏| 2352/12392 [00:00<00:00, 12933\u001b[A\n",
      "Converting scenarios to PyG Data objects:  58%|▌| 7128/12392 [00:00<00:00, 28251\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3162\u001b[A\n",
      "Simulating N-1 Contingencies:  92%|███████▎| 9182/10000 [16:03<01:50,  7.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4795/12392 [00:00<00:00, 47942\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4809\u001b[A\n",
      "Simulating N-1 Contingencies:  92%|███████▎| 9185/10000 [16:03<01:42,  7.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  27%|▎| 3309/12392 [00:00<00:00, 16302\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3191\u001b[A\n",
      "Simulating N-1 Contingencies:  92%|███████▎| 9188/10000 [16:03<01:47,  7.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4811/12392 [00:00<00:00, 48103\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4864\u001b[A\n",
      "Simulating N-1 Contingencies:  92%|███████▎| 9190/10000 [16:04<01:49,  7.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4793/12392 [00:00<00:00, 47919\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3175\u001b[A\n",
      "Simulating N-1 Contingencies:  92%|███████▎| 9199/10000 [16:04<01:01, 13.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4693/12392 [00:00<00:00, 46928\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4771\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4682/12392 [00:00<00:00, 46812\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3138\u001b[A\n",
      "/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:  92%|███████▎| 9202/10000 [16:05<01:34,  8.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4743/12392 [00:00<00:00, 47426\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4852\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4760/12392 [00:00<00:00, 47594\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3178\u001b[A\n",
      "Simulating N-1 Contingencies:  92%|███████▎| 9205/10000 [16:06<01:58,  6.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4811/12392 [00:00<00:00, 48101\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4862\u001b[A\n",
      "Simulating N-1 Contingencies:  92%|███████▎| 9207/10000 [16:06<01:57,  6.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4700/12392 [00:00<00:00, 46990\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3164\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4805/12392 [00:00<00:00, 48047\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4854\u001b[A\n",
      "Simulating N-1 Contingencies:  92%|███████▎| 9209/10000 [16:07<02:32,  5.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4780/12392 [00:00<00:00, 47794\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3123\u001b[A\n",
      "Simulating N-1 Contingencies:  92%|███████▎| 9216/10000 [16:07<01:41,  7.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4763/12392 [00:00<00:00, 47624\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4828\u001b[A\n",
      "Simulating N-1 Contingencies:  92%|███████▍| 9231/10000 [16:08<00:47, 16.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4770/12392 [00:00<00:00, 47696\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4812\u001b[A\n",
      "Simulating N-1 Contingencies:  92%|███████▍| 9235/10000 [16:08<00:56, 13.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4805/12392 [00:00<00:00, 48041\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4841\u001b[A\n",
      "Simulating N-1 Contingencies:  92%|███████▍| 9239/10000 [16:08<00:57, 13.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4682/12392 [00:00<00:00, 46813\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3112\u001b[A\n",
      "Simulating N-1 Contingencies:  92%|███████▍| 9242/10000 [16:09<01:08, 10.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4782/12392 [00:00<00:00, 47815\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4825\u001b[A\n",
      "/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:  92%|███████▍| 9244/10000 [16:09<01:15,  9.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4708/12392 [00:00<00:00, 47075\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4806\u001b[A\n",
      "Simulating N-1 Contingencies:  93%|███████▍| 9251/10000 [16:09<00:58, 12.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  20%|▏| 2441/12392 [00:00<00:00, 13225\u001b[A\n",
      "Converting scenarios to PyG Data objects:  58%|▌| 7231/12392 [00:00<00:00, 28351\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3158\u001b[A\n",
      "Simulating N-1 Contingencies:  93%|███████▍| 9253/10000 [16:10<01:14, 10.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4781/12392 [00:00<00:00, 47805\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4812\u001b[A\n",
      "Simulating N-1 Contingencies:  93%|███████▍| 9257/10000 [16:10<01:09, 10.62it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  18%|▏| 2267/12392 [00:00<00:00, 12603\u001b[A\n",
      "Converting scenarios to PyG Data objects:  57%|▌| 7051/12392 [00:00<00:00, 28199\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3170\u001b[A\n",
      "Simulating N-1 Contingencies:  93%|███████▍| 9265/10000 [16:11<00:58, 12.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4766/12392 [00:00<00:00, 47652\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4827\u001b[A\n",
      "Simulating N-1 Contingencies:  93%|███████▍| 9273/10000 [16:11<00:48, 15.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  12%| | 1482/12392 [00:00<00:01, 9142.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  50%|▍| 6157/12392 [00:00<00:00, 26759\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3151\u001b[A\n",
      "Simulating N-1 Contingencies:  93%|███████▍| 9279/10000 [16:12<00:51, 14.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4790/12392 [00:00<00:00, 47894\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4786\u001b[A\n",
      "Simulating N-1 Contingencies:  93%|███████▍| 9282/10000 [16:12<00:55, 13.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  16%|▏| 2006/12392 [00:00<00:00, 11430\u001b[A\n",
      "Converting scenarios to PyG Data objects:  55%|▌| 6831/12392 [00:00<00:00, 27950\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3174\u001b[A\n",
      "Simulating N-1 Contingencies:  93%|███████▍| 9284/10000 [16:12<01:09, 10.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4785/12392 [00:00<00:00, 47846\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4798\u001b[A\n",
      "Simulating N-1 Contingencies:  93%|███████▍| 9286/10000 [16:13<01:15,  9.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  14%|▏| 1743/12392 [00:00<00:01, 10149\u001b[A\n",
      "Converting scenarios to PyG Data objects:  53%|▌| 6582/12392 [00:00<00:00, 27514\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3150\u001b[A\n",
      "Simulating N-1 Contingencies:  93%|███████▍| 9292/10000 [16:13<01:07, 10.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4801/12392 [00:00<00:00, 48004\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4827\u001b[A\n",
      "Simulating N-1 Contingencies:  93%|███████▍| 9299/10000 [16:13<00:54, 12.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  15%|▏| 1919/12392 [00:00<00:00, 10981\u001b[A\n",
      "Converting scenarios to PyG Data objects:  54%|▌| 6688/12392 [00:00<00:00, 27489\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3152\u001b[A\n",
      "Simulating N-1 Contingencies:  93%|███████▍| 9301/10000 [16:14<01:08, 10.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4813/12392 [00:00<00:00, 48122\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4874\u001b[A\n",
      "Simulating N-1 Contingencies:  93%|███████▍| 9303/10000 [16:14<01:14,  9.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  21%|▏| 2615/12392 [00:00<00:00, 14028\u001b[A\n",
      "Converting scenarios to PyG Data objects:  60%|▌| 7486/12392 [00:00<00:00, 29075\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3187\u001b[A\n",
      "Simulating N-1 Contingencies:  93%|███████▍| 9304/10000 [16:15<01:37,  7.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4813/12392 [00:00<00:00, 48122\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4838\u001b[A\n",
      "Simulating N-1 Contingencies:  93%|███████▍| 9305/10000 [16:15<01:50,  6.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  25%|▎| 3137/12392 [00:00<00:00, 15803\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3187\u001b[A\n",
      "Simulating N-1 Contingencies:  93%|███████▍| 9309/10000 [16:15<01:37,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4774/12392 [00:00<00:00, 47731\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4817\u001b[A\n",
      "Simulating N-1 Contingencies:  93%|███████▍| 9326/10000 [16:16<00:29, 22.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  13%|▏| 1657/12392 [00:00<00:01, 9708.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  52%|▌| 6472/12392 [00:00<00:00, 27223\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3150\u001b[A\n",
      "Simulating N-1 Contingencies:  93%|███████▍| 9331/10000 [16:16<00:39, 17.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4799/12392 [00:00<00:00, 47985\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4827\u001b[A\n",
      "Simulating N-1 Contingencies:  93%|███████▍| 9335/10000 [16:17<00:42, 15.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  11%| | 1395/12392 [00:00<00:01, 8600.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  50%|▌| 6196/12392 [00:00<00:00, 27053\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3172\u001b[A\n",
      "Simulating N-1 Contingencies:  93%|███████▍| 9339/10000 [16:17<00:51, 12.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4677/12392 [00:00<00:00, 46763\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4797\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  17%|▏| 2093/12392 [00:00<00:00, 11847\u001b[A\n",
      "Converting scenarios to PyG Data objects:  56%|▌| 6914/12392 [00:00<00:00, 28103\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3173\u001b[A\n",
      "Simulating N-1 Contingencies:  93%|███████▍| 9342/10000 [16:18<01:14,  8.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4762/12392 [00:00<00:00, 47613\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4820\u001b[A\n",
      "Simulating N-1 Contingencies:  93%|███████▍| 9348/10000 [16:18<00:59, 10.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  20%|▏| 2440/12392 [00:00<00:00, 13271\u001b[A\n",
      "Converting scenarios to PyG Data objects:  57%|▌| 7066/12392 [00:00<00:00, 27694\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3133\u001b[A\n",
      "Simulating N-1 Contingencies:  94%|███████▍| 9350/10000 [16:19<01:12,  8.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4737/12392 [00:00<00:00, 47360\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4779\u001b[A\n",
      "Simulating N-1 Contingencies:  94%|███████▍| 9352/10000 [16:19<01:16,  8.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  29%|▎| 3572/12392 [00:00<00:00, 17116\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3170\u001b[A\n",
      "Simulating N-1 Contingencies:  94%|███████▍| 9354/10000 [16:19<01:29,  7.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4744/12392 [00:00<00:00, 47435\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4787\u001b[A\n",
      "Simulating N-1 Contingencies:  94%|███████▍| 9356/10000 [16:20<01:31,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  30%|▎| 3746/12392 [00:00<00:00, 17693\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3124\u001b[A\n",
      "Simulating N-1 Contingencies:  94%|███████▍| 9362/10000 [16:20<01:11,  8.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4673/12392 [00:00<00:00, 46721\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4776\u001b[A\n",
      "Simulating N-1 Contingencies:  94%|███████▍| 9365/10000 [16:20<01:09,  9.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  34%|▎| 4268/12392 [00:00<00:00, 19347\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3177\u001b[A\n",
      "Simulating N-1 Contingencies:  94%|███████▍| 9367/10000 [16:21<01:22,  7.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4748/12392 [00:00<00:00, 47472\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4781\u001b[A\n",
      "Simulating N-1 Contingencies:  94%|███████▍| 9372/10000 [16:21<01:05,  9.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4779/12392 [00:00<00:00, 47779\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3170\u001b[A\n",
      "Simulating N-1 Contingencies:  94%|███████▍| 9374/10000 [16:22<01:18,  7.93it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4747/12392 [00:00<00:00, 47462\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4829\u001b[A\n",
      "Simulating N-1 Contingencies:  94%|███████▌| 9380/10000 [16:22<00:59, 10.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4800/12392 [00:00<00:00, 47992\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3163\u001b[A\n",
      "Simulating N-1 Contingencies:  94%|███████▌| 9383/10000 [16:22<01:06,  9.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4757/12392 [00:00<00:00, 47559\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4807\u001b[A\n",
      "Simulating N-1 Contingencies:  94%|███████▌| 9388/10000 [16:23<00:57, 10.70it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4772/12392 [00:00<00:00, 47708\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3150\u001b[A\n",
      "Simulating N-1 Contingencies:  94%|███████▌| 9390/10000 [16:23<01:10,  8.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4776/12392 [00:00<00:00, 47751\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4830\u001b[A\n",
      "Simulating N-1 Contingencies:  94%|███████▌| 9391/10000 [16:23<01:21,  7.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4758/12392 [00:00<00:00, 47573\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3115\u001b[A\n",
      "Simulating N-1 Contingencies:  94%|███████▌| 9392/10000 [16:24<01:45,  5.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4755/12392 [00:00<00:00, 47542\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4827\u001b[A\n",
      "Simulating N-1 Contingencies:  94%|███████▌| 9394/10000 [16:24<01:40,  6.01it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4808/12392 [00:00<00:00, 48072\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4835\u001b[A\n",
      "Simulating N-1 Contingencies:  94%|███████▌| 9399/10000 [16:25<01:10,  8.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   9%| | 1136/12392 [00:00<00:01, 7267.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  48%|▍| 5953/12392 [00:00<00:00, 26797\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3188\u001b[A\n",
      "Simulating N-1 Contingencies:  94%|███████▌| 9400/10000 [16:25<01:32,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4765/12392 [00:00<00:00, 47647\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4799\u001b[A\n",
      "Simulating N-1 Contingencies:  94%|███████▌| 9401/10000 [16:25<01:44,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   8%| | 1047/12392 [00:00<00:01, 6531.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  47%|▍| 5853/12392 [00:00<00:00, 26100\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3133\u001b[A\n",
      "Simulating N-1 Contingencies:  94%|███████▌| 9406/10000 [16:26<01:19,  7.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4681/12392 [00:00<00:00, 46804\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4776\u001b[A\n",
      "Simulating N-1 Contingencies:  94%|███████▌| 9413/10000 [16:26<00:53, 10.89it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:  94%|███████▌| 9417/10000 [16:26<00:45, 12.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4810/12392 [00:00<00:00, 48090\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4815\u001b[A\n",
      "Simulating N-1 Contingencies:  94%|███████▌| 9419/10000 [16:27<00:52, 11.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4806/12392 [00:00<00:00, 48052\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3143\u001b[A\n",
      "Simulating N-1 Contingencies:  94%|███████▌| 9427/10000 [16:27<00:44, 12.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4710/12392 [00:00<00:00, 47096\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4781\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4715/12392 [00:00<00:00, 47144\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4793\u001b[A\n",
      "Simulating N-1 Contingencies:  94%|███████▌| 9429/10000 [16:28<01:02,  9.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  18%|▏| 2178/12392 [00:00<00:00, 12039\u001b[A\n",
      "Converting scenarios to PyG Data objects:  56%|▌| 6938/12392 [00:00<00:00, 27728\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3140\u001b[A\n",
      "Simulating N-1 Contingencies:  94%|███████▌| 9432/10000 [16:28<01:07,  8.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4774/12392 [00:00<00:00, 47731\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4826\u001b[A\n",
      "Simulating N-1 Contingencies:  94%|███████▌| 9433/10000 [16:28<01:17,  7.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  24%|▏| 2963/12392 [00:00<00:00, 15043\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3174\u001b[A\n",
      "Simulating N-1 Contingencies:  94%|███████▌| 9440/10000 [16:29<00:57,  9.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  31%|▎| 3892/12392 [00:00<00:00, 38912\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4510\u001b[A\n",
      "Simulating N-1 Contingencies:  94%|███████▌| 9441/10000 [16:29<01:07,  8.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  34%|▎| 4266/12392 [00:00<00:00, 19361\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3199\u001b[A\n",
      "Simulating N-1 Contingencies:  94%|███████▌| 9442/10000 [16:30<01:27,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4747/12392 [00:00<00:00, 47460\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4807\u001b[A\n",
      "Simulating N-1 Contingencies:  94%|███████▌| 9447/10000 [16:30<01:04,  8.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4760/12392 [00:00<00:00, 47589\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3154\u001b[A\n",
      "Simulating N-1 Contingencies:  94%|███████▌| 9449/10000 [16:30<01:15,  7.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4769/12392 [00:00<00:00, 47680\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4802\u001b[A\n",
      "Simulating N-1 Contingencies:  95%|███████▌| 9455/10000 [16:31<00:54, 10.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4727/12392 [00:00<00:00, 47265\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3139\u001b[A\n",
      "Simulating N-1 Contingencies:  95%|███████▌| 9457/10000 [16:31<01:05,  8.23it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4766/12392 [00:00<00:00, 47656\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4787\u001b[A\n",
      "Simulating N-1 Contingencies:  95%|███████▌| 9460/10000 [16:31<01:03,  8.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4721/12392 [00:00<00:00, 47206\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3165\u001b[A\n",
      "Simulating N-1 Contingencies:  95%|███████▌| 9461/10000 [16:32<01:22,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4702/12392 [00:00<00:00, 47012\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4784\u001b[A\n",
      "Simulating N-1 Contingencies:  95%|███████▌| 9464/10000 [16:32<01:13,  7.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4764/12392 [00:00<00:00, 47632\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3123\u001b[A\n",
      "Simulating N-1 Contingencies:  95%|███████▌| 9465/10000 [16:33<01:34,  5.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4816/12392 [00:00<00:00, 48155\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4825\u001b[A\n",
      "Simulating N-1 Contingencies:  95%|███████▌| 9467/10000 [16:33<01:29,  5.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4795/12392 [00:00<00:00, 47943\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4843\u001b[A\n",
      "Simulating N-1 Contingencies:  95%|███████▌| 9469/10000 [16:33<01:26,  6.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   8%| | 1049/12392 [00:00<00:01, 6772.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  46%|▍| 5758/12392 [00:00<00:00, 26114\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3166\u001b[A\n",
      "Simulating N-1 Contingencies:  95%|███████▌| 9470/10000 [16:34<01:49,  4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4790/12392 [00:00<00:00, 47870\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4816\u001b[A\n",
      "Simulating N-1 Contingencies:  95%|███████▌| 9471/10000 [16:34<01:57,  4.51it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  10%| | 1223/12392 [00:00<00:01, 7679.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  48%|▍| 6009/12392 [00:00<00:00, 26678\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3169\u001b[A\n",
      "Simulating N-1 Contingencies:  95%|███████▌| 9479/10000 [16:34<00:58,  8.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4719/12392 [00:00<00:00, 47182\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4791\u001b[A\n",
      "Simulating N-1 Contingencies:  95%|███████▌| 9484/10000 [16:35<00:49, 10.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   3%| | 351/12392 [00:00<00:04, 2445.7\u001b[A\n",
      "Converting scenarios to PyG Data objects:  41%|▍| 5109/12392 [00:00<00:00, 24960\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3145\u001b[A\n",
      "Simulating N-1 Contingencies:  95%|███████▌| 9488/10000 [16:35<00:51,  9.86it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4784/12392 [00:00<00:00, 47829\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4805\u001b[A\n",
      "Simulating N-1 Contingencies:  95%|███████▌| 9496/10000 [16:36<00:42, 11.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4710/12392 [00:00<00:00, 47092\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4796\u001b[A\n",
      "Simulating N-1 Contingencies:  95%|███████▌| 9498/10000 [16:36<00:48, 10.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4727/12392 [00:00<00:00, 47268\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4781\u001b[A\n",
      "Simulating N-1 Contingencies:  95%|███████▌| 9500/10000 [16:36<00:53,  9.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4653/12392 [00:00<00:00, 46519\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4804\u001b[A\n",
      "Simulating N-1 Contingencies:  95%|███████▌| 9501/10000 [16:37<01:13,  6.76it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:  95%|███████▌| 9509/10000 [16:37<00:33, 14.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4842/12392 [00:00<00:00, 48408\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3160\u001b[A\n",
      "Simulating N-1 Contingencies:  95%|███████▌| 9512/10000 [16:37<00:42, 11.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4739/12392 [00:00<00:00, 47387\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4793\u001b[A\n",
      "Simulating N-1 Contingencies:  95%|███████▌| 9515/10000 [16:38<00:44, 10.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4932/12392 [00:00<00:00, 49318\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4885\u001b[A\n",
      "Simulating N-1 Contingencies:  95%|███████▌| 9517/10000 [16:38<00:49,  9.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   5%| | 612/12392 [00:00<00:02, 4161.2\u001b[A\n",
      "Converting scenarios to PyG Data objects:  44%|▍| 5396/12392 [00:00<00:00, 25679\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3161\u001b[A\n",
      "Simulating N-1 Contingencies:  95%|███████▌| 9523/10000 [16:38<00:44, 10.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4759/12392 [00:00<00:00, 47588\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4790\u001b[A\n",
      "Simulating N-1 Contingencies:  95%|███████▌| 9525/10000 [16:39<00:48,  9.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   9%| | 1134/12392 [00:00<00:01, 7105.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  48%|▍| 5960/12392 [00:00<00:00, 26541\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3155\u001b[A\n",
      "Simulating N-1 Contingencies:  95%|███████▌| 9528/10000 [16:39<00:54,  8.65it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4755/12392 [00:00<00:00, 47547\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4821\u001b[A\n",
      "Simulating N-1 Contingencies:  95%|███████▋| 9535/10000 [16:39<00:39, 11.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  11%| | 1309/12392 [00:00<00:01, 8005.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  49%|▍| 6115/12392 [00:00<00:00, 26682\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3143\u001b[A\n",
      "Simulating N-1 Contingencies:  95%|███████▋| 9537/10000 [16:40<00:49,  9.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4702/12392 [00:00<00:00, 47014\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4755\u001b[A\n",
      "Simulating N-1 Contingencies:  95%|███████▋| 9540/10000 [16:40<00:48,  9.41it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:  96%|███████▋| 9551/10000 [16:41<00:26, 16.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4707/12392 [00:00<00:00, 47065\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4828\u001b[A\n",
      "Simulating N-1 Contingencies:  96%|███████▋| 9554/10000 [16:41<00:31, 14.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4659/12392 [00:00<00:00, 46580\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4749\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4686/12392 [00:00<00:00, 46856\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4608\u001b[A\n",
      "Simulating N-1 Contingencies:  96%|███████▋| 9557/10000 [16:42<00:49,  8.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4714/12392 [00:00<00:00, 47129\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4775\u001b[A\n",
      "Simulating N-1 Contingencies:  96%|███████▋| 9559/10000 [16:42<00:58,  7.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4755/12392 [00:00<00:00, 47542\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4531\u001b[A\n",
      "Simulating N-1 Contingencies:  96%|███████▋| 9562/10000 [16:42<00:54,  7.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4735/12392 [00:00<00:00, 47341\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3116\u001b[A\n",
      "Simulating N-1 Contingencies:  96%|███████▋| 9566/10000 [16:43<00:53,  8.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4750/12392 [00:00<00:00, 47489\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4776\u001b[A\n",
      "Simulating N-1 Contingencies:  96%|███████▋| 9572/10000 [16:43<00:40, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4737/12392 [00:00<00:00, 47362\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4799\u001b[A\n",
      "Simulating N-1 Contingencies:  96%|███████▋| 9580/10000 [16:44<00:30, 13.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   9%| | 1136/12392 [00:00<00:01, 7177.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  48%|▍| 5893/12392 [00:00<00:00, 26337\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3150\u001b[A\n",
      "Simulating N-1 Contingencies:  96%|███████▋| 9590/10000 [16:44<00:23, 17.29it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4744/12392 [00:00<00:00, 47429\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4815\u001b[A\n",
      "Simulating N-1 Contingencies:  96%|███████▋| 9594/10000 [16:45<00:28, 14.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4820/12392 [00:00<00:00, 48190\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4826\u001b[A\n",
      "Simulating N-1 Contingencies:  96%|███████▋| 9601/10000 [16:45<00:25, 15.69it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4716/12392 [00:00<00:00, 47155\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3008\u001b[A\n",
      "Simulating N-1 Contingencies:  96%|███████▋| 9609/10000 [16:45<00:25, 15.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4586/12392 [00:00<00:00, 45855\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4678\u001b[A\n",
      "Simulating N-1 Contingencies:  96%|███████▋| 9612/10000 [16:46<00:27, 13.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4784/12392 [00:00<00:00, 47837\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4837\u001b[A\n",
      "Simulating N-1 Contingencies:  96%|███████▋| 9618/10000 [16:46<00:28, 13.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4825/12392 [00:00<00:00, 48243\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4818\u001b[A\n",
      "Simulating N-1 Contingencies:  96%|███████▋| 9620/10000 [16:47<00:33, 11.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4769/12392 [00:00<00:00, 47686\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4813\u001b[A\n",
      "Simulating N-1 Contingencies:  96%|███████▋| 9622/10000 [16:47<00:37,  9.97it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:  96%|███████▋| 9624/10000 [16:47<00:35, 10.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4767/12392 [00:00<00:00, 47665\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4824\u001b[A\n",
      "Simulating N-1 Contingencies:  96%|███████▋| 9626/10000 [16:47<00:40,  9.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4749/12392 [00:00<00:00, 47484\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4784\u001b[A\n",
      "Simulating N-1 Contingencies:  96%|███████▋| 9627/10000 [16:48<00:50,  7.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   3%| | 351/12392 [00:00<00:04, 2507.2\u001b[A\n",
      "Converting scenarios to PyG Data objects:  42%|▍| 5152/12392 [00:00<00:00, 25487\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3180\u001b[A\n",
      "Simulating N-1 Contingencies:  96%|███████▋| 9628/10000 [16:48<01:08,  5.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4798/12392 [00:00<00:00, 47976\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4852\u001b[A\n",
      "Simulating N-1 Contingencies:  96%|███████▋| 9633/10000 [16:48<00:45,  8.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4734/12392 [00:00<00:00, 47336\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4799\u001b[A\n",
      "Simulating N-1 Contingencies:  96%|███████▋| 9637/10000 [16:49<00:38,  9.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4786/12392 [00:00<00:00, 47850\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4839\u001b[A\n",
      "Simulating N-1 Contingencies:  96%|███████▋| 9641/10000 [16:49<00:34, 10.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4792/12392 [00:00<00:00, 47915\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4793\u001b[A\n",
      "Simulating N-1 Contingencies:  96%|███████▋| 9643/10000 [16:50<00:43,  8.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4822/12392 [00:00<00:00, 48211\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4859\u001b[A\n",
      "Simulating N-1 Contingencies:  96%|███████▋| 9645/10000 [16:50<00:45,  7.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   1%| | 90/12392 [00:00<00:18, 661.36i\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4822/12392 [00:00<00:00, 24556\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3158\u001b[A\n",
      "Simulating N-1 Contingencies:  96%|███████▋| 9646/10000 [16:50<01:00,  5.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4764/12392 [00:00<00:00, 47636\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3143\u001b[A\n",
      "Simulating N-1 Contingencies:  97%|███████▋| 9652/10000 [16:51<00:42,  8.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4808/12392 [00:00<00:00, 48072\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4827\u001b[A\n",
      "Simulating N-1 Contingencies:  97%|███████▋| 9653/10000 [16:51<00:48,  7.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4740/12392 [00:00<00:00, 47396\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4817\u001b[A\n",
      "Simulating N-1 Contingencies:  97%|███████▋| 9659/10000 [16:51<00:33, 10.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  27%|▎| 3311/12392 [00:00<00:00, 16414\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3157\u001b[A\n",
      "Simulating N-1 Contingencies:  97%|███████▋| 9661/10000 [16:52<00:41,  8.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4722/12392 [00:00<00:00, 47213\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4775\u001b[A\n",
      "Simulating N-1 Contingencies:  97%|███████▋| 9664/10000 [16:52<00:39,  8.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  36%|▎| 4442/12392 [00:00<00:00, 19513\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3164\u001b[A\n",
      "Simulating N-1 Contingencies:  97%|███████▋| 9665/10000 [16:53<00:51,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4746/12392 [00:00<00:00, 47455\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4812\u001b[A\n",
      "Simulating N-1 Contingencies:  97%|███████▋| 9670/10000 [16:53<00:37,  8.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4811/12392 [00:00<00:00, 48100\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3141\u001b[A\n",
      "Simulating N-1 Contingencies:  97%|███████▋| 9680/10000 [16:53<00:22, 14.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4783/12392 [00:00<00:00, 47827\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4801\u001b[A\n",
      "Simulating N-1 Contingencies:  97%|███████▋| 9684/10000 [16:54<00:22, 13.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4786/12392 [00:00<00:00, 47853\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3012\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4762/12392 [00:00<00:00, 47617\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4810\u001b[A\n",
      "Simulating N-1 Contingencies:  97%|███████▋| 9687/10000 [16:54<00:35,  8.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4734/12392 [00:00<00:00, 47329\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3148\u001b[A\n",
      "Simulating N-1 Contingencies:  97%|███████▊| 9689/10000 [16:55<00:40,  7.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4734/12392 [00:00<00:00, 47338\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4795\u001b[A\n",
      "Simulating N-1 Contingencies:  97%|███████▊| 9692/10000 [16:55<00:38,  8.09it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4751/12392 [00:00<00:00, 47505\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3150\u001b[A\n",
      "Simulating N-1 Contingencies:  97%|███████▊| 9708/10000 [16:56<00:17, 16.92it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:  97%|███████▊| 9716/10000 [16:56<00:11, 23.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4762/12392 [00:00<00:00, 47613\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4836\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4702/12392 [00:00<00:00, 47014\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3131\u001b[A\n",
      "Simulating N-1 Contingencies:  97%|███████▊| 9721/10000 [16:57<00:19, 14.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4880/12392 [00:00<00:00, 48796\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4837\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4724/12392 [00:00<00:00, 47233\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3119\u001b[A\n",
      "Simulating N-1 Contingencies:  97%|███████▊| 9725/10000 [16:57<00:25, 10.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4777/12392 [00:00<00:00, 47759\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4854\u001b[A\n",
      "Simulating N-1 Contingencies:  97%|███████▊| 9728/10000 [16:58<00:26, 10.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4774/12392 [00:00<00:00, 47737\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4828\u001b[A\n",
      "Simulating N-1 Contingencies:  97%|███████▊| 9734/10000 [16:58<00:21, 12.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  20%|▏| 2439/12392 [00:00<00:00, 13305\u001b[A\n",
      "Converting scenarios to PyG Data objects:  59%|▌| 7295/12392 [00:00<00:00, 28745\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3178\u001b[A\n",
      "Simulating N-1 Contingencies:  97%|███████▊| 9737/10000 [16:59<00:25, 10.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4802/12392 [00:00<00:00, 48012\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4848\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  30%|▎| 3746/12392 [00:00<00:00, 17549\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3173\u001b[A\n",
      "Simulating N-1 Contingencies:  97%|███████▊| 9747/10000 [16:59<00:19, 12.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4734/12392 [00:00<00:00, 47338\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4775\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4731/12392 [00:00<00:00, 47301\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3161\u001b[A\n",
      "/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:  98%|███████▊| 9751/10000 [17:00<00:26,  9.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4749/12392 [00:00<00:00, 47484\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4807\u001b[A\n",
      "Simulating N-1 Contingencies:  98%|███████▊| 9754/10000 [17:00<00:25,  9.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4761/12392 [00:00<00:00, 47604\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3129\u001b[A\n",
      "Simulating N-1 Contingencies:  98%|███████▊| 9762/10000 [17:01<00:20, 11.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4759/12392 [00:00<00:00, 47585\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4815\u001b[A\n",
      "Simulating N-1 Contingencies:  98%|███████▊| 9764/10000 [17:01<00:22, 10.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4790/12392 [00:00<00:00, 47796\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3173\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4795/12392 [00:00<00:00, 47947\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4825\u001b[A\n",
      "Simulating N-1 Contingencies:  98%|███████▊| 9766/10000 [17:02<00:32,  7.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4677/12392 [00:00<00:00, 46767\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3145\u001b[A\n",
      "Simulating N-1 Contingencies:  98%|███████▊| 9768/10000 [17:02<00:35,  6.54it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4740/12392 [00:00<00:00, 47390\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4795\u001b[A\n",
      "Simulating N-1 Contingencies:  98%|███████▊| 9774/10000 [17:03<00:24,  9.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4790/12392 [00:00<00:00, 47895\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3145\u001b[A\n",
      "Simulating N-1 Contingencies:  98%|███████▊| 9777/10000 [17:03<00:26,  8.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4745/12392 [00:00<00:00, 47443\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4788\u001b[A\n",
      "Simulating N-1 Contingencies:  98%|███████▊| 9779/10000 [17:03<00:27,  7.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4805/12392 [00:00<00:00, 48044\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4839\u001b[A\n",
      "Simulating N-1 Contingencies:  98%|███████▊| 9782/10000 [17:04<00:25,  8.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  13%|▏| 1658/12392 [00:00<00:01, 10070\u001b[A\n",
      "Converting scenarios to PyG Data objects:  52%|▌| 6490/12392 [00:00<00:00, 27840\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3208\u001b[A\n",
      "Simulating N-1 Contingencies:  98%|███████▊| 9783/10000 [17:04<00:33,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4751/12392 [00:00<00:00, 47499\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4809\u001b[A\n",
      "Simulating N-1 Contingencies:  98%|███████▊| 9787/10000 [17:04<00:26,  8.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  10%| | 1221/12392 [00:00<00:01, 7729.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  49%|▍| 6072/12392 [00:00<00:00, 27093\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3183\u001b[A\n",
      "Simulating N-1 Contingencies:  98%|███████▊| 9793/10000 [17:05<00:21,  9.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4792/12392 [00:00<00:00, 47910\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4820\u001b[A\n",
      "Simulating N-1 Contingencies:  98%|███████▊| 9795/10000 [17:05<00:23,  8.91it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:  98%|███████▊| 9803/10000 [17:05<00:12, 16.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  36%|▎| 4492/12392 [00:00<00:00, 44916\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4693\u001b[A\n",
      "Simulating N-1 Contingencies:  98%|███████▊| 9806/10000 [17:06<00:15, 12.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4677/12392 [00:00<00:00, 46764\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4757\u001b[A\n",
      "Simulating N-1 Contingencies:  98%|███████▊| 9811/10000 [17:06<00:16, 11.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4672/12392 [00:00<00:00, 46709\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4736\u001b[A\n",
      "Simulating N-1 Contingencies:  98%|███████▊| 9813/10000 [17:07<00:18, 10.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4828/12392 [00:00<00:00, 48274\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4860\u001b[A\n",
      "Simulating N-1 Contingencies:  98%|███████▊| 9815/10000 [17:07<00:23,  8.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4788/12392 [00:00<00:00, 47862\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4827\u001b[A\n",
      "Simulating N-1 Contingencies:  98%|███████▊| 9819/10000 [17:07<00:19,  9.32it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4737/12392 [00:00<00:00, 47366\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3111\u001b[A\n",
      "Simulating N-1 Contingencies:  98%|███████▊| 9826/10000 [17:08<00:15, 11.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4798/12392 [00:00<00:00, 47970\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4816\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4783/12392 [00:00<00:00, 47821\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4823\u001b[A\n",
      "Simulating N-1 Contingencies:  98%|███████▊| 9828/10000 [17:08<00:21,  8.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  21%|▏| 2612/12392 [00:00<00:00, 13979\u001b[A\n",
      "Converting scenarios to PyG Data objects:  60%|▌| 7437/12392 [00:00<00:00, 28826\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3175\u001b[A\n",
      "Simulating N-1 Contingencies:  98%|███████▊| 9832/10000 [17:09<00:20,  8.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4753/12392 [00:00<00:00, 47524\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4654\u001b[A\n",
      "Simulating N-1 Contingencies:  98%|███████▊| 9839/10000 [17:09<00:14, 11.08it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  15%|▏| 1832/12392 [00:00<00:01, 10116\u001b[A\n",
      "Converting scenarios to PyG Data objects:  53%|▌| 6603/12392 [00:00<00:00, 26693\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3078\u001b[A\n",
      "Simulating N-1 Contingencies:  98%|███████▉| 9846/10000 [17:10<00:12, 11.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4769/12392 [00:00<00:00, 47686\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4787\u001b[A\n",
      "Simulating N-1 Contingencies:  98%|███████▉| 9850/10000 [17:10<00:12, 12.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  21%|▏| 2613/12392 [00:00<00:00, 13790\u001b[A\n",
      "Converting scenarios to PyG Data objects:  60%|▌| 7423/12392 [00:00<00:00, 28535\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3155\u001b[A\n",
      "Simulating N-1 Contingencies:  99%|███████▉| 9854/10000 [17:11<00:13, 10.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4759/12392 [00:00<00:00, 47587\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4811\u001b[A\n",
      "Simulating N-1 Contingencies:  99%|███████▉| 9856/10000 [17:11<00:14,  9.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  35%|▎| 4355/12392 [00:00<00:00, 19454\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 2975\u001b[A\n",
      "Simulating N-1 Contingencies:  99%|███████▉| 9857/10000 [17:11<00:19,  7.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4761/12392 [00:00<00:00, 47606\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4814\u001b[A\n",
      "Simulating N-1 Contingencies:  99%|███████▉| 9859/10000 [17:12<00:19,  7.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4783/12392 [00:00<00:00, 47824\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3019\u001b[A\n",
      "Simulating N-1 Contingencies:  99%|███████▉| 9863/10000 [17:12<00:17,  7.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4763/12392 [00:00<00:00, 47620\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4811\u001b[A\n",
      "Simulating N-1 Contingencies:  99%|███████▉| 9865/10000 [17:12<00:18,  7.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4721/12392 [00:00<00:00, 47201\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3151\u001b[A\n",
      "Simulating N-1 Contingencies:  99%|███████▉| 9868/10000 [17:13<00:18,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  37%|▎| 4621/12392 [00:00<00:00, 46202\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4740\u001b[A\n",
      "Simulating N-1 Contingencies:  99%|███████▉| 9878/10000 [17:13<00:08, 14.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4743/12392 [00:00<00:00, 47429\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3140\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4800/12392 [00:00<00:00, 47991\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4818\u001b[A\n",
      "Simulating N-1 Contingencies:  99%|███████▉| 9881/10000 [17:14<00:12,  9.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4825/12392 [00:00<00:00, 48247\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3108\u001b[A\n",
      "Simulating N-1 Contingencies:  99%|███████▉| 9884/10000 [17:14<00:13,  8.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4757/12392 [00:00<00:00, 47559\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4692\u001b[A\n",
      "Simulating N-1 Contingencies:  99%|███████▉| 9896/10000 [17:15<00:06, 16.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  36%|▎| 4496/12392 [00:00<00:00, 44957\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 2964\u001b[A\n",
      "Simulating N-1 Contingencies:  99%|███████▉| 9900/10000 [17:15<00:07, 12.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4843/12392 [00:00<00:00, 48423\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4858\u001b[A\n",
      "Simulating N-1 Contingencies:  99%|███████▉| 9903/10000 [17:16<00:08, 12.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4717/12392 [00:00<00:00, 47161\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4766\u001b[A\n",
      "Simulating N-1 Contingencies:  99%|███████▉| 9907/10000 [17:16<00:07, 12.13it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  11%| | 1395/12392 [00:00<00:01, 8569.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  50%|▍| 6140/12392 [00:00<00:00, 26740\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3156\u001b[A\n",
      "Simulating N-1 Contingencies:  99%|███████▉| 9911/10000 [17:16<00:08, 10.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4778/12392 [00:00<00:00, 47778\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4835\u001b[A\n",
      "Simulating N-1 Contingencies:  99%|███████▉| 9916/10000 [17:17<00:07, 11.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  14%|▏| 1744/12392 [00:00<00:01, 10045\u001b[A\n",
      "Converting scenarios to PyG Data objects:  53%|▌| 6554/12392 [00:00<00:00, 27221\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3140\u001b[A\n",
      "Simulating N-1 Contingencies:  99%|███████▉| 9918/10000 [17:17<00:08,  9.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4802/12392 [00:00<00:00, 48013\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4838\u001b[A\n",
      "Simulating N-1 Contingencies:  99%|███████▉| 9922/10000 [17:17<00:07, 10.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  19%|▏| 2352/12392 [00:00<00:00, 12793\u001b[A\n",
      "Converting scenarios to PyG Data objects:  58%|▌| 7160/12392 [00:00<00:00, 28221\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3140\u001b[A\n",
      "Simulating N-1 Contingencies:  99%|███████▉| 9928/10000 [17:18<00:06, 10.96it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies:  99%|███████▉| 9936/10000 [17:18<00:03, 17.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4767/12392 [00:00<00:00, 47660\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4790\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  23%|▏| 2789/12392 [00:00<00:00, 14469\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3181\u001b[A\n",
      "Simulating N-1 Contingencies: 100%|███████▉| 9956/10000 [17:19<00:01, 24.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4698/12392 [00:00<00:00, 46975\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4792\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  11%| | 1308/12392 [00:00<00:01, 8045.\u001b[A\n",
      "Converting scenarios to PyG Data objects:  49%|▍| 6080/12392 [00:00<00:00, 26599\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3143\u001b[A\n",
      "Simulating N-1 Contingencies: 100%|███████▉| 9962/10000 [17:20<00:02, 15.37it/s]/Users/zhenhua/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Simulating N-1 Contingencies: 100%|███████▉| 9970/10000 [17:20<00:01, 21.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4746/12392 [00:00<00:00, 47450\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4796\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   1%| | 89/12392 [00:00<00:18, 650.57i\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4780/12392 [00:00<00:00, 24278\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3150\u001b[A\n",
      "Simulating N-1 Contingencies: 100%|███████▉| 9975/10000 [17:21<00:01, 14.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4726/12392 [00:00<00:00, 47255\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4792\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:   1%| | 177/12392 [00:00<00:09, 1260.3\u001b[A\n",
      "Converting scenarios to PyG Data objects:  40%|▍| 4897/12392 [00:00<00:00, 24424\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3129\u001b[A\n",
      "Simulating N-1 Contingencies: 100%|███████▉| 9979/10000 [17:21<00:02, 10.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4693/12392 [00:00<00:00, 46928\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4760\u001b[A\n",
      "Simulating N-1 Contingencies: 100%|███████▉| 9985/10000 [17:22<00:01, 11.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4756/12392 [00:00<00:00, 47557\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4807\u001b[A\n",
      "Simulating N-1 Contingencies: 100%|███████▉| 9989/10000 [17:22<00:00, 11.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4756/12392 [00:00<00:00, 47555\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3058\u001b[A\n",
      "Simulating N-1 Contingencies: 100%|███████▉| 9991/10000 [17:23<00:00,  9.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4868/12392 [00:00<00:00, 48672\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4888\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  39%|▍| 4840/12392 [00:00<00:00, 48390\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4851\u001b[A\n",
      "Simulating N-1 Contingencies: 100%|███████▉| 9993/10000 [17:23<00:01,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  31%|▎| 3833/12392 [00:00<00:00, 17711\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3160\u001b[A\n",
      "Simulating N-1 Contingencies: 100%|███████▉| 9995/10000 [17:24<00:00,  6.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  33%|▎| 4094/12392 [00:00<00:00, 40931\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 4555\u001b[A\n",
      "Simulating N-1 Contingencies: 100%|███████▉| 9996/10000 [17:24<00:00,  5.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed edge_index_tensor shape: torch.Size([2, 14])\n",
      "Pre-computed static_edge_attr_tensor shape: torch.Size([14, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting scenarios to PyG Data objects:   0%|       | 0/12392 [00:00<?, ?it/s]\u001b[A\n",
      "Converting scenarios to PyG Data objects:  38%|▍| 4759/12392 [00:00<00:00, 47578\u001b[A\n",
      "Converting scenarios to PyG Data objects: 100%|█| 12392/12392 [00:00<00:00, 3154\u001b[A\n",
      "Simulating N-1 Contingencies: 100%|███████| 10000/10000 [17:24<00:00,  9.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- N-1 Contingency Simulation Complete ---\n",
      "\n",
      "Total feasible N-1 scenarios processed: 2758\n",
      "\n",
      "--- GNN Prediction Accuracy under N-1 Contingencies ---\n",
      "Average Pg MAE (Generator Buses): 77.1181 MW\n",
      "Average Pg MSE (Generator Buses): 9907.4567 MW^2\n",
      "Average Theta MAE (All Buses): 405.4100 degrees\n",
      "Average Theta MSE (All Buses): 330553.8811 degrees^2\n",
      "\n",
      "--- Detailed Results for First 5 Feasible Scenarios ---\n",
      "\n",
      "Scenario ID: 6, Contingency: 1-2\n",
      "  Input Loads (MW): {'1': 0, '2': 0, '3': 2.3983672273069896, '4': 158.04012892402164, '5': 0, '6': 64.39899836161523}\n",
      "  True Pg (MW): {'1': '65.38', '2': '149.46', '3': '0.00', '4': '0.00', '5': '10.00', '6': '0.00'}\n",
      "  Pred Pg (MW): {'1': '241.93', '2': '140.07', '3': '52.79', '4': '81.86', '5': '65.05', '6': '-5.55'}\n",
      "  True Theta (deg): {'1': '0.00', '2': '729.17', '3': '77.33', '4': '-779.48', '5': '471.78', '6': '-599.07'}\n",
      "  Pred Theta (deg): {'1': '181.43', '2': '-239.88', '3': '-678.48', '4': '-739.89', '5': '-368.00', '6': '-1079.38'}\n",
      "\n",
      "Scenario ID: 14, Contingency: 2-5\n",
      "  Input Loads (MW): {'1': 0, '2': 0, '3': 86.3750869434436, '4': 67.20612503153488, '5': 0, '6': 1.2298466060425783}\n",
      "  True Pg (MW): {'1': '44.07', '2': '100.74', '3': '0.00', '4': '0.00', '5': '10.00', '6': '0.00'}\n",
      "  Pred Pg (MW): {'1': '171.96', '2': '183.77', '3': '73.50', '4': '2.50', '5': '-97.74', '6': '-105.22'}\n",
      "  True Theta (deg): {'1': '0.00', '2': '145.04', '3': '-709.58', '4': '-702.75', '5': '-535.27', '6': '-649.23'}\n",
      "  Pred Theta (deg): {'1': '630.35', '2': '515.53', '3': '-451.10', '4': '-415.60', '5': '40.63', '6': '-303.01'}\n",
      "\n",
      "Scenario ID: 17, Contingency: 5-6\n",
      "  Input Loads (MW): {'1': 0, '2': 0, '3': 42.50952710818089, '4': 51.21861544986718, '5': 0, '6': 54.368522755645415}\n",
      "  True Pg (MW): {'1': '42.05', '2': '96.05', '3': '0.00', '4': '0.00', '5': '10.00', '6': '0.00'}\n",
      "  Pred Pg (MW): {'1': '61.64', '2': '214.80', '3': '-23.27', '4': '-21.93', '5': '230.31', '6': '-104.48'}\n",
      "  True Theta (deg): {'1': '0.00', '2': '305.79', '3': '-437.74', '4': '-875.00', '5': '336.45', '6': '-1206.76'}\n",
      "  Pred Theta (deg): {'1': '342.69', '2': '-132.87', '3': '-615.41', '4': '-1234.76', '5': '-346.09', '6': '-1904.40'}\n",
      "\n",
      "Scenario ID: 19, Contingency: 1-4\n",
      "  Input Loads (MW): {'1': 0, '2': 0, '3': 22.558870224731294, '4': 2.990082588555678, '5': 0, '6': 106.96810959294949}\n",
      "  True Pg (MW): {'1': '37.28', '2': '85.24', '3': '0.00', '4': '0.00', '5': '10.00', '6': '0.00'}\n",
      "  Pred Pg (MW): {'1': '258.70', '2': '232.65', '3': '-72.89', '4': '-136.50', '5': '13.51', '6': '-55.09'}\n",
      "  True Theta (deg): {'1': '-0.00', '2': '-363.75', '3': '-893.69', '4': '-1310.42', '5': '-576.08', '6': '-1479.44'}\n",
      "  Pred Theta (deg): {'1': '2388.75', '2': '1442.44', '3': '-969.76', '4': '-1725.57', '5': '-244.70', '6': '-1477.38'}\n",
      "\n",
      "Scenario ID: 27, Contingency: 2-5\n",
      "  Input Loads (MW): {'1': 0, '2': 0, '3': 103.13630444874464, '4': 136.64819002249132, '5': 0, '6': 48.84889209813669}\n",
      "  True Pg (MW): {'1': '124.56', '2': '75.44', '3': '0.00', '4': '0.00', '5': '88.63', '6': '0.00'}\n",
      "  Pred Pg (MW): {'1': '225.38', '2': '185.12', '3': '73.48', '4': '-1.82', '5': '-124.88', '6': '-104.72'}\n",
      "  True Theta (deg): {'1': '0.00', '2': '-239.69', '3': '-1234.91', '4': '-1192.33', '5': '60.52', '6': '-949.56'}\n",
      "  Pred Theta (deg): {'1': '439.23', '2': '177.98', '3': '-1211.80', '4': '-1269.73', '5': '-562.85', '6': '-1117.84'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Main Execution for N-1 Simulation ---\n",
    "num_n_1_scenarios = 10000\n",
    "\n",
    "comparison_results, detailed_results, all_true_pg_per_gen_buses, all_pred_pg_per_gen_buses = simulate_n_1_contingencies(\n",
    "    num_n_1_scenarios,\n",
    "    ieee_6_buses_data,\n",
    "    ieee_6_generators_data,\n",
    "    ieee_6_branches_data_base,\n",
    "    SLACK_BUS_IDX,\n",
    "    model, # the trained GNN model\n",
    "    x_scaler, # the fitted x_scaler\n",
    "    y_scaler, # the fitted y_scaler\n",
    "    edge_attr_scaler, # the fitted edge_attr_scaler\n",
    "    device # 'cuda' or 'cpu'\n",
    ")\n",
    "\n",
    "print(f\"\\nTotal feasible N-1 scenarios processed: {len(comparison_results)}\")\n",
    "\n",
    "# --- Summarize Comparison Results ---\n",
    "if comparison_results:\n",
    "    all_pg_maes = [res['pg_mae_gen_buses'] for res in comparison_results if not np.isnan(res['pg_mae_gen_buses'])]\n",
    "    all_pg_mses = [res['pg_mse_gen_buses'] for res in comparison_results if not np.isnan(res['pg_mse_gen_buses'])]\n",
    "    all_theta_maes = [res['theta_mae_all_buses'] for res in comparison_results]\n",
    "    all_theta_mses = [res['theta_mse_all_buses'] for res in comparison_results]\n",
    "\n",
    "    print(\"\\n--- GNN Prediction Accuracy under N-1 Contingencies ---\")\n",
    "    print(f\"Average Pg MAE (Generator Buses): {np.mean(all_pg_maes):.4f} MW\")\n",
    "    print(f\"Average Pg MSE (Generator Buses): {np.mean(all_pg_mses):.4f} MW^2\")\n",
    "    print(f\"Average Theta MAE (All Buses): {np.mean(all_theta_maes):.4f} degrees\")\n",
    "    print(f\"Average Theta MSE (All Buses): {np.mean(all_theta_mses):.4f} degrees^2\")\n",
    "\n",
    "    print(\"\\n--- Detailed Results for First 5 Feasible Scenarios ---\")\n",
    "    for scenario in detailed_results:\n",
    "        print(f\"\\nScenario ID: {scenario['scenario_id']}, Contingency: {scenario['contingency_branch_info']['from_bus']+1}-{scenario['contingency_branch_info']['to_bus']+1}\")\n",
    "        print(\"  Input Loads (MW):\", scenario['input_bus_loads_MW'])\n",
    "        print(\"  True Pg (MW):\", {k: f\"{v:.2f}\" for k, v in scenario['opf_true_pg_MW'].items()})\n",
    "        print(\"  Pred Pg (MW):\", {k: f\"{v:.2f}\" for k, v in scenario['gnn_pred_pg_MW'].items()})\n",
    "        print(\"  True Theta (deg):\", {k: f\"{v:.2f}\" for k, v in scenario['opf_true_theta_deg'].items()})\n",
    "        print(\"  Pred Theta (deg):\", {k: f\"{v:.2f}\" for k, v in scenario['gnn_pred_theta_deg'].items()})\n",
    "else:\n",
    "    print(\"No feasible scenarios found for comparison.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cd36ab1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Pg Distribution Plots Generated for Generator Buses ---\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the list of generator bus IDs (0-indexed)\n",
    "generator_bus_ids = sorted([g['bus'] for g in ieee_6_generators_data])\n",
    "num_generators = len(generator_bus_ids)\n",
    "\n",
    "if num_generators == 0:\n",
    "    print(\"No generator buses defined. Cannot plot Pg distributions.\")\n",
    "else:\n",
    "    # Determine grid size for subplots\n",
    "    cols = 3\n",
    "    rows = (num_generators + cols - 1) // cols\n",
    "\n",
    "    plt.figure(figsize=(cols * 7, rows * 5)) # Adjust figure size as needed\n",
    "    plt.suptitle('10k N-1 Contingencies: Distribution of True vs. Predicted Generator Active Power', \n",
    "                 y=1.00, fontsize=20)\n",
    "\n",
    "    for i, gen_bus_idx in enumerate(generator_bus_ids):\n",
    "        ax = plt.subplot(rows, cols, i + 1)\n",
    "        \n",
    "        true_pg_values = all_true_pg_per_gen_buses[gen_bus_idx]\n",
    "        pred_pg_values = all_pred_pg_per_gen_buses[gen_bus_idx]\n",
    "\n",
    "        if not true_pg_values or not pred_pg_values:\n",
    "            print(f\"Warning: No data for generator bus {gen_bus_idx+1}. Skipping plot.\")\n",
    "            continue\n",
    "\n",
    "        # Plot histograms\n",
    "        ax.hist(true_pg_values, bins=50, alpha=0.7, label='True Pg (OPF)', color='blue', density=True)\n",
    "        ax.hist(pred_pg_values, bins=50, alpha=0.7, label='Predicted Pg (GNN)', color='orange', density=True)\n",
    "        \n",
    "        ax.set_title(f'Generator Bus {gen_bus_idx+1} (G)', fontsize=16)\n",
    "        ax.set_xlabel('Active Power Generation (MW)', fontsize=16)\n",
    "        ax.set_ylabel('Density', fontsize=16)\n",
    "        ax.legend(fontsize=16)\n",
    "        ax.grid(True, linestyle='--', alpha=0.7)\n",
    "        \n",
    "        if (i + 1) == 3:\n",
    "            ax.set_ylim(0, 0.02) # Set y-axis limits from 0 to 0.03\n",
    "\n",
    "#     plt.tight_layout(rect=[0, 0.03, 1, 0.98]) # Adjust rect to make space for suptitle\n",
    "#     plt.show()\n",
    "\n",
    "print(\"\\n--- Pg Distribution Plots Generated for Generator Buses ---\")\n",
    "plt.savefig(\"n1.png\", dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1bdbbf7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Pg Scatter Plots Generated for Generator Buses ---\n"
     ]
    }
   ],
   "source": [
    "# Get the list of generator bus IDs (0-indexed)\n",
    "generator_bus_ids = sorted([g['bus'] for g in ieee_6_generators_data])\n",
    "num_generators = len(generator_bus_ids)\n",
    "\n",
    "if num_generators == 0:\n",
    "    print(\"No generator buses defined. Cannot plot Pg distributions.\")\n",
    "else:\n",
    "    # Determine grid size for subplots\n",
    "    cols = 3\n",
    "    rows = 1\n",
    "\n",
    "    plt.figure(figsize=(cols * 7, rows * 5)) # Adjust figure size as needed\n",
    "    plt.suptitle('True vs. Predicted Generator Active Power (Pg) under N-1 Contingencies', y=1.02, fontsize=16)\n",
    "\n",
    "    for i, gen_bus_idx in enumerate(generator_bus_ids):\n",
    "        ax = plt.subplot(rows, cols, i + 1)\n",
    "        \n",
    "        true_pg_values = all_true_pg_per_gen_buses[gen_bus_idx]\n",
    "        pred_pg_values = all_pred_pg_per_gen_buses[gen_bus_idx]\n",
    "\n",
    "        if not true_pg_values or not pred_pg_values:\n",
    "            print(f\"Warning: No data for generator bus {gen_bus_idx+1}. Skipping plot.\")\n",
    "            continue\n",
    "        \n",
    "        # Ensure true_pg_values and pred_pg_values have the same length for scatter plot\n",
    "        if len(true_pg_values) != len(pred_pg_values):\n",
    "            print(f\"Warning: Mismatched data lengths for generator bus {gen_bus_idx+1}. Skipping scatter plot.\")\n",
    "            continue\n",
    "\n",
    "        # Plot scatter plot\n",
    "        ax.scatter(true_pg_values, pred_pg_values, alpha=0.7, label='Predicted vs. True Pg', color='blue', s=20) # s is marker size\n",
    "        \n",
    "        # Plot a perfect prediction line (y=x)\n",
    "        min_val = min(min(true_pg_values), min(pred_pg_values))\n",
    "        max_val = max(max(true_pg_values), max(pred_pg_values))\n",
    "        ax.plot([min_val, max_val], [min_val, max_val], color='red', linestyle='--', label='Perfect Prediction (y=x)')\n",
    "\n",
    "        ax.set_title(f'Generator Bus {gen_bus_idx+1} (G)', fontsize=12)\n",
    "        ax.set_xlabel('True Active Power Generation (MW)', fontsize=12)\n",
    "        ax.set_ylabel('Predicted Active Power Generation (MW)', fontsize=12)\n",
    "        ax.legend(fontsize=9)\n",
    "        ax.grid(True, linestyle='--', alpha=0.7)\n",
    "        ax.set_aspect('equal', adjustable='box') # To ensure x and y axes have the same scale\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\n--- Pg Scatter Plots Generated for Generator Buses ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dc8a4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "389.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
